2025-05-30 21:12:16 | INFO     | knowledge:load_knowledge:55 - 当前知识库文件列表: ['人事管理流程.docx']
2025-05-30 21:12:16 | INFO     | knowledge:load_knowledge:63 - 文件路径: ./chroma/knowledge/人事管理流程.docx
2025-05-30 21:12:16 | INFO     | knowledge:load_knowledge:67 - 知识库名称: 71eeedee21ca1f1bec56c3087d4cbfa7
2025-05-30 21:12:16 | INFO     | knowledge:load_knowledge:68 - self.__retrievers: {}
2025-05-30 21:12:16 | INFO     | custom_loader:__init__:25 - 本文档[./chroma/knowledge/人事管理流程.docx]需使用文档加载器: <class 'langchain_community.document_loaders.word_document.UnstructuredWordDocumentLoader'>
2025-05-30 21:12:17 | INFO     | knowledge:create_indexes:124 - record_manager: <langchain.indexes._sql_record_manager.SQLRecordManager object at 0x0000025E0F273510>
2025-05-30 21:12:17 | INFO     | knowledge:create_indexes:131 - 准备进行文件的加载切分....
2025-05-30 21:13:17 | INFO     | knowledge:create_indexes:133 - 文档切分数量: 22....
2025-05-30 21:13:17 | DEBUG    | knowledge:create_indexes:134 - documents: [Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='汇视威管理制度\n\n人事管理制度\n\n一、聘用\n\n1、聘用原则\n\n1.1基础岗位人员任用，由部门主管面试确定。\n\n1.2管理岗位人员任用，由总经理最终面试确定。\n\n注：基层岗位：主管岗位以下人员均属于基础岗位\n\n2、聘用程序\n\n人员需求部门提前申请      人事行政部核实情况     总经理审批\n\n注：在正常编制范围内的人员，不需要提交《人事需求审批表》，可直接招聘，招聘工作由用人部门与人事行政部共同完成。\n\n二、入职\n\n1、人员入职，人事行政部为新员工办理如下手续：\n\n1.1 入职人员提交资料：身份证、银行卡、毕业证、职业资格证、与原单位解除或终止劳动合同证明（此项没有填写无法提供离职证明承诺书）原件审核、体检报告。\n\n1.2 资料审核无误    入职面谈及安排工位    签订培训告知书\n\n发放入职指引    办理意外保险    进入培训期(7天)\n\n试用与转正\n\n1、试用与转正流程\n\n试用期1-3个月    试用期合格与否用人部门提前7天告知人事行政部        员工填写转正申请走审批流程    人事行政部备案\n\n员工填写离职申请走审批流程    人事行政部办理离职'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='1.2 资料审核无误    入职面谈及安排工位    签订培训告知书\n\n发放入职指引    办理意外保险    进入培训期(7天)\n\n试用与转正\n\n1、试用与转正流程\n\n试用期1-3个月    试用期合格与否用人部门提前7天告知人事行政部        员工填写转正申请走审批流程    人事行政部备案\n\n员工填写离职申请走审批流程    人事行政部办理离职\n\n员工申请    主管审批    人事招聘主管审批    抄送人事经理/人事主管\n\n员工申请（主管岗）   人事经理审批    总经理审批    抄送人事招聘/行政主管\n\n2、凡有以下情形者，均被视为不符合录用条件：\n\n2.1不符合招录条件：提供的学历、个人简历、工作经历、技能证明、体检证明等材料或者填写的《员工登记表》等内容与事实不符或有虚假的或者不按入职要求提供资料的；\n\n2.2 与原用人单位未依法解除、终止劳动合同或劳动关系的；或与原用人单位存在竞业限制约定且在限制范围之内的；\n\n2.3体检不合格者或患有职业病、传染病、精神疾病、其他身体健康条件不符合工作岗位要求的；'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='2.1不符合招录条件：提供的学历、个人简历、工作经历、技能证明、体检证明等材料或者填写的《员工登记表》等内容与事实不符或有虚假的或者不按入职要求提供资料的；\n\n2.2 与原用人单位未依法解除、终止劳动合同或劳动关系的；或与原用人单位存在竞业限制约定且在限制范围之内的；\n\n2.3体检不合格者或患有职业病、传染病、精神疾病、其他身体健康条件不符合工作岗位要求的；\n\n2.4被发现在外兼职对本职工作造成影响，经书面通知后仍不纠正的；\n\n2.5未完成工作内容、工作指标或工作任务，或者未能通过相关的工作考核的；\n\n2.6严重失职、营私舞弊，给用人单位利益造损失达1000元以上的；\n\n2.7寻衅滋事、工作态度有严重问题、或给团队造成恶劣影响的；\n\n2.8如无特别约定的，合同签约后5天内未能上岗的；\n\n2.9月度连续旷工3天者，或年度累计旷工2次；\n\n2.10法律法规或公司规章制度规定的其他情形。\n\n四、晋升\n\n1、员工的晋升必须符合公司的需要，实行德能与业绩并重的原则；\n\n2、能升能降原则：根据绩效考核与综合能力考核，员工职位能者居之；\n\n3、晋升的流程：同试用与转正流程\n\n五、降级'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='2.8如无特别约定的，合同签约后5天内未能上岗的；\n\n2.9月度连续旷工3天者，或年度累计旷工2次；\n\n2.10法律法规或公司规章制度规定的其他情形。\n\n四、晋升\n\n1、员工的晋升必须符合公司的需要，实行德能与业绩并重的原则；\n\n2、能升能降原则：根据绩效考核与综合能力考核，员工职位能者居之；\n\n3、晋升的流程：同试用与转正流程\n\n五、降级\n\n1、降级条件：经考核不能胜任工作\n\n2、降级流程：部门负责人与相关人员谈话     相关人员填写《员工降级审批表》    同试用与转正流程\n\n六、调岗\n\n员工填写员工内部调动申请表    调出部门审批    用人部门\n\n审批   人事招聘主管审批    抄送人事经理/人事主管\n\n员工填写员工内部调动申请表（管理岗）    调出部门审批    用人部门审批   人事行政经理审批    总经理审批    抄送人事招聘/行政主管\n\n注：严禁私自调岗，申请审批通过后方可调职；\n\n七、离职'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='六、调岗\n\n员工填写员工内部调动申请表    调出部门审批    用人部门\n\n审批   人事招聘主管审批    抄送人事经理/人事主管\n\n员工填写员工内部调动申请表（管理岗）    调出部门审批    用人部门审批   人事行政经理审批    总经理审批    抄送人事招聘/行政主管\n\n注：严禁私自调岗，申请审批通过后方可调职；\n\n七、离职  \n\n离职流程：递交《员工离职申请表》    主管部门审批    人事行政部审批    总经理审批    到期办理离职手续解除劳动合同停用账号与保险    财务核算工资    离职\n\n离职时间：入职人员试用期内离职需提前7天向公司提交申请，转正后离职需提前1个月向公司提交申请；\n\n离职规定：未按规定办理离职手续或未获公司批准自行离职的，公司不予计发离职工资；离职未按规定时间提前申请，申请需要同步人事部门，试用期未提前申请公司有权扣发7天工资，转正期间未提前申请公司有权扣发一个月工资。\n\n培训体系及流程\n\n公司奉行“先培训，后上岗，再持续提高”的原则，具体培训如下：\n\n1、岗前培训：岗前培训，时间为1-3天；'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='离职规定：未按规定办理离职手续或未获公司批准自行离职的，公司不予计发离职工资；离职未按规定时间提前申请，申请需要同步人事部门，试用期未提前申请公司有权扣发7天工资，转正期间未提前申请公司有权扣发一个月工资。\n\n培训体系及流程\n\n公司奉行“先培训，后上岗，再持续提高”的原则，具体培训如下：\n\n1、岗前培训：岗前培训，时间为1-3天；\n\n培训内容：员工手册、员工绩效、薪酬体系、考勤制度等相关制度培训；\n\n培训负责人：人事行政部\n\n2、技能培训：岗前培训后进行技能培训，时间为3-7天；\n\n培训内容：产品知识、平台规则、岗位技能等；\n\n培训负责人：用人部门\n\n3、其他培训：专业培训、其他不定期学习培训等。\n\n考勤管理制度\n\n第一条 目的 \n\n为规范公司人员出勤及休假，确保工作正常有序开展，更好的保障员工福利待遇及薪资核算，特制定本制度。\n\n第二条 原则  \n\n公平、公正、公开。\n\n第三条 适用范围 \n\n1、本制度适用于公司全体员工。\n\n2、员工入职时间是指员工最近一次就职时间，若员工入职后又中途离开的，按最近一次时间为入职时间。'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='3、其他培训：专业培训、其他不定期学习培训等。\n\n考勤管理制度\n\n第一条 目的 \n\n为规范公司人员出勤及休假，确保工作正常有序开展，更好的保障员工福利待遇及薪资核算，特制定本制度。\n\n第二条 原则  \n\n公平、公正、公开。\n\n第三条 适用范围 \n\n1、本制度适用于公司全体员工。\n\n2、员工入职时间是指员工最近一次就职时间，若员工入职后又中途离开的，按最近一次时间为入职时间。\n\n3、公司其它规章制度中关于下述类似条款的规定如与本规定有出入时，以本规定为准。\n\n第四条 职责分工\n\n1、行政人事部是公司全员出勤、休假的主管部门，负责公司全员考勤、休假的统筹管理。\n\n2、各用人部门是本部门员工出勤、休假的直管部门，负责本部门人员出勤、休假的严格管理。\n\n第五条 作息时间\n\n1、工作天数：公司实行月度单双休工作制，考勤按自然月核算。\n\n2、作息时间：\n\n早班：09:00-12:00   13:30-18:00\n\n晚班：13:30-18:00   19:30-22:30 / 14:00-18:00  19:30-23:00\n\n其他班次：10:00--20:00  /  19:30--22:30'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='第五条 作息时间\n\n1、工作天数：公司实行月度单双休工作制，考勤按自然月核算。\n\n2、作息时间：\n\n早班：09:00-12:00   13:30-18:00\n\n晚班：13:30-18:00   19:30-22:30 / 14:00-18:00  19:30-23:00\n\n其他班次：10:00--20:00  /  19:30--22:30\n\n因公司实际工作需要而调整作息时间的，以公司通知为准。\n\n第六条 考勤打卡\n\n1、考勤内容：\n\n1.1 迟到/早退：正常工作时间未到岗或提前离岗的且时间不超过1个小时视为迟到/早退；超过1个小时的请假按请假处理，未请假按旷工处理；\n\n1.2 旷工：未请假（含脱岗）、未准假（含延长假），当天无故不上班、病假证明弄虚作假、考勤弄虚作假（双方当事人）者按旷工处理；时间不足0.5天按0.5天算，超过0.5天按1天计算。\n\n2、考勤方式：\n\n公司除总经理及以上人员均实行上下班打卡制度（含外勤人员），每天打两次卡，人事行政部依据打卡记录核算考勤；每人每月3次免费补卡机会，不补卡或超过次数负激励 50元/次。\n\n3、考勤扣款：'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='1.2 旷工：未请假（含脱岗）、未准假（含延长假），当天无故不上班、病假证明弄虚作假、考勤弄虚作假（双方当事人）者按旷工处理；时间不足0.5天按0.5天算，超过0.5天按1天计算。\n\n2、考勤方式：\n\n公司除总经理及以上人员均实行上下班打卡制度（含外勤人员），每天打两次卡，人事行政部依据打卡记录核算考勤；每人每月3次免费补卡机会，不补卡或超过次数负激励 50元/次。\n\n3、考勤扣款：\n\n3.1 迟到/早退：30分钟以内，负激励20元/人次；31分钟-60分钟以内，负激励50元/次。\n\n3.2 迟到/早退/脱岗/未准假不在岗：指员工在上班期间未履行任何手续不在工作岗位的，超过 1 小时（未请假）按旷工0.5天计算；超过4小时以上（未请假）则按旷工 1 天计算。\n\n3.3 旷工处罚：旷工当日工资不计薪另处以当日工资双倍的罚款。\n\n3.4 自动离职：员工未按公司离职流程办理离职手续且未做工作交接者，视为自动离职。自动离职员工，公司有权扣发一个月工资，并记入员工个人档案。\n\n第七条 加班\n\n公司不支持加班，因特殊原因公司安排需要加班的，请在系统提交申请审批。\n\n请假规定与类别'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='3.3 旷工处罚：旷工当日工资不计薪另处以当日工资双倍的罚款。\n\n3.4 自动离职：员工未按公司离职流程办理离职手续且未做工作交接者，视为自动离职。自动离职员工，公司有权扣发一个月工资，并记入员工个人档案。\n\n第七条 加班\n\n公司不支持加班，因特殊原因公司安排需要加班的，请在系统提交申请审批。\n\n请假规定与类别\n\n1、请假审批流程：\n\n1.1普通员工申请请假/加班/调休：由直属领导、事业部总监、人事行政主管审批。抄送考勤组、请假部门、人事行政经理；\n\n1.2 主管及以上人员申请请假/调休/请假≥3天：由直属领导、事业部总监、人事行政经理、总经理审批。抄送考勤组、请假部门、人事行政主管、股东会成员；\n\n1.3原则上所有请假/加班/调休必须在钉钉系统进行申请并批准后方可执行；因紧急特殊原因请假/调休，可以电话获得部门经理同意后24小时内申请，逾期未申请相关审批人员可不予准假，否则视为旷工。\n\n1.4常规请假需提前1个工作日在钉钉系统进行申请，请假3天及以上人员需提前3天申请，并注明请假时间、类型、事由，未按要求提前申请可不予准假，请假审批通过后方可休假，否则按旷工处理；\n\n2、请假规定'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='1.3原则上所有请假/加班/调休必须在钉钉系统进行申请并批准后方可执行；因紧急特殊原因请假/调休，可以电话获得部门经理同意后24小时内申请，逾期未申请相关审批人员可不予准假，否则视为旷工。\n\n1.4常规请假需提前1个工作日在钉钉系统进行申请，请假3天及以上人员需提前3天申请，并注明请假时间、类型、事由，未按要求提前申请可不予准假，请假审批通过后方可休假，否则按旷工处理；\n\n2、请假规定\n\n2.1最小请假单位为1小时，不足1小时按1小时计算。\n\n2.2如请假提前结束的，需到行政人事行政部办理销假手续，否则假期时间按请假审批所填期限计算；\n\n2.3请假期间如需续假，须在假期到期日前1个工作日在钉钉系统申请，经批准后方可续假；\n\n2.4无特殊情况，法定节假日前后不得连续请假，特殊情况需请假的，请假前请做好工作交接，请假期间请保持手机畅通，以便公司及时了解请假员工状况和对接相关工作事宜。\n\n3、请假类别\n\n3.1法定假节日：元旦1天、春节3天、清明节1天、劳动节1天、端午节1天、中秋节1天、国庆节3天\n\n注：如遇国家对法定节假日的休假有最新的调整，按照最新国家规定执行。\n\n3.2事假：无薪'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='2.4无特殊情况，法定节假日前后不得连续请假，特殊情况需请假的，请假前请做好工作交接，请假期间请保持手机畅通，以便公司及时了解请假员工状况和对接相关工作事宜。\n\n3、请假类别\n\n3.1法定假节日：元旦1天、春节3天、清明节1天、劳动节1天、端午节1天、中秋节1天、国庆节3天\n\n注：如遇国家对法定节假日的休假有最新的调整，按照最新国家规定执行。\n\n3.2事假：无薪\n\n3.2.1 员工遇有个人事务可在不妨碍正常工作的前提下申请事假；\n\n3.2.2 事假全年累计一般不得超过 15天，一次不得超过3天，特殊情况请假一般不得大于5天；\n\n3.2.3 试用期员工请事假，原则上不允许超过3个工作日，用人部门可酌情考虑是否继续留用；\n\n3.3病假：\n\n3.3.1病假单次2天以内提供医院门诊证明，单次2天以上提供三级甲等医院门诊及相关检查证明材料，住院的需提供住院及出院相关证明材料，同时通过钉钉系统办理请假手续；若无相关证明或证明不符合要求的按照事假计算；\n\n3.3.2 工资支付标准：病假期间按长沙市最低工资标准的80%计发；'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='3.2.3 试用期员工请事假，原则上不允许超过3个工作日，用人部门可酌情考虑是否继续留用；\n\n3.3病假：\n\n3.3.1病假单次2天以内提供医院门诊证明，单次2天以上提供三级甲等医院门诊及相关检查证明材料，住院的需提供住院及出院相关证明材料，同时通过钉钉系统办理请假手续；若无相关证明或证明不符合要求的按照事假计算；\n\n3.3.2 工资支付标准：病假期间按长沙市最低工资标准的80%计发；\n\n3.3.3 3个月≤入职≤1年，全年累计病假计薪天数不超过15天，入职满1年以上，全年累计病假计薪天数不超过30天，超过部分按事假计算。\n\n3.4工伤假：\n\n员工因公负伤且符合劳动和社会保障局工伤认定标准，按法律规定伤残等级支付周期支付长沙市最低工资标准。\n\n3.5年假：全额计薪\n\n3.5.1职工在本公司累计工作满1年不满10年，年假5天；职工在本公司累计工作满10年不满20年，年假10天；职工在本公司累计工作满20年以上，年假15天；当年累计请病假15天及以上的，当年无年假。'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='3.4工伤假：\n\n员工因公负伤且符合劳动和社会保障局工伤认定标准，按法律规定伤残等级支付周期支付长沙市最低工资标准。\n\n3.5年假：全额计薪\n\n3.5.1职工在本公司累计工作满1年不满10年，年假5天；职工在本公司累计工作满10年不满20年，年假10天；职工在本公司累计工作满20年以上，年假15天；当年累计请病假15天及以上的，当年无年假。\n\n3.5.2年假具体天数由行政人事部根据员工入职日期计算，可用于抵扣当年的病假或事假，年度内未使用的年假，将于次年02月28日清零。\n\n3.5.3同一时间休年假的员工不得超过本部门人员数量的10%；\n\n3.6婚假：全额计薪\n\n入司以后领取结婚证的员工可提供结婚证复印件享受 3 天带薪婚假，婚假必须在领证后的半年内一次性休完，如在此期间内未休，则视为作废。'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='3.5.2年假具体天数由行政人事部根据员工入职日期计算，可用于抵扣当年的病假或事假，年度内未使用的年假，将于次年02月28日清零。\n\n3.5.3同一时间休年假的员工不得超过本部门人员数量的10%；\n\n3.6婚假：全额计薪\n\n入司以后领取结婚证的员工可提供结婚证复印件享受 3 天带薪婚假，婚假必须在领证后的半年内一次性休完，如在此期间内未休，则视为作废。\n\n3.7产假：符合国家计划生育政策及社保报销政策的员工可依法享受产假待遇，生育保险符合条件的由社会保险基金支付，公司不再承担另外的费用及工资；反之因员工个人原因不符合国家计划生育政策规定及产假申报条件/资料不齐/超过时间等，社会保险基金与公司均不承担产假此项费用，由此而引起的损失由员工自行承担。\n\n3.7.1员工休产假需在休假前15日办理请假手续，同时需提供“准生证”复印件，产后其工作岗位将根据公司需求进行安排；\n\n3.7.2产假为158天（含产前15天），产假遇节假日不顺延,难产增加15天；多胞胎生育的，每多生育一个婴儿，增加15天；超期未返岗无特殊情况公司将不再批假；'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='3.7.1员工休产假需在休假前15日办理请假手续，同时需提供“准生证”复印件，产后其工作岗位将根据公司需求进行安排；\n\n3.7.2产假为158天（含产前15天），产假遇节假日不顺延,难产增加15天；多胞胎生育的，每多生育一个婴儿，增加15天；超期未返岗无特殊情况公司将不再批假；\n\n3.7.3 2个月以下流产的，产假为15 天；2-4个月流产的，产假为 30 天；4 个月以上流产的，产假为 42 天，产假期包含休息日及法定假期；\n\n3.7.4产假社保：休假期间公司继续缴纳保险，产假期间（5个月）社保个人部分从休产假前发放的最后一个月工资中一次性扣除。\n\n3.8孕检假和哺乳假：全额计薪\n\n3.8.1员工休孕检假须通过钉钉系统提出休假申请，并同步当天产检证明复印件。\n\n3.8.2 怀孕7个月以内产检假1天/月，怀孕7 - 9个月产检假1天/半月，怀孕9个月以上产检假1天/周；\n\n3.8.3 小孩一周岁内，女职工可享受每天工作时间内一次1小时的哺乳时间，多胞胎生育的，每多哺乳一个婴儿，每次哺乳时间增加1小时；\n\n3.9陪产假：全额计薪'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='3.8孕检假和哺乳假：全额计薪\n\n3.8.1员工休孕检假须通过钉钉系统提出休假申请，并同步当天产检证明复印件。\n\n3.8.2 怀孕7个月以内产检假1天/月，怀孕7 - 9个月产检假1天/半月，怀孕9个月以上产检假1天/周；\n\n3.8.3 小孩一周岁内，女职工可享受每天工作时间内一次1小时的哺乳时间，多胞胎生育的，每多哺乳一个婴儿，每次哺乳时间增加1小时；\n\n3.9陪产假：全额计薪\n\n3.9.1男员工配偶生育的（须提供“准生证”复印件、“小孩出生证明”复印件），可享受陪产假7天（含公休日且不能拆分）；\n\n3.9.2员工提出离职申请后，自申请提出之日起不再享受陪护假；\n\n3.9.3员工不能提供医学出生证明的，按事假处理。\n\n3.10 丧假：全额计薪\n\n3.10.1直系亲属（父母、养父母、配偶、子女、配偶父母）去世的员工，可享受3个工作日丧假；\n\n3.10.2 非直系亲属（兄弟姊妹、祖父母和外祖父母、孙子女和外孙子女）去世的员工请丧假，可享受2个工作日丧假；\n\n3.10.3以上假期超过部分按事假处理；\n\n销假管理'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='3.9.3员工不能提供医学出生证明的，按事假处理。\n\n3.10 丧假：全额计薪\n\n3.10.1直系亲属（父母、养父母、配偶、子女、配偶父母）去世的员工，可享受3个工作日丧假；\n\n3.10.2 非直系亲属（兄弟姊妹、祖父母和外祖父母、孙子女和外孙子女）去世的员工请丧假，可享受2个工作日丧假；\n\n3.10.3以上假期超过部分按事假处理；\n\n销假管理\n\n为方便行政人事部对员工假期的管理以及考勤统计，员工需于假期结束后第一个工作日内，到行政人事部进行销假处理；需要续延假期的应重新办理请假手续。\n\n以下行为，公司有权予以辞退处理并不支付任何经济补偿金：\n\n迟到/早退次数：月度合计达到5次者，或季度合计达到12次者，或半年达到20次者，或年度达到36次及以上者，公司有权单方面予以辞退处理。\n\n员工（含试用期）月度事假累计5天，或季度累计10天，或半年累计15天，或年度累计20天及以上者，公司有权单方面予以辞退处理。\n\n员工（含试用期）月度病假累计10天，或年度累计30天者及以上者，公司有权单方面予以辞退处理。'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='迟到/早退次数：月度合计达到5次者，或季度合计达到12次者，或半年达到20次者，或年度达到36次及以上者，公司有权单方面予以辞退处理。\n\n员工（含试用期）月度事假累计5天，或季度累计10天，或半年累计15天，或年度累计20天及以上者，公司有权单方面予以辞退处理。\n\n员工（含试用期）月度病假累计10天，或年度累计30天者及以上者，公司有权单方面予以辞退处理。\n\n月度连续旷工3天者，或年度累计旷工2次，视为严重违反公司管理制度，公司有权单方面对违纪员工作出开除处理。\n\n资产管理制度\n\n目的\n\n为提高公司资产管理水平，了解资产使用状况，分清资产保管权责，特制订本细则。\n\n适用范围及规则\n\n本制度适用于公司所有人员。\n\n管理规则：谁使用谁保管，由部门主管及人事行政专员监管，其中运营账号由运营部门负责人统一管理并确保数据的准确性。\n\n资产的分类\n\n根据资产的使用形态，分为固定资产和虚拟资产两类。\n\n固定资产：显示器、主机、笔记本、手机、图书、桌椅、直播设备等\n\n虚拟资产：公司提供的手机卡及其他虚拟资产（QQ账号、运营平台账号、微信账号等）\n\n资产的采购、领用、保管与报废\n\n资产采购与领用'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='管理规则：谁使用谁保管，由部门主管及人事行政专员监管，其中运营账号由运营部门负责人统一管理并确保数据的准确性。\n\n资产的分类\n\n根据资产的使用形态，分为固定资产和虚拟资产两类。\n\n固定资产：显示器、主机、笔记本、手机、图书、桌椅、直播设备等\n\n虚拟资产：公司提供的手机卡及其他虚拟资产（QQ账号、运营平台账号、微信账号等）\n\n资产的采购、领用、保管与报废\n\n资产采购与领用\n\n采购：部门将需求报给人事行政专员，由人事行政部审核，若审核通过，则优先查询库存，库存不足时再进行采购，若审核不通过，则说明驳回原因。\n\n采买回来的所有物品需先入库再出库，并及时进行系统数据更新；\n\n领用：物品领用人需在领用登记表上签字，人事行政专员需及时更新系统数据。\n\n（二）资产保管\n\n（1）所有资产谁使用谁保管：若出现丢失，则由保管人进行赔偿；由于自然损坏导致的维修费则由公司承担；因人为损坏导致的维修费，则由保管人进行赔偿；\n\n（2）资产遗失惩罚\n\n固定资产：按照资产的价值进行赔偿，新采买遗失的按照原价赔偿，使用一段时间遗失的则按时间折价赔偿。'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='领用：物品领用人需在领用登记表上签字，人事行政专员需及时更新系统数据。\n\n（二）资产保管\n\n（1）所有资产谁使用谁保管：若出现丢失，则由保管人进行赔偿；由于自然损坏导致的维修费则由公司承担；因人为损坏导致的维修费，则由保管人进行赔偿；\n\n（2）资产遗失惩罚\n\n固定资产：按照资产的价值进行赔偿，新采买遗失的按照原价赔偿，使用一段时间遗失的则按时间折价赔偿。\n\n虚拟资产：手机卡按照100元一张进行赔偿，其他账号按照粉丝量来进行赔偿，一个粉丝1元进行计价。\n\n（三）资产报废\n\n固定资产报废需经专业人员确认已无法维修或维修费用超过资产原值时，报公司同意后，人事行专员走报废流程，审批通过后由并及时更新系统数据。\n\n资产清查\n\n资产清查：人事&财务每个季度清查一次资产，并确定资产状态，清查前人事行政专员通知被清理人准备好所有后台显示在他名下的资产，如清查发现资产损坏遗失，则按资产保管规则核定，资产清查无误后，当事人签字确认。\n\n资产转移'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx'}, page_content='（三）资产报废\n\n固定资产报废需经专业人员确认已无法维修或维修费用超过资产原值时，报公司同意后，人事行专员走报废流程，审批通过后由并及时更新系统数据。\n\n资产清查\n\n资产清查：人事&财务每个季度清查一次资产，并确定资产状态，清查前人事行政专员通知被清理人准备好所有后台显示在他名下的资产，如清查发现资产损坏遗失，则按资产保管规则核定，资产清查无误后，当事人签字确认。\n\n资产转移\n\n因入职、离职或资产公司内部调拨，保管人需在公司后台（资产管理）进行资产转让审批，经行政专员审核后接收人完成资产确认方为交接成功。因个人原因未及时办理转让审批，导致资产遗失的，由上一任保管人承担赔偿责任。\n\n其他说明\n\n1、其他未列出的易耗品，需由员工在个人领用登记表内签字确认，如遇损坏，需以坏换新或以旧换新；如有遗失，照价赔偿。\n\n2、员工填写固定资产领用清单，并仔细阅读本细则后签署，人事行政部存档。')]
2025-05-30 21:13:17 | INFO     | knowledge:create_indexes:138 - 文档索引结果为: {'num_added': 0, 'num_updated': 0, 'num_skipped': 22, 'num_deleted': 0}
2025-05-30 21:13:17 | INFO     | knowledge:load_knowledge:78 - 检索器详情: {'71eeedee21ca1f1bec56c3087d4cbfa7': EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)], weights=[0.5, 0.5])}
2025-05-30 21:15:15 | INFO     | knowledge:load_knowledge:55 - 当前知识库文件列表: ['中国人工智能系列白皮书.pdf', '人事管理流程.docx']
2025-05-30 21:15:15 | INFO     | knowledge:load_knowledge:63 - 文件路径: ./chroma/knowledge/中国人工智能系列白皮书.pdf
2025-05-30 21:15:15 | INFO     | knowledge:load_knowledge:67 - 知识库名称: 503dc7d31f89743234dc87e712078441
2025-05-30 21:15:15 | INFO     | knowledge:load_knowledge:68 - self.__retrievers: {'71eeedee21ca1f1bec56c3087d4cbfa7': EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)], weights=[0.5, 0.5])}
2025-05-30 21:15:15 | INFO     | custom_loader:__init__:25 - 本文档[./chroma/knowledge/中国人工智能系列白皮书.pdf]需使用文档加载器: <class 'langchain_community.document_loaders.pdf.PyPDFLoader'>
2025-05-30 21:15:15 | INFO     | knowledge:create_indexes:124 - record_manager: <langchain.indexes._sql_record_manager.SQLRecordManager object at 0x0000025E34D23750>
2025-05-30 21:15:15 | INFO     | knowledge:create_indexes:131 - 准备进行文件的加载切分....
2025-05-30 21:15:20 | INFO     | knowledge:create_indexes:133 - 文档切分数量: 352....
2025-05-30 21:15:20 | DEBUG    | knowledge:create_indexes:134 - documents: [Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 0, 'page_label': '1'}, page_content='中国人工智能系列白皮书  \n \n        ——大模型技术 （2023版） \n            \n \n \n \n \n \n \n \n \n \n中国人工智能学会  \n \n二○二三年九月'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 1, 'page_label': '2'}, page_content='1  \n《中国人工智能系列白皮书》编委会  \n主  任：戴琼海  \n执行主任：王国胤  \n副 主 任：陈 杰 何 友 刘成林 刘 宏 孙富春 王恩东  \n     王文博 赵春江 周志华  \n委  员：班晓娟  曹 鹏 陈 纯 陈松灿 邓伟文 董振江  \n     杜军平 付宜利 古天龙 桂卫华 何 清 胡国平  \n     黄河燕 季向阳 贾英民 焦李成 李 斌 刘 民  \n     刘庆峰 刘增良 鲁华祥 马华东 苗夺谦 潘 纲  \n     朴松昊 钱 锋 乔俊飞 孙长银 孙茂松 陶建华  \n     王卫宁 王熙照 王 轩 王蕴红 吾守尔·斯拉木  \n     吴晓蓓 杨放春 于 剑 岳 东 张小川 张学工  \n     张 毅 章 毅 周国栋 周鸿祎 周建设 周 杰  \n     祝烈煌 庄越挺  \n \n《中国人工智能系列白皮书 ----大模型技术》编写组  \n       陶建华   吴  飞  黄民烈   文继荣   王海峰   刘知远  \n        刘  静  杨小康   聂  帅'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 2, 'page_label': '3'}, page_content='2 目录 \n \n第1章 大模型技术概述  ................................ ................................ ..........  5 \n1.1 大模型技术的发展历程  ................................ .............................  5 \n1.2 大模型技术的生态发展  ................................ .............................  9 \n1.3 大模型技术的风险与挑战  ................................ .......................  11 \n第2章 语言大模型技术  ................................ ................................ ........  13'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 2, 'page_label': '3'}, page_content='1.3 大模型技术的风险与挑战  ................................ .......................  11 \n第2章 语言大模型技术  ................................ ................................ ........  13 \n2.1 Transformer 架构  ................................ ................................ ........  13 \n2.2 语言大模型架构  ................................ ................................ ....... 17 \n2.2.1 掩码语言建模  ................................ ................................ .... 17'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 2, 'page_label': '3'}, page_content='2.2 语言大模型架构  ................................ ................................ ....... 17 \n2.2.1 掩码语言建模  ................................ ................................ .... 17 \n2.2.2 自回归语言建模  ................................ ................................  18 \n2.2.3 序列到序列建模  ................................ ................................  18 \n2.3 语言大模型关键技术  ................................ ...............................  19'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 2, 'page_label': '3'}, page_content='2.2.3 序列到序列建模  ................................ ................................  18 \n2.3 语言大模型关键技术  ................................ ...............................  19 \n2.3.1 语言大模型的预训练  ................................ ........................  19 \n2.3.2 语言大模型的适配微调  ................................ ....................  21 \n2.3.3 语言大模型的提示学习  ................................ ....................  24 \n2.3.4 语言大模型的知识增强  ................................ ....................  26'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 2, 'page_label': '3'}, page_content='2.3.3 语言大模型的提示学习  ................................ ....................  24 \n2.3.4 语言大模型的知识增强  ................................ ....................  26 \n2.4.5 语言大模型的工具学习  ................................ ....................  27 \n第3章 多模态大模型技术  ................................ ................................ .... 29 \n3.1 多模态大模型的技术体系  ................................ .......................  29 \n3.1.1 面向理解任务的多模态大模型  ................................ ........  29'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 2, 'page_label': '3'}, page_content='3.1 多模态大模型的技术体系  ................................ .......................  29 \n3.1.1 面向理解任务的多模态大模型  ................................ ........  29 \n3.1.2 面向生成任务的多模态大模型  ................................ ........  31 \n3.1.3 兼顾理解和生成任务的多模态大模型  ............................  33 \n3.1.4 知识增强的多模态大模型  ................................ ................  35 \n3.2 多模态大模型的关键技术  ................................ .......................  36 \n3.2.1 多模态大模型的网络结构设计  ................................ ........  36'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 3, 'page_label': '4'}, page_content='3 3.2.2 多模态大模型的自监督学习优化  ................................ .... 37 \n3.2.3 多模态大模型的下游任务微调适配  ................................  39 \n第4章 大模型技术生态  ................................ ................................ ........  41 \n4.1 典型大模型平台  ................................ ................................ ....... 41 \n4.2 典型开源大模型  ................................ ................................ ....... 44 \n4.2.1 典型开源语言大模型  ................................ ........................  44'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 3, 'page_label': '4'}, page_content='4.2 典型开源大模型  ................................ ................................ ....... 44 \n4.2.1 典型开源语言大模型  ................................ ........................  44 \n4.2.2 典型开源多模态大模型  ................................ ....................  53 \n4.3 典型开源框架与工具  ................................ ...............................  57 \n4.4大模型的训练数据  ................................ ................................ .... 60 \n4.4.1 大模型的训练数据处理流程和特点  ................................  60'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 3, 'page_label': '4'}, page_content='4.4大模型的训练数据  ................................ ................................ .... 60 \n4.4.1 大模型的训练数据处理流程和特点  ................................  60 \n4.4.2 大模型常用的公开数据集  ................................ ................  63 \n第5章 大模型的开发训练与推理部署  ................................ ................  66 \n5.1 大模型开发与训练  ................................ ................................ ... 66 \n5.2 大模型推理部署  ................................ ................................ ....... 68'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 3, 'page_label': '4'}, page_content='5.1 大模型开发与训练  ................................ ................................ ... 66 \n5.2 大模型推理部署  ................................ ................................ ....... 68 \n5.2.1 大模型压缩  ................................ ................................ ........  69 \n5.2.2 大模型推理与服务部署  ................................ ....................  70 \n5.3 软硬件适配与协同优化  ................................ ...........................  71'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 3, 'page_label': '4'}, page_content='5.2.2 大模型推理与服务部署  ................................ ....................  70 \n5.3 软硬件适配与协同优化  ................................ ...........................  71 \n5.3.1 大模型的软硬件适配  ................................ ........................  72 \n5.3.2 大模型的软硬件协同优化  ................................ ................  72 \n第6章 大模型应用  ................................ ................................ ................  74'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 3, 'page_label': '4'}, page_content='5.3.2 大模型的软硬件协同优化  ................................ ................  72 \n第6章 大模型应用  ................................ ................................ ................  74 \n6.1 信息检索  ................................ ................................ ...................  74 \n6.2 新闻媒体  ................................ ................................ ...................  75 \n6.3 智慧城市  ................................ ................................ ...................  76'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 3, 'page_label': '4'}, page_content='6.3 智慧城市  ................................ ................................ ...................  76 \n6.4 生物科技  ................................ ................................ ...................  76 \n6.5 智慧办公  ................................ ................................ ...................  77 \n6.6 影视制作  ................................ ................................ ...................  78'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 3, 'page_label': '4'}, page_content='6.6 影视制作  ................................ ................................ ...................  78 \n6.7 智能教育  ................................ ................................ ...................  78'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 4, 'page_label': '5'}, page_content='4 6.8 智慧金融  ................................ ................................ ...................  79 \n6.9 智慧医疗  ................................ ................................ ...................  79 \n6.10 智慧工厂  ................................ ................................ .................  79 \n6.11 生活服务  ................................ ................................ ..................  80'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 4, 'page_label': '5'}, page_content='6.11 生活服务  ................................ ................................ ..................  80 \n6.12 智能机器人  ................................ ................................ .............  80 \n6.13 其他应用  ................................ ................................ .................  80 \n第7章 大模型的安全性  ................................ ................................ ........  82 \n7.1 大模型安全风险引发全球广泛关注  ................................ ....... 82'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 4, 'page_label': '5'}, page_content='第7章 大模型的安全性  ................................ ................................ ........  82 \n7.1 大模型安全风险引发全球广泛关注  ................................ ....... 82 \n7.2 大模型安全治理的政策法规和标准规范  ...............................  83 \n7.3 大模型安全风险的具体表现  ................................ ...................  85 \n7.3.1 大模型自身的安全风险  ................................ ....................  85 \n7.3.2 大模型在应用中衍生的安全风险  ................................ .... 86'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 4, 'page_label': '5'}, page_content='7.3.1 大模型自身的安全风险  ................................ ....................  85 \n7.3.2 大模型在应用中衍生的安全风险  ................................ .... 86 \n7.4 大模型安全研究关键技术  ................................ .......................  88 \n7.4.1 大模型的安全对齐技术  ................................ ....................  88 \n7.4.2 大模型安全性评测技术  ................................ ....................  91 \n第8章  总结与思考  ................................ ................................ ..............  94'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 4, 'page_label': '5'}, page_content='7.4.2 大模型安全性评测技术  ................................ ....................  91 \n第8章  总结与思考  ................................ ................................ ..............  94 \n8.1 协同多方合作，共同推动大模型发展  ................................ ... 95 \n8.2 建立大模型 合规标准和评测平台  ................................ ...........  96 \n8.3 应对大模型带来的安全性挑战  ................................ ...............  97 \n8.4 开展大模型广泛适配，推动大模型技术栈自主可控  ...........  98'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 4, 'page_label': '5'}, page_content='8.2 建立大模型 合规标准和评测平台  ................................ ...........  96 \n8.3 应对大模型带来的安全性挑战  ................................ ...............  97 \n8.4 开展大模型广泛适配，推动大模型技术栈自主可控  ...........  98 \n名词索引  ................................ ................................ ................................ ... 99 \n参考文献  ................................ ................................ ................................ . 101'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 4, 'page_label': '5'}, page_content='参考文献  ................................ ................................ ................................ . 101  \n编写人员贡献 ................................ ................................ .........................  120'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 5, 'page_label': '6'}, page_content='5 第1章 大模型技术 概述  \n1.1 大模型技术 的发展历程  \n2006年Geoffrey Hinton 提出通过逐层无监督预训练的方式来缓\n解由于梯度消失而导致的深层网络难以训练的问题 [1]，为神经网络\n的有效学习提供了重要的优化途径 。此后，深度学习在计算机视觉\n[2]、语音 [3]、自然语言处理 [4]等众多领域取得 了突破性的研究进展，\n开启了新一轮深度学习 的发展浪潮。总结过去十多年的 技术发展，基\n于深度学习 的人工智能技术主要经历了如下的 研究范式转变 ：从早期\n的“标注数据监督学习”的任务特定模型，到“无标注数据预训练 +\n标注数据微调”的预训练模型，再到如今的 “大规模无标注数据预训\n练+指令微调 +人类对齐 ”的大模型， 经历了从小数据到大数据，从小\n模型到大模型 ，从专用到通用 的发展历程 ，人工智能技术正逐步进入\n大模型时代 。 \n2022年底，由 OpenAI发布的语言大模型 ChatGPT引发了社会\n的广泛关注。在 “大模型 +大数据 +大算力 ”的加持下， ChatGPT能够通\n过自然语言交互 完成多种任务，具备了多场景、多用途、跨学科的 任'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 5, 'page_label': '6'}, page_content='练+指令微调 +人类对齐 ”的大模型， 经历了从小数据到大数据，从小\n模型到大模型 ，从专用到通用 的发展历程 ，人工智能技术正逐步进入\n大模型时代 。 \n2022年底，由 OpenAI发布的语言大模型 ChatGPT引发了社会\n的广泛关注。在 “大模型 +大数据 +大算力 ”的加持下， ChatGPT能够通\n过自然语言交互 完成多种任务，具备了多场景、多用途、跨学科的 任\n务处理能力。 以ChatGPT 为代表的大模型技 术可以在经济、 法律、\n社会等众多领域发挥重要作用。大模型被认为很可能像 PC时代的操\n作系统一样 ，成为未来人工智能 领域的关键基础设施 ，引发了大模型\n的发展热潮。  \n本次大模型热潮主要由语言大模型（亦称为大语言模型）引领。\n语言大模型通过在海量无标注数据上进 行大规模预训练， 能够学习到\n大量的语言知识与世界知识，并且通过指令微调、人类对齐等关键技\n术拥有面向多任务的通用求解能力。在原理上， 语言大模型旨在构建\n面向文本序列的概率生成模型， 其发展过程主要 经历了四个主要阶段\n[5]：'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 6, 'page_label': '7'}, page_content='6 1）统计语言模型： 统计语言模型 主要基于马尔可夫假设建模文\n本序列的生成概率。特别地， N-gram语言模型 [6]认为下一个词汇的\n生成概率只依赖于前面出现的 N个词汇（即 N阶马尔可夫假设） 。此\n类语言模型的问题在于 容易受到数据稀疏问题的影响， 需要使用平滑\n策略改进概率分布的估计，对于文本序列的建模能力较弱 。 \n2）神经语言模 型：针对统计语言模型存在的问题，神经语言模\n型主要通过神经网络（ MLP[7]、RNN [8]）建模目标词汇与上下文词\n汇的语义共现关系， 能够有效捕获复杂的语义依 赖关系，更为精准建\n模词汇的生成概率。进一步， word2vec [4]简化了神经语言模型的网络\n架构，可以从无监督语料中学习可迁移的词表示（又称为词向量或词\n嵌入） ，为后续预训练语言模型的研究奠定了基础。  \n3） 预训练语言模型： 预训练语言模型主要是基于 “预训练 +微调”\n的学习范式构建， 首先通过自监督学习任务从无标注文本中学习可迁\n移的模型参数，进而通过有监督微调适配下游任务。早期的代表性预'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 6, 'page_label': '7'}, page_content='模词汇的生成概率。进一步， word2vec [4]简化了神经语言模型的网络\n架构，可以从无监督语料中学习可迁移的词表示（又称为词向量或词\n嵌入） ，为后续预训练语言模型的研究奠定了基础。  \n3） 预训练语言模型： 预训练语言模型主要是基于 “预训练 +微调”\n的学习范式构建， 首先通过自监督学习任务从无标注文本中学习可迁\n移的模型参数，进而通过有监督微调适配下游任务。早期的代表性预\n训练语言模型包括 ELMo [9]、GPT-1[10]和BERT [11]等。其中， ELMo\n模型基于传统的循环神经网络（ LSTM）[12]构建，存在长距离序列\n建模能力弱的问题；随着 Transformer [13]的提出，神经网络序列建模\n能力得到了显著的提升， GPT-1和BERT都是基于 Transformer 架构\n构建的，可通过微调学习解决大部分的自然语言处理任务。  \n4）语言大模型（探索阶段） ：在预训练语言模型的研发过程中，\n一个重要的经验性法则是扩展定律（ Scaling Law）[14]：随着模型参\n数规模和预训练数据规模的不断增加， 模型能力与任务效果将会随之'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 6, 'page_label': '7'}, page_content='能力得到了显著的提升， GPT-1和BERT都是基于 Transformer 架构\n构建的，可通过微调学习解决大部分的自然语言处理任务。  \n4）语言大模型（探索阶段） ：在预训练语言模型的研发过程中，\n一个重要的经验性法则是扩展定律（ Scaling Law）[14]：随着模型参\n数规模和预训练数据规模的不断增加， 模型能力与任务效果将会随之\n改善。图 1-1展示了 2018至2023年间典型预训练 模型的参数量变化\n趋势。 OpenAI在研发 GPT系列模型过程中，主要探索了 GPT-1[10]\n（1.1亿参数） 、 GPT-2（15亿参数） [15]、以及 GPT-3（1750亿参数）\n[16]三个不同参数 规模的模型，谷歌也推出了参数规模高达 5400亿\n参数的 PaLM模型 [17]。当模型参数规模达到千亿量级，语言大模型'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 7, 'page_label': '8'}, page_content='7 能够展现出多方面的能力跃升 [18]。例如， GPT-3在没有微调 的情况\n下，可以仅通过提示词或少数样例 （In-context learning ，上下文学习\n[19]）完成多种任务，甚至 在某些任务上 超过当时最好的专用模型。\n学术界引入了“语言大模型” （ Large language models ）[5]来特指这种\n超大规模的预训练语言模型，以突 出与早期预训练语言模型的不 同。 \n图1-1 2018 -2023年模型参数规模变化图  \n5）语言大模型（提升阶段） ：虽然早期的语言大模型表现出一定\n的少样本学习能力 ，但是其学习目标主要通过预测下一个单词实现，\n仍不能很好地遵循人类指令，甚至会 输出无用的、有害的信息， 难以\n有效对齐人类的偏好。 针对这些问题，主要有两种大模型改进技术，\n包括指令微调（ Instructio n Tuning）[20]以及基于人类反馈的强化学习\n(Reinforcemen t Learning from Human Feedback, RLHF) [21]。指令微调\n利用格式化（指令和回答配对）的训练数据加强大模型的通用任务泛'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 7, 'page_label': '8'}, page_content='有效对齐人类的偏好。 针对这些问题，主要有两种大模型改进技术，\n包括指令微调（ Instructio n Tuning）[20]以及基于人类反馈的强化学习\n(Reinforcemen t Learning from Human Feedback, RLHF) [21]。指令微调\n利用格式化（指令和回答配对）的训练数据加强大模型的通用任务泛\n化能力；基于人类反馈的强化学习（如图 1-2所示）将人类标注者引\n入到大模型的学习过程中，训练与人类偏好对齐的奖励模型，进而有\n效指导语言大模型的训练， 使得模型能够更好地遵循用户意图，生成\n符合用户偏好的 内容。在大模型使用过程中，可以使用各种提示技术\n（包括思维链（ Chain -of-Thoughts, CoT ）[22]、 思 维 树\n（Tree-of-Thoughts, ToT）[23]等） ，从而更好地利用大模型的潜在能'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 8, 'page_label': '9'}, page_content='8 力，提升大模型解决实际问题的能力。进一步，语言大模型主要是基\n于文本数据形式进行训练与推理，存在一些特定 能力的不足，例如数\n值计算等。针对这一问题，可以使用外部工具（ 如计算器、搜索引擎\n等）扩展大模型的能力边界 [24]。 \n \n图1-2 基于人类反馈强 化学习的算法示意图  \n 作为重要前沿探索力量， OpenAI对于语言大模型的研发工作主\n要是在 Transformer 架构推出后开展，形成了一系列的技术进展。其\n中，GPT-1探索了解码器 Transformer 架构 （ decoder -only Transfo rmer）\n在“预训练 +微调”范式下的自然语言任务求解能力； GPT-2初步验\n证了扩大模型参数规模的有效性（扩展法则） ，并且探索了基于自然\n语言提示的多任务解决能力； GPT-3首次探索了千亿参数规模的语言\n模型效果，提出了基于“上下文学习”的任务解决方法； CodeX[25]\n使用代码数据对 GPT-3进行微调，从而提升代码能力和复杂推理能\n力； InstructGPT [21]基于人类反馈的强化学习技术（ RLHF） ，能够强'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 8, 'page_label': '9'}, page_content='证了扩大模型参数规模的有效性（扩展法则） ，并且探索了基于自然\n语言提示的多任务解决能力； GPT-3首次探索了千亿参数规模的语言\n模型效果，提出了基于“上下文学习”的任务解决方法； CodeX[25]\n使用代码数据对 GPT-3进行微调，从而提升代码能力和复杂推理能\n力； InstructGPT [21]基于人类反馈的强化学习技术（ RLHF） ，能够强\n化对于人类指令的遵循能力和人类 偏好的对齐能力； ChatGP T与\nInstructGPT 的技术原理相似，进一步引入了对话数据 进行学习，从\n而加强了多轮对话能力； GPT-4[26]能够处理更长的上下文窗口 ，具\n备多模态理解能力，在逻辑推理 、复杂任务处理方面的能力得到显著'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 9, 'page_label': '10'}, page_content='9 改进，但其他相关技术细节未予披露。  \n随着 GPT-4的成功，语言大模型对于多模态领域也产生了重要影\n响，它从单调的文本交互，升级为可以接受文本与图像组合的多模态\n输入，相比传统的单模态大模型，多 模态大模型更加符合人类的多渠\n道感认知方式，能够应对更加复杂丰富的环境、场景和任务。 GPT-4\n表明在多模态大模型中引入基于人类知识的自然语言能够带来模型\n在多模态理解、生成、交互能力上的。  \n1.2 大模型技术的生态 发展  \n大模型服务平台正向个人开放及商业落 地应用延伸 ,不同公司互\n有侧重 ,为用户提供了多种获取大模型能力的 途径。 OpenAI API 较早\n地面向公众开放的大模型服务平台 ,用户可以通过 API访问不同的\nGPT模型来完成下游任务。 Claude系列模型是由 Anthropic 开发的闭\n源语言大模型， 目前包含 Claude和Claude -Instant两种模型可供选择。\n该系列模型通过无监督预训练、基于人类反馈的强化学习和\nConstitutional  AI技术（包含监督训练和强化学习）进行训练，旨在'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 9, 'page_label': '10'}, page_content='地面向公众开放的大模型服务平台 ,用户可以通过 API访问不同的\nGPT模型来完成下游任务。 Claude系列模型是由 Anthropic 开发的闭\n源语言大模型， 目前包含 Claude和Claude -Instant两种模型可供选择。\n该系列模型通过无监督预训练、基于人类反馈的强化学习和\nConstitutional  AI技术（包含监督训练和强化学习）进行训练，旨在\n改进模型的有用性、诚实性和无害性。 Claude最高支持 100K词元的\n上下文，而 Claude-2更是拓展到了 200K词元的上下文。文心一言是\n基于百度文心大模型的知识增强语言大模型，提供 APP、网页版、\nAPI接口等多种形式的开 放服务。文心一言还建设了插件机制，通过\n外部工具、服务的调用，拓展大模型的能力的边界。讯飞星火认知大\n模型具有开放式 知识问答、多轮对话、逻辑和数学能力，并且具有较\n强的对代码和多模态的理解能力。 讯飞和华为还联合重磅发布了国内\n首款支持大模型训练私有化的全国产化产品“星火一体机” ，可支持\n企业快速实现讯飞星火大模型的私有化部署、 场景赋能和专属大模型\n训练优化。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 9, 'page_label': '10'}, page_content='API接口等多种形式的开 放服务。文心一言还建设了插件机制，通过\n外部工具、服务的调用，拓展大模型的能力的边界。讯飞星火认知大\n模型具有开放式 知识问答、多轮对话、逻辑和数学能力，并且具有较\n强的对代码和多模态的理解能力。 讯飞和华为还联合重磅发布了国内\n首款支持大模型训练私有化的全国产化产品“星火一体机” ，可支持\n企业快速实现讯飞星火大模型的私有化部署、 场景赋能和专属大模型\n训练优化。  \n大模型的开源 生态也“百花 齐放” ，主要包括开源框架与开 源大\n模型。开源框架可以有效地支撑大规模模型的训练，如： PyTorch [27]'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 10, 'page_label': '11'}, page_content='10 提供了分桶梯度、通信计算重叠、跳过同步等技术 ,支持大规模的分\n布式数据并行训练； 飞桨 [28]是国产的深度学习框架 ,早在内部就支持\n了大规模分布式训练，覆盖了计算机视觉 、自然语言处理等多个领域\n的模型，其中 4D混合并行策略 ,可训练千亿规模模型； OneFlow 将分\n布式集群抽象成逻辑上的超级设备 ,支持动静态图灵活转换 ,以数据 +\n模型混合并行提升性能； DeepSpeed [29]是微软推出的大模型训练框\n架,其中 ZeRO技术减少冗余内存访问 ,使得可以训练万亿级模型。开\n源大模型可降低大模型研究的门槛，促进大模型应用的繁荣。其中典\n型代表有： LLaMA [30]系列是 Meta研发的开源大模型 ,参数规模从 7B\n到65B不等 ,仅依赖公开数据集进行预训练 ,通过数据过滤和并行优化\n实现高效训练。 Falcon [31]系列来自阿布扎比的 TII研究院 ,最大规模\n达180B参数 ,基于开源许可发布 ,性能与 GPT-4和PaLM2相当 ,参数量\n却较小。 GLM [32]系列采用空白填 充等多任务联合 训练方式 ,提升了模'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 10, 'page_label': '11'}, page_content='到65B不等 ,仅依赖公开数据集进行预训练 ,通过数据过滤和并行优化\n实现高效训练。 Falcon [31]系列来自阿布扎比的 TII研究院 ,最大规模\n达180B参数 ,基于开源许可发布 ,性能与 GPT-4和PaLM2相当 ,参数量\n却较小。 GLM [32]系列采用空白填 充等多任务联合 训练方式 ,提升了模\n型的生成能力。 Baichuan 系列模型由百川智能开发 , 支持中英双语 ,\n使用高质量训练数据 ,在多个基准测试上表现优秀，该系列模型还开\n源了多种量化版本。 Baichuan 2 在保留原有模型优势的基础上 ,增强了\n逻辑推理等方面的能力。 CPM  [33][34]系列采用经典的语言模型自回\n归训练方式 ,在各类中文 NLP任务上均表现卓越。  \n大模型技术具有广泛的应用场景， 可以用来赋能不同行业。 大模\n型+传媒可以实现智能新闻写作， 降低新闻的生产成本 ；大模型 +影视\n可以拓宽创作素材，开拓创作思路，激发创作灵感，提升作品质量；\n大模型 +营销可以打造虚拟客服，助力产品营销；大模型 +娱乐可以加'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 10, 'page_label': '11'}, page_content='逻辑推理等方面的能力。 CPM  [33][34]系列采用经典的语言模型自回\n归训练方式 ,在各类中文 NLP任务上均表现卓越。  \n大模型技术具有广泛的应用场景， 可以用来赋能不同行业。 大模\n型+传媒可以实现智能新闻写作， 降低新闻的生产成本 ；大模型 +影视\n可以拓宽创作素材，开拓创作思路，激发创作灵感，提升作品质量；\n大模型 +营销可以打造虚拟客服，助力产品营销；大模型 +娱乐可以加\n强人机互动，激发用户参与热情，增加互动的 趣味性和娱乐性；大模\n型+军事可以增强军事情报和决策能力，可以实现实时战场翻译，快\n速准确的威胁评估、 作战任务规划和执行、 战场感知、 战术决策支持、\n改进态势感知等；大模型 +教育可以赋 予教育教材新活力，让教育方\n式更个性化、更智能；大模型 +金融可以帮助金融机构降本增效，让'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 11, 'page_label': '12'}, page_content='11 金融服务更有温度 ；大模型 +医疗可以赋能医疗机构诊疗全过程。总\n之，大模型的发展将给人类带来了非常强大的助推力，让数字世界和\n现实世界的共生变得更为便 捷、更为有效。  \n大模型的通用性使其被认为是可以成为未来人工智能应用中的\n关键基础设施，就像 PC时代的操作系统一样，赋能百业，加速推进\n国民经济的高质量发展。向上，大模型可带动上游软硬件计算平台的\n革新，形成高性能软硬件与大模型的协同发展，构建 “大模型 +软硬件\n+数据资源 ”上游发展生态； 向下， 大模型可以打造 “大模型 +应用场景 ”\n的下游应用生态，加速全产业的智能升级，对经济、社会和安全等领\n域的智能化升级中形成关键支撑。  \n1.3 大模型技术的风险与挑战  \n尽管以 ChatGPT 为代表的大模型技术 取得关键性突破 ，但当前\n大模型技术仍 存在诸多风险 与挑战。  \n首先，大模型 的可靠性 无法得到 有效保障。例如，基于海量数据\n训练的语言大模型， 尽管其生成的内容符合语言规则 、通顺流畅 且与\n人类偏好对齐，但 其合成内容 在事实性、时效性方面 等仍存在较多问'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 11, 'page_label': '12'}, page_content='域的智能化升级中形成关键支撑。  \n1.3 大模型技术的风险与挑战  \n尽管以 ChatGPT 为代表的大模型技术 取得关键性突破 ，但当前\n大模型技术仍 存在诸多风险 与挑战。  \n首先，大模型 的可靠性 无法得到 有效保障。例如，基于海量数据\n训练的语言大模型， 尽管其生成的内容符合语言规则 、通顺流畅 且与\n人类偏好对齐，但 其合成内容 在事实性、时效性方面 等仍存在较多问\n题，尚无法对所合成内容做出可靠 评估 [35][36]。 \n其次，大模型的可解 释性存在不足。大模型 基于深度神经网络 ，\n为黑盒模型，其 工作机理仍难以理解。语言 大模型的涌现能力 [18]、\n规模定律 [14]，多模态大模型的 知识表示、逻辑推理能力、泛化能力、\n情景学习能力 [19][37]等方面有待展开深入 研究，为大模型的大规模\n实际应用提供理论保障。  \n再次，大模型 应用部署代价高。 大模型参数规模和数据规模都非\n常巨大， 存在训练和推理计算量大、功耗高、应用成本高 、端侧推理\n存在延迟 等问题，从而限制了其 落地应用。提高推理速度降低大模型\n使用成本是大规模应用的关键。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 11, 'page_label': '12'}, page_content='情景学习能力 [19][37]等方面有待展开深入 研究，为大模型的大规模\n实际应用提供理论保障。  \n再次，大模型 应用部署代价高。 大模型参数规模和数据规模都非\n常巨大， 存在训练和推理计算量大、功耗高、应用成本高 、端侧推理\n存在延迟 等问题，从而限制了其 落地应用。提高推理速度降低大模型\n使用成本是大规模应用的关键。  \n此外，大模型在小数据情景下的迁移能力存在不足。 大模型基于'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 12, 'page_label': '13'}, page_content='12 数据驱动深度学习方式，依赖训练数据所覆盖的场景，由于复杂场景\n数据不足，大模型存在特定场景适用性不足的问题，面临鲁棒性和泛\n化性等挑战。 提升大模型对小数据的高效适配迁移能力是未来研究的\n重点。  \n最后，大模型还 存在伴生技术风险 问题。例如，语言 大模型具有\n通用的自然语言理解和生成能力， 其与语音合成、图像视频生成等技\n术结合可以产生人类难以辨别的音视频 等逼真多媒体 内容， 可能 会被\n滥用于制造虚假信息、恶意引导行为 ，诱发舆论攻击、甚至危害国家\n安全 [38][39]。此外，大模型存在安全 与隐私问题 ，目前针对大模型\n安全漏洞 的典型攻击方式包括：数据投毒攻击、对抗样本攻击、模型\n窃取攻击、后门攻击 、指令攻击 。大模型的安全漏洞 可能被攻击者利\n用，使得大模型关联业务面临整体失效的风险 ，威胁以其为基础构建\n的应用生态。大模型利用 海量的互联网数据进行训练， 包括个人、企\n业甚至国家的 敏感数据可能被编码进大模型参数中， 因 而存在数据隐\n私问题。例如，通过 提示信息可能诱发大模型隐私数据泄露问题。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 13, 'page_label': '14'}, page_content='13 第2章 语言大模型技术  \n近年来，在 Transformer 架构基础上构建的预训练语言模型为自\n然语言处理领域带来了一系列 突破式进展， 成为人工智能主流技术范\n式。预训练语言模型采用“预训练 +微调”方法，主要分为两步： 1）\n将模型在大规模无标注数据上进行自监督训练得到预训练模型， 2）\n将模型在下游各种自然语言处理任务上的小规模有标 注数据进行微\n调得到适配模型。由于预训练语言模型参数越大模型表现越好，这激\n发了语言大模型（ Large Language Model , LLM）研究热潮。  \n2.1 Transformer 架构  \nTransformer 架构 [13]是目前语言大模型 采用的主流架构 [5]，其基\n于自注意力机制 (Self -attention Mechanism) 模型。 其主要思想是通过自\n注意力机制获取输入序列的全局信息， 并将这些信息通过网络层进行\n传递。标准的 Transformer 如图 2-1所示，是一个编码器 -解码器架构，\n其编码器和解码器均由一个编码层和若干相同的 Transformer 模块层'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 13, 'page_label': '14'}, page_content='于自注意力机制 (Self -attention Mechanism) 模型。 其主要思想是通过自\n注意力机制获取输入序列的全局信息， 并将这些信息通过网络层进行\n传递。标准的 Transformer 如图 2-1所示，是一个编码器 -解码器架构，\n其编码器和解码器均由一个编码层和若干相同的 Transformer 模块层\n堆叠组成，编码器的 Transformer 模块层包括多头注意力层和全连接\n前馈网络层，这两部分通过残差连接和层归一化操作连接起来。与编\n码器模块相比， 解码器由于需要考虑解码器输出作为背景信息进行生\n成，其中每个 Transformer层多了一个交叉注意力层。相比于传统循\n环神经网络（ Recurrent  Neural Network, RNN ）和长短时记忆神经网\n络（Long Short -Term Memory Network , LSTM），Transformer 架构的\n优势在于它的并行计算能 力，即不需要按照时间步顺序地进行计算。  \nTransformer 架构包含编码层与 Transformer模块两个核心组件，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 13, 'page_label': '14'}, page_content='环神经网络（ Recurrent  Neural Network, RNN ）和长短时记忆神经网\n络（Long Short -Term Memory Network , LSTM），Transformer 架构的\n优势在于它的并行计算能 力，即不需要按照时间步顺序地进行计算。  \nTransformer 架构包含编码层与 Transformer模块两个核心组件，  \n编码层， 主要是将输入词序 列映射到连续值向量空间进行编码，\n每个词编码由词嵌入和位置编码构成，由二者加和得到：  \n1）词嵌入，在 Transformer 架构中，词嵌入是输入数据的第一步\n处理过程 ，它将词映射到高维空间中的向量 ，可以捕获词汇的语义信\n息，如词义和语法关系。每个词都被转化为一个固定长度的向量，然'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 14, 'page_label': '15'}, page_content='14 后被送入模型进行处理。  \n \n图2-1 Transformer 架构 [13] \n2）位置编码，由于自注意力机制本身对位置信息不敏感，为了\n让模型能够理解序列中的顺序信息，引入了位置编码。 标准\nTransformer 架构的位置编码方式是使用正弦和余弦函数的方法。对\n于每个位置 i，对应的位置编码是一个长度为 d的向量，其中 d是模\n型的嵌入维度。这个向量的第 j个元素由以下公式计算：如果  j 是偶  \n数，那么编码的第 j个元素为\n/sin( /10000 )jdi ; 如果  j 是奇数，那么编\n码的第 j个元素为\n/cos( /10000 )jdi 。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 15, 'page_label': '16'}, page_content='15 \n \n图2-2 Transformer 自注意力网络 [13] \nTransformer 模块，通过自注意力机制获取输入序列的全局信息，\n并将这些信息通过网络层进行传递 ，包括多头注意力层和全连接前馈\n网络层，这两部分通过残差连接和层归一化操作连接起来 ，\nTransformer 模块，由 自注意力层、全连接前馈层、残差连接和层归\n一化操作等基本单元组成：  \n1）自注意力层 ，注意力（ Attention ）是 Transformer 模型的核心\n组成部分。它包含一个查询矩阵\nkndQ\uf0b4\uf0ce\n ，一个键矩阵\nkmdK\uf0b4\uf0ce\n 和一\n个值矩阵\nvmdV\uf0b4\uf0ce\n ，其中矩阵中的每一行对应一个词。注意力机制的\n计算方式：  \nAttention( , , ) Softmax( )T\nkQKH Q K V V\nd==\n  \n直观来说，矩阵\nvndH\uf0b4\uf0ce\n 中的每一行是\nV 中行向量的加权和，其\n中权重由查询向量和键矩阵的点积决定。 记具有序列长度 n的查询序\n列的特征矩阵和具有序列长度 为m的键 -值序列的特征矩阵分别为\nnd\nqX\uf0b4\uf0ce\n和\nmd\nkvX\uf0b4\uf0ce\n ，三个矩阵\nQ 、\nK、'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 15, 'page_label': '16'}, page_content='计算方式：  \nAttention( , , ) Softmax( )T\nkQKH Q K V V\nd==\n  \n直观来说，矩阵\nvndH\uf0b4\uf0ce\n 中的每一行是\nV 中行向量的加权和，其\n中权重由查询向量和键矩阵的点积决定。 记具有序列长度 n的查询序\n列的特征矩阵和具有序列长度 为m的键 -值序列的特征矩阵分别为\nnd\nqX\uf0b4\uf0ce\n和\nmd\nkvX\uf0b4\uf0ce\n ，三个矩阵\nQ 、\nK、\nV由三个线性变换得到\n, , .q q kv k kv v Q X W K X W V X W= = =\n Transformer 模型采用的特定注意力机制\n被称为自注意力机制，因为三个矩阵\nQ 、\nK、\nV都来自于前一层的相'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 16, 'page_label': '17'}, page_content='16 同特征矩阵\nndX\uf0b4\uf0ce\n 。 \n此外， Transformer 采用了多头自注意力（ Multi -head Attention ）\n机制，即输入序列被线性映射多次得到不同的投影矩阵。多个尺度化\n后点积注意力可以并行计算，并产生多个 自注意力输出。多头注意力\n生成多个高维的注意力表示， 这使得其比单头注意力具有更强的表达\n能力。多头注意力的计算方式如下：使用了多个查询矩阵\n()iQ ，键矩\n阵\n()iK和值矩阵\n()iV ，最终输出为\nvoddH\uf0b4\uf0ce\n ，它是通过将一系列\niH 进行\n拼接， 并使用一个新的权重矩阵\nvodd\noW\uf0b4\uf0ce\n 将其投影到一个新的特征空\n间中获得的 : \n1 MultiHead( , , ) Concat( , , )ho H Q K V H H W==\n, \n( ) ( ) ( ) ( ) ( ) ( )Attention( , , ) Attention( , , ),i i i i i i\ni q q kv k kv vH Q K V X W X W X W=='), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 16, 'page_label': '17'}, page_content='vodd\noW\uf0b4\uf0ce\n 将其投影到一个新的特征空\n间中获得的 : \n1 MultiHead( , , ) Concat( , , )ho H Q K V H H W==\n, \n( ) ( ) ( ) ( ) ( ) ( )Attention( , , ) Attention( , , ),i i i i i i\ni q q kv k kv vH Q K V X W X W X W==\n \n对于解码器， Transformer 层在 Attention 的Softmax之前引入了\n一个额外的掩码（ MASK）操作，防止查询矩阵\nQ 去对序列中尚未解\n码的后续位置来施加注意力操作。此外，在自注意层之后还有一个额\n外的 “交叉注意力 ”层，其中查询矩阵\nQ 是从解码器中前一层的输出中\n派生出来的 ，而键矩阵\nK 和值矩阵\nV 是从编码器的最后一层的输出中\n转换而来的。这种设计的主要目的是为了让 Transformer 在解码时避\n免看到真实标签，并且同时 处理来自编码器的信息。  \n2）全连接前馈层 ，在注意力层之后的全连接前馈层由两个线性\n变换和一个非线性激活函数组成。将输入矩阵表示为'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 16, 'page_label': '17'}, page_content='外的 “交叉注意力 ”层，其中查询矩阵\nQ 是从解码器中前一层的输出中\n派生出来的 ，而键矩阵\nK 和值矩阵\nV 是从编码器的最后一层的输出中\n转换而来的。这种设计的主要目的是为了让 Transformer 在解码时避\n免看到真实标签，并且同时 处理来自编码器的信息。  \n2）全连接前馈层 ，在注意力层之后的全连接前馈层由两个线性\n变换和一个非线性激活函数组成。将输入矩阵表示为\niddX\uf0b4\uf0ce\n ，前馈\n层的输出  \n1 1 2 2 FFN( ) ( ) X XW b W b\uf073= + +\n \n其中，\n()\uf073\uf0d7 是激活函数（通常为 ReLU或GELU） ，而\n1ifddW\uf0b4\uf0ce\n ，\n1fdb\uf0ce\n，\n2foddW\uf0b4\uf0ce\n ，\n2odb\uf0ce\n 均为可学习的参数。在实践中，\nid 通常设\n置为\nod，\nfd设置为\nid的4倍。 FFN作用包括两个方面： （ 1）非线性激\n活：在每个注意力模块之后引 入了非线性激活函数\n()\uf073\uf0d7 ，这有助于增\n强模型的 表达能力； （ 2）信息整合：自注意力机制允许模型在不同的'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 17, 'page_label': '18'}, page_content='17 位置间建立联系， 而全连接前馈网络则在每个位置独立地对信息进 行\n整合，这两者结合起来，使得模型既能捕获全局（长距离）的信息，\n又能在每个位置进行局部的信息整合。  \n3）残差连接和层归一化 ，在每个注意力层和每个全连接前馈层\n之后， Transformer 都应用残差连接（ Residual Connection ）和层归 一\n化（ Layer Normalization ）技术，这有助于在模型非常深时保留信息\n并确保模型性能。具体来说，对于 某一层神经网络\n()f\uf0d7 ，残差连接和\n归一化层定义 为\nLayerNorm( ( )) X f X+ 。 \n在Transformer 模型被提出之后，它也衍生出了相当一部分的变\n体，包括在编码器和解码器中 出现了不同方式的注意力机制 、归一化\n操作、残差连接 、前馈层和位置编码等。  \n \n2.2 语言大模型架构  \n现有的语言大模型几乎全部是 以 Transformer 模型作为基础架\n构来构建的，不过它们在所采用的具体结构上通常存在差异 ，如只使\n用 Transformer 编码器或解码器，或者同时使用两者。从建模策略的'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 17, 'page_label': '18'}, page_content='体，包括在编码器和解码器中 出现了不同方式的注意力机制 、归一化\n操作、残差连接 、前馈层和位置编码等。  \n \n2.2 语言大模型架构  \n现有的语言大模型几乎全部是 以 Transformer 模型作为基础架\n构来构建的，不过它们在所采用的具体结构上通常存在差异 ，如只使\n用 Transformer 编码器或解码器，或者同时使用两者。从建模策略的\n角度，语言大模型架构大致可以分为三类  [36]： \n \n图2-3 语言大模型的三种典型架构 [36] \n2.2.1 掩码语言建模  \n掩码语言建模（ Masked Language Modeling, MLM ）是基于  \nTransformer 编码器的双向模型，其中  BERT [11]和 RoBERTa [41]是\n其中典型代表 。这类模型通过掩码语言建模任务进行预训练， BERT'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 18, 'page_label': '19'}, page_content='18 中还加入了下一句预测（ Next Sentence Prediction, NSP ）任务。在预\n训练时，模型的输入是自然语言序列。首先在原始输入中添加特殊标\n记 [CLS] 和 [SEP]，并且随机用 [MASK] 标记替换原始序列中的字\n符。 掩码语言建模旨在根据上下文来最大化  [MASK]位置的标签字符\n的条件概率，即让模型执行 “完型填空 ”任务。而  [CLS] 的最终表示\n被用于预测两个句子是否连贯。 RoBERTa 与 BERT 基本相同，但是\n它删去了下一句预测任务，采用了更具鲁棒性的动态掩码机制，并使\n用更大的批次、 更长的时间和更多的数据进行训练。  \n2.2.2 自回归语言建模  \n自回归语言模型在训练时通过学习预测序列中的下一个词来建\n模语言，其主要是通过 Transformer 解码器来实现。 自回归语言模型\n的优化目标为最大化对序列中每个位置的下一个词的条件概率 的预\n测。代表性模型，包括 OpenAI的GPT系列模型 [16][26]、Meta的\nLLaMA系列模型 [30]和Google的PaLM系列模型 [17]。其中， GPT-3'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 18, 'page_label': '19'}, page_content='自回归语言模型在训练时通过学习预测序列中的下一个词来建\n模语言，其主要是通过 Transformer 解码器来实现。 自回归语言模型\n的优化目标为最大化对序列中每个位置的下一个词的条件概率 的预\n测。代表性模型，包括 OpenAI的GPT系列模型 [16][26]、Meta的\nLLaMA系列模型 [30]和Google的PaLM系列模型 [17]。其中， GPT-3 \n[16]是首个将模型参数扩增到 千亿参数规模的预训练模型。 自回归语\n言模型更加适用于生成任务，同时也更适用于对模型进行规模扩增。  \n2.2.3 序列到序列建模  \n序列到序列模型是建立在完整 Transfo rmer架构上的序列到序列\n模型，即同时使用编码器 -解码器结构，代表性模型包 括T5[42]和\nBART [43]。这两个模型都采用文本片段级别的掩码语言模型作为主\n要的预训练任务，即随机用单个  [MASK] 特殊标记替换文本中任意\n长度的一段字符序列，并要求模型 生成填充原始的字符。 序列到序列\n模型可以形式化地表示为最大化在给定掩码的字符序列的情况下目\n标字符序列的概率。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 18, 'page_label': '19'}, page_content='模型，即同时使用编码器 -解码器结构，代表性模型包 括T5[42]和\nBART [43]。这两个模型都采用文本片段级别的掩码语言模型作为主\n要的预训练任务，即随机用单个  [MASK] 特殊标记替换文本中任意\n长度的一段字符序列，并要求模型 生成填充原始的字符。 序列到序列\n模型可以形式化地表示为最大化在给定掩码的字符序列的情况下目\n标字符序列的概率。  \n总体而言， 自回归语言模型较其 它预训练语言模型架构展现了更\n优异的情境学习、思维链推理、内容创造等能力， 自回归模型架构 是\n当前大模型的主流架构 [5]。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 19, 'page_label': '20'}, page_content='19 2.3 语言大模型关键技术  \n语言大模型技术主要包括模型预训练、适配微调、提示学习、知\n识增强和工具学习等。  \n2.3.1 语言大模型的预训练  \n支撑语言大模型高效训练的技术主要包括 高性能训练工具 、 高效\n预训练策略、高质量训练数据、高效的模型架构等，其中 高性能训练\n工具和高质量训练数据分别见第 5章和第 4章。 \n高效预训练 策略。其主要思路是采用不同的策略 以更低成本 实现\n对语言大模型的 预训练。一种是在预训练中 设计高效的优化任务目\n标，使得可以使得模型能够利用每个样本更多的监督信息，从而实现\n模型训练的加速。第二 种是热启动策略 ，在训练开始时线性地提高学\n习率， 以解决在预训练中单纯增加批处理大小可能会导致优化困难问\n题。第三 种是渐进式训练策略 ，不同于传统的训练范式使用相同的超\n参数同时优化模型每一层， 该方法认为不同的层可以共享相似的自注\n意力模式，首先训练浅层 模型，然后复制构建深层模型。第四 种是知\n识继承方法 ， 即在模型训练中同时学习文本和已经预训练 语言大模型\n中的知识，以加速模型训练。在中文语言 大模型 CPM -2[34]中，采用'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 19, 'page_label': '20'}, page_content='题。第三 种是渐进式训练策略 ，不同于传统的训练范式使用相同的超\n参数同时优化模型每一层， 该方法认为不同的层可以共享相似的自注\n意力模式，首先训练浅层 模型，然后复制构建深层模型。第四 种是知\n识继承方法 ， 即在模型训练中同时学习文本和已经预训练 语言大模型\n中的知识，以加速模型训练。在中文语言 大模型 CPM -2[34]中，采用\n知识继承技术经测试可以使大模型在预训练前期提速 37.5%。第五种\n是可预测扩展策略 （Predictable Scaling ）[26]，旨在大模型训练初期，\n利用大模型和小模型的同源性关系， 通过拟合系列较小模型的性能曲\n线预测大模型性能，指导大模型训练优化。 OpenAI在GPT-4训练中，\n使用 1000倍至 10000倍较少计算资源训练的小模型可 靠地预测\nGPT-4某些性能 ，大幅降低了模型训练成本。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 20, 'page_label': '21'}, page_content='20 \n \n图2-4  GPT -4的可预测扩展实验 [26] \n高效的模型架构。 BERT之后的 Transformer 架构在提高自然语\n言处理效率方面有两个重要优化方向： （ 1）统一的序列建模 ，旨在将\n多种自然语言处理任务（如分类、信息抽取、翻译、对话等）整合到\n一个统一的框架，然后在同一模型中执行多个任务，以实现更高效 的\n自然语言处理。该方法可以充分利用大规模训练数据，从而提高了模\n型在多个任务上的性能和泛化性。 这减少了开发和维护多个单独模型\n的复杂性以及资源消耗，提高模型的通用性。统一任务序列建模有 两\n种方式：一是转化为序列生成的统一任务，如 T5[42]和BART [43]等\n将多种自然语言任务统一转化文本到文本的生成任务； 二是转化为语\n言大模型预训练任务， 通过语言提示在输入文本中插入人类设计或者\n自动生成的上下文，实现对不同任务的处理。 （ 2）计算高效的模型架\n构。从 Transformer 模型架构本身在处理训练复杂度、编解码效率、\n训练稳定性、显存利用等 方面进行优化。比如， Transformer 其并行'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 20, 'page_label': '21'}, page_content='将多种自然语言任务统一转化文本到文本的生成任务； 二是转化为语\n言大模型预训练任务， 通过语言提示在输入文本中插入人类设计或者\n自动生成的上下文，实现对不同任务的处理。 （ 2）计算高效的模型架\n构。从 Transformer 模型架构本身在处理训练复杂度、编解码效率、\n训练稳定性、显存利用等 方面进行优化。比如， Transformer 其并行\n处理机制是以低效推理为代价的，解码时每个步骤 的复杂度为 O(N)，\nTransformer 模型也是显存密集型模型，输入序列越长、占用的内存\n越多。为此，微软设计了一种新的 Transformer 架构 RetNet [44]，其\n采用线性化注意力 +尺度保持（ Retention ）机制，在基本保持 模型性\n能的基础上同时实现模型训练速度、推断速度和内存节约的大幅提\n升。针对自注意力显存消耗大，斯坦福大学在 Transformer 中引入\nFashAttention [45]，给出了一种具有 IO感知，且兼具快速、内存高效'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 21, 'page_label': '22'}, page_content='21 的注意力算法， 已经被各种主流大模型采用 以扩展对超长文本输入的\n支持。最近，模块化大模型架构引起广泛关注，其利用大模型的神经\n激活稀疏性，对稠密模型进行模块化划分，不同任务只经过部分模块\n计算实现训练和推理加速，典型工作包括 Google的Switch \nTransformers [46]和Pathways [47]架构、清华大学的 MoEfication 架构\n[48]、FastMoE 架构 [49]等。   \n \n图2-5 混合专家化的模型架构 [49] \n2.3.2 语言大模型的适配微调  \n       语言大模型由于在大规模通用领域数据预训练通常缺乏对特\n定任务或领域的知识，因此需要适配微调。微调可以帮助模型更好地\n适应特定需求，如对敏感数据（如医疗记录）的处理，同时不暴露原\n始数据。此外，微调可以提高部署效率、减少计算资源需求。指令微\n调和参数高效学习是适配微调的关键技术。  \n指令微调  (Instruction Tu ning)[21]，是一种可以帮助 语言大模型\n实现人类语言指令遵循的能力， 在零样本设置中泛化到未见任务上的'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 21, 'page_label': '22'}, page_content='定任务或领域的知识，因此需要适配微调。微调可以帮助模型更好地\n适应特定需求，如对敏感数据（如医疗记录）的处理，同时不暴露原\n始数据。此外，微调可以提高部署效率、减少计算资源需求。指令微\n调和参数高效学习是适配微调的关键技术。  \n指令微调  (Instruction Tu ning)[21]，是一种可以帮助 语言大模型\n实现人类语言指令遵循的能力， 在零样本设置中泛化到未见任务上的\n学习方法。指令微调学习形式与多任务提示微调相似，但与提示微调\n让提示适应 语言大模型 并且让下游任务对齐预训练任务不同， 其是让\n语言大模型 对齐理解人类指令并按照指令要求完成任务 ，即在给定指\n令提示的情况 下给出特定的回应， 其 中提示可以选择性包含一条解释'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 22, 'page_label': '23'}, page_content='22 任务的指令。 指令微调研究涉及 指令理解、指令数据获取 和指令对齐\n等内容。  \n（1）指令理解 ，指语言大模型 准确理解人类语言指令的能 力，\n是语言大模型 执行指令完成任务的前提。为了增强对指令的理解，许\n多工作采用多 任务提示方式对基于指令描述的大量任务集上对 语言\n大模型进行微调，如 FLAN [50]、InstructGPT [21]等，这些模型在未见\n的任务上显示出优越的零样本性能。  \n（2）指令数据获取 , 指如何构建包含多样性的任务指令数据。\n指令数据构建常见有三种方式： i）基于公开人工标注数据构建，代\n表指令数据集包括 1616种不同任务的 Super -Natu ral Instruction [51]、\n2000 种不同 NLP任务的 OPT-IML[52]。ii）借助语言大模型 的自动\n生成构建，如 Unnatural Instructions [53]，通过种子指令作为提示让 语\n言大模型 生成新的指令描述和问题，然后再输入到模型让其输出回\n答。iii）基于人工标注方法，如 ChatGPT 在人工标注指令的基础上通'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 22, 'page_label': '23'}, page_content='2000 种不同 NLP任务的 OPT-IML[52]。ii）借助语言大模型 的自动\n生成构建，如 Unnatural Instructions [53]，通过种子指令作为提示让 语\n言大模型 生成新的指令描述和问题，然后再输入到模型让其输出回\n答。iii）基于人工标注方法，如 ChatGPT 在人工标注指令的基础上通\n过GPT-3、InstructGPT 等在线平台收集用户真实指令数 据。  \n（3）指令对齐 ,  语言大模型在多种自然语言处理任务上都展现\n了卓越的性能。然而，它们有时可能会出现不预期的行为，如创造虚\n假信息、追求错误目标或产生有偏见的内容 [5]。其根本原因在于，\n语言大模型在预训练时仅通过语言模型建模， 未涉及人类的价值观或\n偏好。为了解决 这一问题，研究者提出了“指令对齐” ，使语言大模\n型的输出更符合人类的预期。但这种对齐 与原始预训练有所不同 ，更\n注重于有用性、诚 实性和无害性。此外，指令对齐可能会降低语言大\n模型的某些通用能力，这被称为“ Alignment Tax ” 。为实现模型输出'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 22, 'page_label': '23'}, page_content='语言大模型在预训练时仅通过语言模型建模， 未涉及人类的价值观或\n偏好。为了解决 这一问题，研究者提出了“指令对齐” ，使语言大模\n型的输出更符合人类的预期。但这种对齐 与原始预训练有所不同 ，更\n注重于有用性、诚 实性和无害性。此外，指令对齐可能会降低语言大\n模型的某些通用能力，这被称为“ Alignment Tax ” 。为实现模型输出\n与对人类价值的对齐， InstructGPT 提出了一种基于人类反馈的微调\n方法， 利用了强化学习技术， 将人类反馈纳入模型微调过程。 实际上，\nChatGPT 也采用了与 InstructGPT 相似的技术，以确保产生高质量且\n无害的输出。指令对 齐的广泛应用，适配微调从纯数据学习的传统微'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 23, 'page_label': '24'}, page_content='23 调范式开始逐步向人类学习范式的转变。  \n参数高效微调 （Parameter -Efficient Tuning ）。早期以 BERT为代\n表的微调方法 ，是在大模型基座上增加一个任务适配层 ，然后进行全\n参微调，但是这种方法存在两方面的问题 ：一是任务 “鸿沟 ”问题，预\n训练和微调之间的任务形式不一致， 这种差别会显著影响知识迁移的\n效能。二是高计算成本， 语言大模型 的参数规模不断增长，导致模型\n全参微调也需要大量计算资源。 解决以上问题的有效途径是参数 高效\n学习， 即通过仅微调少量参数实现大模型在下游任务上获得全参微调\n效果。目前 许多参数高效微调方法被提出，这些方法大致可分为 3类\n[40]：（1）添加式方法 ：旨在原模型基础上引入额外的模块或参数，\n并仅微调该引入部分的参数。如适配器（ Adapter）方法，旨将小规\n模的神经模块（适配器）注入到预训练模型中，并只调整这些适配器\n以进行模型自适应。在实际应用中，适配器模块通常分别插入在多头\n自注意和前馈网络子层之后， 成为最广泛使用方式 ；（2）指定式方法 ：'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 23, 'page_label': '24'}, page_content='[40]：（1）添加式方法 ：旨在原模型基础上引入额外的模块或参数，\n并仅微调该引入部分的参数。如适配器（ Adapter）方法，旨将小规\n模的神经模块（适配器）注入到预训练模型中，并只调整这些适配器\n以进行模型自适应。在实际应用中，适配器模块通常分别插入在多头\n自注意和前馈网络子层之后， 成为最广泛使用方式 ；（2）指定式方法 ：\n旨在原模型指定模型中部分参数为可训练参数，并固定模型其他参\n数。这类方法简单也十分有效， 如仅通过优化模型内的偏置项并固定\n其他参数，模型仍然可以再现 95%以上的模型全参微调性能 ；（3）重\n参数化方法： 将原模型或部分模型参数重 参数化到低维度参数空间\n中，仅仅优化低维空间中的近似参数，显著降低模型的计算量和内存\n消耗。如LoRA [54]，将模型自注意力模块的变化权重参数分解为两\n个低秩矩阵相乘 ，即\n00 down up W W W W W W= +\uf044 = +  。 \n \n图2-6 参数高效微调的 3种范式 [40]'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 24, 'page_label': '25'}, page_content='24 参数高效微调 通常具有微调参数规模小、增量式微调参数、即插\n即用等特点，这种技术 也统一成技术框架 Delta  Tunin g[40]。一些围\n绕参数高效微 调的开源工具也被研发，代表性包括 OpenPrompt [55]、\nOpenDelta [56]等。由于不同任务的微调参数可以被重复利用，一些关\n于高效微调的仓库也被构建， 如Adapt erHub [57]、Delta Center [40]等。\n随着语言大模型 的兴起，高效微调吸引了越来越多的关注，以开发一\n种更轻量级的下游任务适 配方法。特别地， LoRA [54]已广泛应用于\n各种开源语言大模型 （如 LLaMA）以实现参数高效微调。  \n2.3.3 语言大模型的提示学习  \n通过大规模文本数据预训练之后的语言大模型具备 了作为通用\n任务求解器的潜在能力 ， 但这些能力在 执行一些特定任务时可能不会\n显式地展示出来。 在大模型输入中 设计合适的 语言指令提示有助于 激\n发这些能力 ，该技术称为模型 提示技术。代表性的提示技术有指令提\n示和思维链提示：'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 24, 'page_label': '25'}, page_content='各种开源语言大模型 （如 LLaMA）以实现参数高效微调。  \n2.3.3 语言大模型的提示学习  \n通过大规模文本数据预训练之后的语言大模型具备 了作为通用\n任务求解器的潜在能力 ， 但这些能力在 执行一些特定任务时可能不会\n显式地展示出来。 在大模型输入中 设计合适的 语言指令提示有助于 激\n发这些能力 ，该技术称为模型 提示技术。代表性的提示技术有指令提\n示和思维链提示：  \n指令提示（ Instruction Prompt ），也称为提示学习 。OpenAI在\nGPT-3 [16]中首次提出上下文提示，并发现 GPT-3在少样本提示下能\n够达到人类水平，证明在低资源场景下非常有效，引起广泛关注。指\n令提示核心思想是避免强制语言大模型适应下游任务， 而是通过提供\n“提示（ Prompt） ”来给数据嵌入额外的上下文以重新组织下游任务，\n使之看起来更像是在语言大模型预训练过程中解决的问题 [10]。指令\n提示有三种形式： （ 1）少样本提示 ，是指在一个自然语言提示后面附\n加一些示例数据，作为语言大模型的输入。其可以提高语言大模型在'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 24, 'page_label': '25'}, page_content='够达到人类水平，证明在低资源场景下非常有效，引起广泛关注。指\n令提示核心思想是避免强制语言大模型适应下游任务， 而是通过提供\n“提示（ Prompt） ”来给数据嵌入额外的上下文以重新组织下游任务，\n使之看起来更像是在语言大模型预训练过程中解决的问题 [10]。指令\n提示有三种形式： （ 1）少样本提示 ，是指在一个自然语言提示后面附\n加一些示例数据，作为语言大模型的输入。其可以提高语言大模型在\n不同领域和任务上的适应性和稳定性。少样本提示也存在一些挑战，\n例如如何确定合适的示例数量、如何选择示例等。 （ 2）零样本提示 ，\n是指不使用任何示例数据， 只依靠一个精心设计的提示来激活语言大\n模型中与目标任务相关的知识和能力。 零样本提示关键问题包括如何\n设计合适的提示、 如何选择最优的提示等。 （ 3）上下文学习 （ In-context'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 25, 'page_label': '26'}, page_content='25 Learni ng, ICL），也称情境学习 ，是指将一个自然语言问题作为语言\n大模型的输入，并将其答案作为输出 [16]。情境学习可以看作是一种\n特殊形式的少样本提示，在问题中隐含地包含了目标任务和格式信\n息。情境学习可以简化问题表示和答案生成，并且可以灵活地处理多\n种类型和复杂度的问题。其挑战在于，如何确保问题质量、如何评估\n答案正确性等。  \n \n图2-7 几种提示样例对比  \n思维链（ Chain -of-Thought，CoT）[58]。推理的过程通常涉及\n多个推论步骤，通过多步推理允许产生可验证的输出，可以提高黑盒\n模型的可解释性。思维链是一种提示技术，已被广泛用于激发语言大\n模型的多步推理能 力，被鼓励语言大模型生成解决问题的中间推理\n链，类似于人类使用深思熟虑的过程来执行复杂的任务。在思维链提\n示中，中间自然语言推理步骤的例子取代了少样本提示中的〈输入，\n输出〉对，形成了〈输入，思维链，输出〉三元组结构。思维链被认\n为是语言大模型的“涌现能力” ，通常只有模型参数规模增大到一定\n程度后， 才具有采用思维链能力。 激活语言大模型的思维链能力方法，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 25, 'page_label': '26'}, page_content='模型的多步推理能 力，被鼓励语言大模型生成解决问题的中间推理\n链，类似于人类使用深思熟虑的过程来执行复杂的任务。在思维链提\n示中，中间自然语言推理步骤的例子取代了少样本提示中的〈输入，\n输出〉对，形成了〈输入，思维链，输出〉三元组结构。思维链被认\n为是语言大模型的“涌现能力” ，通常只有模型参数规模增大到一定\n程度后， 才具有采用思维链能力。 激活语言大模型的思维链能力方法，\n在提示中给出逐步的推理演示作为推理的条件， 每个演示都包含一个\n问题和一个通向最终答案的推理链（图 2-7）。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 26, 'page_label': '27'}, page_content='26 2.3.4 语言大模型的知识增强  \n知识运用和推理能力是衡量语言大模型智能水平的重要因素。 美\n国Allen AI研究大模型的问答能力， 发现 GPT-3在处理具有预设立场\n（false premise ）的简单性常识性问题时，如类似 “太阳有几只眼\n睛？ ”，GPT-3仍然会给出 “太阳两只眼睛 ”的荒谬回复。有效的解决\n方法是在深度学习模型基础上融入各类型相关外部知识。 根据大模型\n知识融合部位不同， 知识融合方法从模型输入、 神经架构、 模型参 数、\n输出等不同层面，大致分为以下 4类[59]，如图 2-8所示：  \n \n图2-8 语言大模型知识增强的 4种途径  \n知识增广 ：从输入端增强模型，有两种主流的方法：一种方式是\n直接把知识加到输入， 另一方法是设计特定模块来融合原输入和相关\n的知识化的输入表示。  \n知识支撑 ：关注于对带有知识的模型本身的处理流程进行优化。\n一种方式是在模型的底部引入知识指导层来处理特征， 以便能得到更\n丰富的特征信息。例如 ，使用专门的知识记忆模块来从大模型底部注\n入丰富的记忆特征。另一方 面，知识也可以作为专家在模型顶层构建'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 26, 'page_label': '27'}, page_content='直接把知识加到输入， 另一方法是设计特定模块来融合原输入和相关\n的知识化的输入表示。  \n知识支撑 ：关注于对带有知识的模型本身的处理流程进行优化。\n一种方式是在模型的底部引入知识指导层来处理特征， 以便能得到更\n丰富的特征信息。例如 ，使用专门的知识记忆模块来从大模型底部注\n入丰富的记忆特征。另一方 面，知识也可以作为专家在模型顶层构建\n后处理模块，以计算得到更准确和有效的输出。  \n知识约束 ：利用知识构建额外的预测目标和约束函数，来增强模'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 27, 'page_label': '28'}, page_content='27 型的原始目标函数。例如，远程监督学习利用知识图谱启发式标注语\n料作为新的目标，并广泛用于实体识别、关系抽取等系列 NLP任务。\n或者利用知识构建额外的预测目标， 在原始语言建模之外构建了相应\n额外的预训练目标。  \n知识迁移： 模型知识作为重要的知识来源，也可以直 接用于下游\n任务，例如初始化模型参数。 迁移学习和自监督学习都是知识迁移的\n重要研究方向。目前，知识迁移技术已被广泛应用于自然 语言处理，\n以BERT为首的各种预训练模型是现在知识迁移的主要方法。  \n2.4.5 语言大模型的工具学习  \n语言大模型具备理 解、推理和决策能力，可与外部工具互动。在\n特定领域任务中，如金融领域的证券交易和市场预测，语言大模型通\n常需要结合外部工具获取信息和技能才能处理。 整合外部工具与语言\n大模型可以发挥各自优势实现复杂任务的处理， 其中外部工具可增强\n专业知识和可解释性，语言大模型提供语义理解和推理规划能力。  \n2021年底， OpenAI推出 WebGPT [60]，利用 GPT-3与网页浏览\n器和搜索引擎交互获取互联网信息在长文本问答上实现非常强的能'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 27, 'page_label': '28'}, page_content='特定领域任务中，如金融领域的证券交易和市场预测，语言大模型通\n常需要结合外部工具获取信息和技能才能处理。 整合外部工具与语言\n大模型可以发挥各自优势实现复杂任务的处理， 其中外部工具可增强\n专业知识和可解释性，语言大模型提供语义理解和推理规划能力。  \n2021年底， OpenAI推出 WebGPT [60]，利用 GPT-3与网页浏览\n器和搜索引擎交互获取互联网信息在长文本问答上实现非常强的能\n力，展现了语言大模型利用工具解决复杂问题的巨大潜力。该工作引\n起了学术界和产业界的广泛关注 ， 产生了许多面向不同任务或场景需\n求的大模型调用工具的方法，如 Webshop [61]，使用语言大模型替代\n人在购物平台上执行一系列操作、 购买所需物品。 2023年3月，OpenA I\n发布 ChatGPT Pl ugins [62]，实现 Chat GPT调用各种 外部插件的功能，\n支持浏览器实时信息获取、代码解释器、 PDF阅读等能力，截至 8\n月已支持 480个常用工具插件。 Meta将这种通过非参数的外部模块\n扩展语言大模型能力的方法，统一称为增广语言模型（ Augmente d'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 27, 'page_label': '28'}, page_content='人在购物平台上执行一系列操作、 购买所需物品。 2023年3月，OpenA I\n发布 ChatGPT Pl ugins [62]，实现 Chat GPT调用各种 外部插件的功能，\n支持浏览器实时信息获取、代码解释器、 PDF阅读等能力，截至 8\n月已支持 480个常用工具插件。 Meta将这种通过非参数的外部模块\n扩展语言大模型能力的方法，统一称为增广语言模型（ Augmente d \nLanguage Models ）[63]。 清华大学在现有大模型工具使用方法基础上，\n提出了工具学习 （Tool Learning ）框架 [24]，指在让模型能够理解和\n使用各种工具完成任务的学习过程。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 28, 'page_label': '29'}, page_content='28 \n \n图2-9 基于用户接口视角的工具分类 [24] \n目前可交互的通用工具按用户接口大致可分为三类（图 2-9） ：物\n理交互的工具（如机器人、传感器等） 、基于图形用户界面的工具（如\n浏览器、 Office办公软件等） 、基于编程接口的工具（如数据库、知\n识图谱）等。 从学习目标的角度来看，现有工具学习方法主要可以分\n为两类 [24]：一类是工具增强学习（ Tool-augmented Learni ng） ，利用\n各种工具的执行结果，增强基础模型性能。在这一 范式中，工具执行\n结果被视为辅助生成高质量输出的外部资源 ； 第二类是 工具导向学习\n（Tool-oriented Learning ） ，将学习过程重点从增强模型性能转向工具\n执行本身。 这一类研究关注开发能够代替人类控制工具并进行序列决\n策的模型 。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 29, 'page_label': '30'}, page_content='29 第3章 多模态大模型技术  \n不同于语言大模型只对文本进行处理，多模态大模型将文本、语\n音、图像、视频等多模态数据联合起来进行学习。多模态大模型 融合\n了多种感知途径与表达形态 ，能够同时处理和理解来自不同感知通道\n（例如视觉、听觉、语言和触觉等 ）的信息，并以 多模态的方式表达\n输出。 \n \n3.1 多模态大模型 的技术体系  \n现有的多模态大模型主要有面向理解 任务的、面向生成任务的、\n兼顾理解和生成的、知识增强的多模态大模型。  \n3.1.1 面向理解任务的多模态大模型  \n面向理解任务的多模态大模型，其核心结构通常是 基于\nTransformer 的编码器。按照模型结构的不同，面向理解任务的多模\n态大模型又可再分为单流和多流两种结构。 单流结构是指不同 模态的\n特征在拼接后由一个共享的 Transf ormer网络进行处理；而多流结构\n中，不同模态则分别 由Trans former网络进行编码处理，这些网络之\n间存在有一些特征上的交互融合机制。  \n多流结构的一个典型代表是图文理解模型 ViLBERT [64]， 它采用'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 29, 'page_label': '30'}, page_content='态大模型又可再分为单流和多流两种结构。 单流结构是指不同 模态的\n特征在拼接后由一个共享的 Transf ormer网络进行处理；而多流结构\n中，不同模态则分别 由Trans former网络进行编码处理，这些网络之\n间存在有一些特征上的交互融合机制。  \n多流结构的一个典型代表是图文理解模型 ViLBERT [64]， 它采用\n了一种双流 Transformer 的结构， 首先 将文本和图像数据分别输入两个\n独立的 Transformer 编码器， 接着使用互注意力 Transformer （Co-Attention \nTransformer ）层将文本和图像 特征进行融合，最后 所得到文本 -图像特\n征可以被应用到视觉问答 、图像描述生成 等不同的多模态的任务中。 多\n流结构的另一个代表是 OpenAI公司的 CLIP [65]模型，它 采用两个独\n立的编码网络对 图像和文本进行特征抽取， 并通过对比学习将两者的\n特征嵌入 到共享的语义空间 中。 CLIP基于 4亿图文对进行训练，可\n以从自然语言监督中有效地学习视觉概念， 从而获得泛化性能极强的'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 29, 'page_label': '30'}, page_content='征可以被应用到视觉问答 、图像描述生成 等不同的多模态的任务中。 多\n流结构的另一个代表是 OpenAI公司的 CLIP [65]模型，它 采用两个独\n立的编码网络对 图像和文本进行特征抽取， 并通过对比学习将两者的\n特征嵌入 到共享的语义空间 中。 CLIP基于 4亿图文对进行训练，可\n以从自然语言监督中有效地学习视觉概念， 从而获得泛化性能极强的\n零样本（ zero-shot）分类能力。 另一个与 CLIP类型的代表性方法'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 30, 'page_label': '31'}, page_content='30 ALIGN [66]，使用对比损失训练了一个简单的双编码器模型，利用包\n含超过 10亿个噪声图像 -文本对的数据集来扩展视觉和视觉语言表 征\n学习。 CLIP是个图文双流结构，而 V ATT [67]则是针对视频 -文本 -音\n频数据的多流模型。与 CLIP类似， V ATT将每个模态线性投影为特\n征向量，然后将其分别送到 Transformer 编码器中，并将编码后的特\n征在语义分层的不同粒度空间中通过对比学习来训练模型。  \n \n图3-1 CLIP[65]模型架构图  \n单流结构的一个典型代表是 VL-BERT[68]，它将图像的描述文本\n和关键物体 的区域特征拼接后作为 BERT网络的输入， 通过 掩码掉部\n分文本输入和图像输入 并预测所缺失的信息来进行模型训练 。此外，\n另一代表性方法 UNITER  [69]，则采用了 一种多任务的多模态预训练\n方法，相对于其它方法， 该模型增加了单词与图像区域 的匹配模块，\n来更进一步建立图像与文本的细粒度关联。 在视频领域，单流结构的'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 30, 'page_label': '31'}, page_content='和关键物体 的区域特征拼接后作为 BERT网络的输入， 通过 掩码掉部\n分文本输入和图像输入 并预测所缺失的信息来进行模型训练 。此外，\n另一代表性方法 UNITER  [69]，则采用了 一种多任务的多模态预训练\n方法，相对于其它方法， 该模型增加了单词与图像区域 的匹配模块，\n来更进一步建立图像与文本的细粒度关联。 在视频领域，单流结构的\n代表性方法有 VideoBERT [70]和ActBERT [71]， 其中 VideoBERT 是一\n个视频 -语言模型，它 融合了文本和视频作为 BERT网络的输入；而\nActBERT 采用了一种全局 -局部关系的建模方法，输入 不止包括文本\n和视频的全局信息， 还利用了视频帧中的局部信息来加强对于视频内\n容的理解。  \n现有的面向理解任务的多模态大 模型大多都以上面两类结构为\n基础，此外，也有不少方法在预训练任务上进行研究，引入更多的预\n训练任务或设计统一的架构去训练所有的任务等 。例如，其中一个典'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 31, 'page_label': '32'}, page_content='31 型方法 Florence [72]，它着重于如何使模型适应各种下游任务，并设\n计了一个由多模态大模型和适应模型组成的工作流。 具体对于任务适\n应，该模型使用动态头部适配器将学习到的视觉特征表示从场景扩展\n到对象， 采用  CoSwin适配器来学习视频表示，并使用 METER适配\n器将模型应用到依赖细粒度视觉 -语言表示的视觉语言任务。  \n3.1.2 面向生成任务的多模态大模型  \n面向生成任务的多模态大模型能够实现文本、 图片、 视频、 音频、\n3D、分子结构等多种模态内容 的生成应用。目前常用的方法主要是\n基于序列生成模型和扩散模型（ diffusion  models）。 \n在序列生成模型中， DALL -E[73]是个典型代表。它是由 OpenAI\n发布的一个基于 4亿图文对训练的图像生成模型，通过采用\nVQV AE [74]图像离散自编码器和 GPT组合的结构，在以文生图任务\n上取得了突破性的生成质量和泛化能力 ，被称作图像版 GPT。另一典\n型的图像生成模型是 北京智源研究院 所的 CogV iew模型 [75]（如图'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 31, 'page_label': '32'}, page_content='在序列生成模型中， DALL -E[73]是个典型代表。它是由 OpenAI\n发布的一个基于 4亿图文对训练的图像生成模型，通过采用\nVQV AE [74]图像离散自编码器和 GPT组合的结构，在以文生图任务\n上取得了突破性的生成质量和泛化能力 ，被称作图像版 GPT。另一典\n型的图像生成模型是 北京智源研究院 所的 CogV iew模型 [75]（如图\n3-2所示） ，它具有与 DALL -E类似的结构 ，但是面向中文环境的文\n本到图像生成 ， 并进一步探索了多模态生成模型在下游任务上精调后\n的泛化能力。 CogView 在基于文本控制的样式学习、服装设计和图像\n超分等任务上均取得出色的效果。在文本生成方向上，采用序列生成\n模型是最主流的方案，例如，典型方法 GIT[76]是一个视觉到文本的\n多模态大模型 ，统一了图像 /视频的描述和问答等视觉语言任务 ，它\n包含有一个图像编码器和一个文本解码器 ，其文本解码器在视觉编码\n的基础上， 以自回归的 方式来生成文 本。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 32, 'page_label': '33'}, page_content='32 \n \n图3-2 CogView [75]模型架构图  \n扩散模型的工作原理， 是通过连续添加高斯噪声来破坏训练数据，\n然后通过反转这个噪声过程，来学习恢复数据。扩散模型的一个代表\n性方法 LDM [77]， 它先压缩图像的像素信息来获取图像对应的隐特征\n表达，再采用扩散模型来建模图像隐特征分布。另一典型扩散模型\nStabl e Diffusion ，它拓展 LDM至开放领域的文本至图像生成，是当\n前开源模型的代表方法。除了开源模型之外，闭源的扩散模型中代表\n性方法有 OpenAI的DALL -E2[78]与谷歌的 Imagen [79]。其中，\nDALL -E2首先然练一个扩散解码器来反转 CLIP图像编码器 ， 然后训\n练一个独立的映射模型将 CLIP模型的文本特征映射到图像特征空\n间，从而实现以文生图的过程，并极大提升了生成图像与输 入文本的\n匹配程度。而 Imagen首先将文本进行编码表征，之后使用扩散模型\n将表征映射成为 64x64像素的低 分辨率的图像， 然后会通过两个超分\n辨率扩散模型来逐渐提高分辨率到 1024x1024像素，如图 3-3所示。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 32, 'page_label': '33'}, page_content='练一个独立的映射模型将 CLIP模型的文本特征映射到图像特征空\n间，从而实现以文生图的过程，并极大提升了生成图像与输 入文本的\n匹配程度。而 Imagen首先将文本进行编码表征，之后使用扩散模型\n将表征映射成为 64x64像素的低 分辨率的图像， 然后会通过两个超分\n辨率扩散模型来逐渐提高分辨率到 1024x1024像素，如图 3-3所示。\n此外， 与  DALL -E2 不同的是， Imagen 使用了通用语言大模型 T5 模\n型直接编码文本信息，然后直接用该文本编码来生成图像；同时，\nImagen发现基于 T5模型提取的文本特征生成的图像比 基于 CLIP模\n型的图像细节准确度更高。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 33, 'page_label': '34'}, page_content='33 \n \n图3-3 Imagen [79]模型架构图  \n \n3.1.3 兼顾理解和生成任务的多模态大模型  \nTransformer 编码器通过双向的注意力机制来学 习对数据的理解\n能力，而解码器通过单向的注意力机制学习生成能力。为了让模型同\n时具备这两种能力从而可以在更广泛的下游任务上应用， 可以联合\nTransformer 编码器与解码器 ，设计能够兼顾理解与生成任务的多模\n态大模型 。例如， 一个典型方法是蒙 特利尔大学 所的 VL-T5[80]模型，\n将多个多模态任务统一为文本生成 任务。具体地， 如图 3-4所示，该\n模型由 Transformer 编码器和自回归的解码器组成，其主要创新点在\n于针对训练任务与数据的不同采用不同的输入文本与输出文本的构'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 34, 'page_label': '35'}, page_content='34 造方式， 这种将模型结构和目标任务统一的方法可以充分利用不同任\n务的数据来训练模型，提高模型的泛化性。 这类方法的另一个典型模\n型Unified VLP [81]，它的主要特点是编 码器和解码器共享同一个\nTransformer 网络。该方法通过设置注意力掩码来 控制网络为编码器\n或解码器。具体地，当使用编码器时，注意力掩码为双向掩码， 任一\n位置都可建模前 后两个方向的依赖关系；当使用解码器功能时，注意\n力掩码设置为单向，每一位置只能建模前文的依赖关系。这种编解码\n共享的方式能够减少参数量，使网络更加简洁。  \n \n图3-4 VL -T5[80]模型架构图  \n此外， 还可以将语言大模型的文本生成能力与各类模态编码器的\n多模态感知能力相结合， 以此构建的多模态大模型也能够兼顾理解和\n生成能力。这类方法 以语言大模型为主导来实现多模态的对齐、融合\n和交互。这是由于文本有高效的表达效率、能够通过语义描述的方式\n与其余所有模态建立直接的联系，另 外，语言大模型在预训练过程中\n学习到了非常多的世界知识，有潜在理解多模态信息的能力。这类模'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 34, 'page_label': '35'}, page_content='此外， 还可以将语言大模型的文本生成能力与各类模态编码器的\n多模态感知能力相结合， 以此构建的多模态大模型也能够兼顾理解和\n生成能力。这类方法 以语言大模型为主导来实现多模态的对齐、融合\n和交互。这是由于文本有高效的表达效率、能够通过语义描述的方式\n与其余所有模态建立直接的联系，另 外，语言大模型在预训练过程中\n学习到了非常多的世界知识，有潜在理解多模态信息的能力。这类模\n型在结构方面常由单模态编码器、连接器与语言大模型三部分组成，\n其中单模态编码器 和语言大模型的参数可以冻结以减少计算量、 提高\n训练效率；连接器常见的有简单的线性映射层，或者特殊设计的网络\n模块如 BLIP -2[82]中的 Q-former结构等（如图 3-5所示） 。这类模型\n通常涉及到两个阶段的训练过程。在第一阶段，训练各个模态到语言\n大模型的语义对齐，通 常利用大规模弱关联的跨 模态数据（如图像 -\n文本、视频 -文本、音频 -文本数据等） ，基于条件文本生成任务进行'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 35, 'page_label': '36'}, page_content='35 训练。在第二阶段进行多模态指令微调以提升零样本多模态能力，此\n阶段的核心是构造面向多模态任务的指令 微调数据， 目前常见的多模\n态指令微调数据类型有多模态对话、 多模态详细描述与多模态推理问\n答等。  \n \n图3-5 BLIP -2[82]模型架构图  \n \n3.1.4 知识增强的多模态大模型  \n大模型不仅对大规模数据有着卓越的拟合能力， 还能够学习到隐\n式的知识。为了促进更有意义的理解和预测， 还需要寻找将隐式知识\n与显式知识（例如来自知识图谱）联系起来的方法。 因此，将知识图\n谱、场景图、外部知识库等结构化的知识信息注入大 模型中，将可增\n强多模态大模型 的知识利用能力。例如，在场景图知识的利用上的一\n个典型方法是百度的 ERNIE -ViL[83]模型，如图 3-6所示，它在视觉 -\n语言模型中 引入了由文本解析而来的 场景图信息 ， 在预训练过程中 通\n过将场景图 中的知识实体和关系进行掩码后要求模型预测所掩码位\n置的知识信息，以此作为更细的多模态预训练任务 ，这能够使得模型\n更能精准把握图像和文本之间细粒度的对齐信息。 在知识图谱的利用'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 35, 'page_label': '36'}, page_content='个典型方法是百度的 ERNIE -ViL[83]模型，如图 3-6所示，它在视觉 -\n语言模型中 引入了由文本解析而来的 场景图信息 ， 在预训练过程中 通\n过将场景图 中的知识实体和关系进行掩码后要求模型预测所掩码位\n置的知识信息，以此作为更细的多模态预训练任务 ，这能够使得模型\n更能精准把握图像和文本之间细粒度的对齐信息。 在知识图谱的利用\n上，典型方法有 KRISP [84]，它结合了隐含知识和明确知识的学习，\n即从无监督语料和有监督的训练数据中学到隐含的知识， 从结构化数'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 36, 'page_label': '37'}, page_content='36 据知识图谱中学习明确的符号化的知识， 这样既可以进行隐式的知识\n推理，又可以获取符号化的知识表示 。 \n \n图3-6 ERNIE -ViL[83]模型架构图  \n3.2 多模态大模型 的关键技术  \n多模态大模型的 关键技术主要包括 预训练数据收集、 基础模型构\n建、自监督学习与模型优化训练、下游任务微调。  \n3.2.1 多模态大模型的 网络结构设计  \n网络架构在多模态预训练中扮演着关键角色， 需要精心设计以适\n应和理解来自不同源的复杂特征。例如，在处理图像和文本模态时，\n通常会采用 Transformer 或卷积神经网络（ CNN）来捕捉视觉和语言\n之间的复杂关系；而对于事件流，脉冲神经网络可能更为适合，因为\n它们能有效地模拟信息的时序动态。随着模型规模的增加，大型多模\n态大模型展示出强大的记忆能力和性能增益。然而，模型复杂度的增\n加也不可避免地 引入了计算效 率的挑战，并 可能最终遇到性能瓶颈。\n因此，对于更高效的网络模型结构的设计和探索，比如改进或甚至替\n代Transformer ，成为了重要的研究方向。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 36, 'page_label': '37'}, page_content='之间的复杂关系；而对于事件流，脉冲神经网络可能更为适合，因为\n它们能有效地模拟信息的时序动态。随着模型规模的增加，大型多模\n态大模型展示出强大的记忆能力和性能增益。然而，模型复杂度的增\n加也不可避免地 引入了计算效 率的挑战，并 可能最终遇到性能瓶颈。\n因此，对于更高效的网络模型结构的设计和探索，比如改进或甚至替\n代Transformer ，成为了重要的研究方向。  \n其次，得益于 语言大模型 涌现出的知识与 逻辑推理 能力，近期有\n一系列多模态大模型 开始以语言大模型 为核心进行构建 。其中一个代\n表性方法是 DeepMind 的Flamingo [85]视觉语言模型，该模型能够将\n图像、视频和文本作为提示并输出相关语言回复。它将视觉编码器与\n语言大模型的参数冻结并通过可学习的融合模块联系起来， 模型采用'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 37, 'page_label': '38'}, page_content='37 20多亿对图片 -文本、 270万对视频 -文本，与 430万图文混排的网页\n数据进行视觉 -语言联合训练； Flamingo 具有少样本（ few-shot）的多\n模态序列推理能力，无需额外训练即可完成视觉语义描述、视觉问答\n等多种任务。另一个代表性模型 KOSMOS -1[86]，它将一个基于  \nTransformer 的语言模型作为通用接口，并将其与视觉感知模块对接，\n使得模型“能看”和“会说” ；该模型具有 16亿参数量，在大规模多\n模态语料库上训练，具有遵循指令（即 零样本学习） 以及在上下文 中\n学习（即少样本学习）能力，能够原生处理视觉对话、视觉问答、图\n像描述生成、光学字符 识别等任务。此外，近期还有一系列模型尝试\n将图像、视频等感知模块与 LLaMA [87]等开源的语言大模型对接，\n从而实现类似 GPT-4的多模态理解能力。其中的一个典型模型是\nChatBridge [88]，它使用多个并行 的感知模块 用来处理包括图片、音\n频、视频 的在内特征， 然后通过少量预训练参数将 这些模态的特征投\n影至语言大模型的语义空间，使得模型具备灵活感知、理解混合模态'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 37, 'page_label': '38'}, page_content='将图像、视频等感知模块与 LLaMA [87]等开源的语言大模型对接，\n从而实现类似 GPT-4的多模态理解能力。其中的一个典型模型是\nChatBridge [88]，它使用多个并行 的感知模块 用来处理包括图片、音\n频、视频 的在内特征， 然后通过少量预训练参数将 这些模态的特征投\n影至语言大模型的语义空间，使得模型具备灵活感知、理解混合模态\n信息的能力。  \n最后，对于多模态预训练，设计与下游任务更 高兼容性的网络结\n构模型显得尤为重要。具体来说，可以通过引入编码器 -解码器结构\n将多模态理解和生成任务统一到一个框架下， 从而更好地支持各种多\n模态任务。这 主要涉及到跨模态的注意机制、模态间的对齐和翻译、\n以及更复杂的特征集成策略。  \n3.2.2 多模态大模型的自监督学习优化  \n以视觉 -语言数据的联合学习为例，多模态大模型常用的自监督\n学习任务通常有以下几种类型。  \n1）掩码语言建模（ Masked Lan guage Modeling ，MLM）：输入文本\n序列中的某些单词或标记会被替换为特殊的掩码标记 [MASK ]，然后'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 37, 'page_label': '38'}, page_content='模态任务。这 主要涉及到跨模态的注意机制、模态间的对齐和翻译、\n以及更复杂的特征集成策略。  \n3.2.2 多模态大模型的自监督学习优化  \n以视觉 -语言数据的联合学习为例，多模态大模型常用的自监督\n学习任务通常有以下几种类型。  \n1）掩码语言建模（ Masked Lan guage Modeling ，MLM）：输入文本\n序列中的某些单词或标记会被替换为特殊的掩码标记 [MASK ]，然后\n预训练模型被要求根据可见的多模态上下文来预测这些被遮 蔽的单\n词或标记，如图 3-7。多模态大模型通过执行这种预训练任务，模型'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 38, 'page_label': '39'}, page_content='38 能够在大规模文本数据上获取深层次的 语言理解， 从而更好地执行下\n游自然语言处理任务，如文本分类、命名实体识别、句子相似性计算\n等。  \n \n图3-7掩码语言预测  \n2）掩码图像建模 （Masked Image Modeling ，MIM）：输入图像\n中的部分区域会被隐藏或被替换为特殊的掩码标记 [MASK]，然后预\n训练模型被要求在仅看到 其余图像内容与文本等其他模态信息的情\n况下，预测或还原被遮蔽的图像区域。多模态大模型通常使用这种训\n练方式促使模型学习图像的 视觉特征、多模态上下文信息和语义关\n系，以更好地理解图像内容，如图 3-8。 \n \n图3-8 掩码视觉预测'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 39, 'page_label': '40'}, page_content='39 3）图像 -文本匹配（ Image -Text Matching ，ITM）：前面的掩码\n语言建模和掩码图像建模旨在建立图像与文本的细粒度对齐， 而图像\n-文本匹配任务是旨在实现图像与文本的全局对齐。通常给定图文对\n作为正样本，随机配对作为负样本对，然后通过二分类方法实现图像\n和文本的匹配，从而建立图像和文本之间的语义 关联，如图 3-9。 \n4）图像 -文本对比学习 (Ima ge-Text Contras tive Learning , ITC），\n使用对比学习的方法将图像和文本的相同样本对的向量表示拉近， 不\n同样本对的向量表示推远，从而增强图像和文本之间的语义关联性。\n这使得模型能够更好地理解图像和文本之间的语义关联， 为多模态任\n务提供更好的表示能力，如图 3-10。 \n3.2.3 多模态大模型的下游任务微调 适配  \n多模态大模型的最终目标是适配并提升特定下游任务上的性能\n表现，因此，需要通过微调适配将预训练大模型的能力迁移到特定数图3-10 图像-文本对\n比学习学习  \n图3-9 图像文本匹配'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 40, 'page_label': '41'}, page_content='40 据下的特定任务场景中。目前，多模态大模型的微调适配方式主要有\n三种： \n1）面向特定任务的模型微调适配： 多模态大模型的权重被作为\n初始参数，并在任务特定数据上进行有监督的微调。通过 这种微调，\n模型将学习针对具体任务的细粒度特征和表示， 从而适应特定任务的\n要求。  \n2）联合提示学习的模型微调适配： 设计契合上游预训练任务的\n模板，挖掘出上游预训练模型的潜力，让上游的预训练模型在尽量不\n需要标注数据的情况下比较好的完成下游的任务。 提示学习允许在不\n同类型的任务上重复使用预训练模型， 只需简单修改提示 模版即可适\n应特定任务，从而节省了训练时间和计算资源。  \n3）基于适配器网 络的模型 微调适配：每个任务都有自己独立的\n适配器层，使得模型可以 在不同任务之间共享通用预训练模型的表\n示，同时在每个任务上进行个性化的调整。适配器层通常由较少的参\n数组成， 因此它们比在整个模型上进行微调更加高效。 在训练过程中，\n预训练模型的参数是固定的，只有适配器层的参数被更新。  \n现有的预训练大型方法通过特征微调或提示学习用于下游任务，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 40, 'page_label': '41'}, page_content='3）基于适配器网 络的模型 微调适配：每个任务都有自己独立的\n适配器层，使得模型可以 在不同任务之间共享通用预训练模型的表\n示，同时在每个任务上进行个性化的调整。适配器层通常由较少的参\n数组成， 因此它们比在整个模型上进行微调更加高效。 在训练过程中，\n预训练模型的参数是固定的，只有适配器层的参数被更新。  \n现有的预训练大型方法通过特征微调或提示学习用于下游任务，\n也需要更多研究考虑为多模态大型模型开发增量学习算法。未来，如\n何将新模态引入到已经预先训练好的多模态模型中具有实际意义 ，因\n为新的传感器 (模态 )将在未来的某个不确定时间出现，设计的多模态\n大型模型应该足够灵活以应对这种情况。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 41, 'page_label': '42'}, page_content='41 第4章 大模型技术生态  \n随着大模型技术的快速发展，大模型的生态体系也在快速构建。\n典型的大模型平台如 ChatGPT 、文心一言、讯飞星火等提供如 APP、\n网页版、 API接口等多种形式的开放服务，并通过开放插件机制、\nFunction Call 等实现大模型外部工具、服务的调用，加速应用生态的\n发展。 与此同时， 开源大模型也已经成 为生态体系中的关键组成部分。\n通过大模型的开源共建，凝聚了来自企业、高校、科研院所等众多领\n域高水平开发者的力量，加速大模型的科研创新和产品迭 代。伴随着\n大模型的开 源开放， 深度学习开源框架和工具更加注重分布式训练和\n推理能力， 并加速与 AI芯片开展适配和联合优化。大模型的训练数\n据作为生态中另一关键组成部分， 相关数据集和配套工具也在加速汇\n聚和优化，愈发得到广泛重视。下文对以上几个方面分别展开介绍。  \n4.1 典型大模型平台  \n（1）GPT 系列  \nOpenAI的GPT系列模型是自然语言处理领域的重大突破，其中\nChatGPT 和GPT-4是两个代表性模型。 ChatGPT 专注于对各种文本'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 41, 'page_label': '42'}, page_content='推理能力， 并加速与 AI芯片开展适配和联合优化。大模型的训练数\n据作为生态中另一关键组成部分， 相关数据集和配套工具也在加速汇\n聚和优化，愈发得到广泛重视。下文对以上几个方面分别展开介绍。  \n4.1 典型大模型平台  \n（1）GPT 系列  \nOpenAI的GPT系列模型是自然语言处理领域的重大突破，其中\nChatGPT 和GPT-4是两个代表性模型。 ChatGPT 专注于对各种文本\n指令做出回应，模型的训练过程包括有监督的指令微调与强化学习。\n现在的 ChatGPT 支持最长达 32,000个字符，它可以执行各种任务，\n包括代码编写、数学问题求解、写作建议等。 GPT-4在推理方面的能\n力比 ChatGPT 更强，同时也减少了幻象的产生，能够更准确地理解\n和回应复杂的问题，从而提供更高质量的答案，但是引人注目的多模\n态功能尚未正式开放体验。由于单一的语言模型难以胜任所有任务，\n自从 ChatGPT 和GPT-4发布以来，许多开发者已经开始将各种工具\n和插件集成到这些模型中， 以进一步增强它们的功能。 现在， ChatGPT'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 41, 'page_label': '42'}, page_content='力比 ChatGPT 更强，同时也减少了幻象的产生，能够更准确地理解\n和回应复杂的问题，从而提供更高质量的答案，但是引人注目的多模\n态功能尚未正式开放体验。由于单一的语言模型难以胜任所有任务，\n自从 ChatGPT 和GPT-4发布以来，许多开发者已经开始将各种工具\n和插件集成到这些模型中， 以进一步增强它们的功能。 现在， ChatGPT \nPlus用户可以使用各种插件来增强模型以满足自己的需求， 这极大地\n扩展了模型的 用途和适用领 域。  \n（2）Claude系列'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 42, 'page_label': '43'}, page_content='42 Claude系列模型是由 Anthropic 开发的闭源语言大模型，目前包\n含Claude和Claude -Instant两种模型可供选择。 最早的 Claude于2023\n年3月15日发布，并在 2023年7月11日，更新至 Claude -2。该系\n列模型通过无监督预训练、基于人类反馈的强化学习和 Constitutional \nAI技术（包含监督训练和强化学习）进行训练，旨在改进模型的有\n用性、诚实性和无害性。值得一提的是， Claude最高支持 100K词元\n的上下文，而 Claude -2更是拓展到了 200K词元的上下文。相比于\nClaude 1. 3， Claude 2 拥有更强的综合能力，同时能够生成更长的相\n应。  \n（3）PaLM 系列  \nPaLM [17]系列语言大模型由 Google 开发。其初始版本于 2022\n年4月发布，并在 2023年3月公开了 API。PaLM基于 Google提出\n的Pathways 机器学习系统搭建，训练数据总量达 780B个字符，内容\n涵盖网页、书籍、新闻、开源代码等多种形式的语料。目前 PaLM共'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 42, 'page_label': '43'}, page_content='应。  \n（3）PaLM 系列  \nPaLM [17]系列语言大模型由 Google 开发。其初始版本于 2022\n年4月发布，并在 2023年3月公开了 API。PaLM基于 Google提出\n的Pathways 机器学习系统搭建，训练数据总量达 780B个字符，内容\n涵盖网页、书籍、新闻、开源代码等多种形式的语料。目前 PaLM共\n有8B、62B、540B三个不同参 数量的模型版 本。 Goog le还开发了多\n种PaLM的改进版本。 Med-PaLM  [89] 是PaLM 540B 在医疗数据上\n进行了微调后的版本，在 MedQA等医疗问答数据集上取得了最好成\n绩。 PaLM -E [90] 是PaLM的多模态版本，能够在现实场景中控制机\n器人完成简单任务。 2023年5月， Google发布了 PaLM 2，但并未公\n开其技术细节。 Google内部文件显示其参数量为 340B，训练数据为\nPaLM的5倍左右。  \n（4）Bard  \nBard是Google开发的对话模型。在 OpenAI发布 ChatGPT 后，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 42, 'page_label': '43'}, page_content='绩。 PaLM -E [90] 是PaLM的多模态版本，能够在现实场景中控制机\n器人完成简单任务。 2023年5月， Google发布了 PaLM 2，但并未公\n开其技术细节。 Google内部文件显示其参数量为 340B，训练数据为\nPaLM的5倍左右。  \n（4）Bard  \nBard是Google开发的对话模型。在 OpenAI发布 ChatGPT 后，\nGoogle担心其会对自身的搜索业务产生威胁，因此推动了 Bard的开\n发。 2023年2月6日， Bard正式发布，其基座模型是 Google此前开\n发的语言大模型 LaMDA。后续 Google为Bard开展了持续的升级，\n包括添加数学与逻辑能力、添加代码能力、支持更多语言等。 2023'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 43, 'page_label': '44'}, page_content='43 年5月， Google发布了基于新一代语 言大模型 PaLM 2的Bard。 \n（5）文心一言  \n文心一言是基于百度文心大模型的知识增强语言 大模型， 于 2023\n年3月在国内率先开启邀测。 文心一言的基础模型文心大 模型于2019\n年发布。 8月31日，文心一言率先向全社会全面开放，提供 APP、\n网页版、 API接口等多种形式的开放服务。文心一言一方面采用有监\n督精调、人类反馈的强化学习、提示等技术，还具备知识增强、检索\n增强和对话增强等关键技术。当前，以文心一言为代表的大模 型已经\n逐步赶超国外最优水平。文心一言基于飞桨深度学习框架进行训练，\n算法与框架的协同优化后效果和效率都得到提升， 模 型训练速度达到\n优化前的 3倍，推理速度达到优化前的 30多倍。文心一言还建设了\n插件机制，通过外部工具、服务的调用，拓展大模型的能力的 边界。  \n（6）讯飞星火认知大模型  \n 讯飞星火认知大模型是科大讯飞于 2023年5月6日发布的语言\n大模型，提供了基于自然语言处理的多元能力，支持多种自然语言处\n理任务， 同时联合中科院人工智能产学研创新联盟和长三角人工智能'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 43, 'page_label': '44'}, page_content='优化前的 3倍，推理速度达到优化前的 30多倍。文心一言还建设了\n插件机制，通过外部工具、服务的调用，拓展大模型的能力的 边界。  \n（6）讯飞星火认知大模型  \n 讯飞星火认知大模型是科大讯飞于 2023年5月6日发布的语言\n大模型，提供了基于自然语言处理的多元能力，支持多种自然语言处\n理任务， 同时联合中科院人工智能产学研创新联盟和长三角人工智能\n产业链联盟在业内提出了覆盖 7大类 481项任务的 《通用人工智能评\n测体系》 ； 6月9日星火大模型升级到 V1.5版，实现 了开放式知识问\n答、多轮对话、逻辑和数学能力的提升； 8月15日星火大模型升级\n到V2.0版，对于代码和多模态能力进行了提升。同时，讯飞和华为\n还联合重磅发布 了国内首款支 持大模型训练私有化的全国产化产品\n“星火一体机 ”，可支持企业快速实现讯飞星火大模型的私有化部署、\n场景赋能和专属大模型训练优化。  \n（7）腾讯混元  \n腾讯混元大模型是腾讯于 2023年9月7日发布的千亿参数量语\n言大模型，具有多轮对话、内容创作、逻辑推理、知识增强能力，训'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 43, 'page_label': '44'}, page_content='到V2.0版，对于代码和多模态能力进行了提升。同时，讯飞和华为\n还联合重磅发布 了国内首款支 持大模型训练私有化的全国产化产品\n“星火一体机 ”，可支持企业快速实现讯飞星火大模型的私有化部署、\n场景赋能和专属大模型训练优化。  \n（7）腾讯混元  \n腾讯混元大模型是腾讯于 2023年9月7日发布的千亿参数量语\n言大模型，具有多轮对话、内容创作、逻辑推理、知识增强能力，训\n练数据截止于 2023年7月。为了降低 幻觉问题，混元大模型在预训'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 44, 'page_label': '45'}, page_content='44 练阶段，利用探真算法对目标函数进行了优化，使用强化学习等方法\n学会识别陷阱。混元大模型针对位置编码进行了优化，并结合指令跟\n随能力解决长难任务。此外，混元大模型还具备了问题分解和分布推\n理能力，从而解决逻辑推理问题。  \n（8）通义千问  \n通义千问由阿里巴巴基于“通义”大模型研发，于 2023年4月正\n式发布。 2023年8月， 阿里云开源了 70亿参数通用模型和对话模型。\n它能够以自然语言方式响应人类的各种指令，拥有强大的能力，如回\n答问题、创作文字、编写代码、提供各类语言的翻译服务、文本润色、\n文本摘要 以及角色扮演对话等。 借助于阿里云丰富的算力资源和平台\n服务，通义千问能够实现快速迭代和创新功能。此外，阿里巴巴完善\n的产品体系以及广泛的应用场景使得通义千问更具可落地性和市场\n可接受程度。  \n4.2 典型开源大模型  \n4.2.1 典型开源语言大模型  \n开源模型  公司  包含模型  参数量  \nLLaMA系列  Meta  LLAMA，LLAMA2  7B，13B，65B \nFalcon系列  TII Falcon  1.3B，7.5B，40B，180B'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 44, 'page_label': '45'}, page_content='的产品体系以及广泛的应用场景使得通义千问更具可落地性和市场\n可接受程度。  \n4.2 典型开源大模型  \n4.2.1 典型开源语言大模型  \n开源模型  公司  包含模型  参数量  \nLLaMA系列  Meta  LLAMA，LLAMA2  7B，13B，65B \nFalcon系列  TII Falcon  1.3B，7.5B，40B，180B   \nPythia系列  EleutherAI  Pythia  70M，160M，410M，\n1B，1.4B，2.8B，6.9B，\n12B \nT5系列  Google  T5，mT5，FLAN -T5 60M，220M，770M，\n3B，11B \nBLOOM 系列  BigScience  BLOOM，BLOOM -Z 560M，1.1B，1.7B，3B，\n7.1B，176B \nGPT -Neo EleutherAI  GPT -Neo 125M，350M，1.3B，\n2.7B  \nOPT系列  Meta  OPT，OPT -IML 125M，350M，1.3B，\n2.7B，6.7B，13B，30B，\n66B，175B'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 44, 'page_label': '45'}, page_content='3B，11B \nBLOOM 系列  BigScience  BLOOM，BLOOM -Z 560M，1.1B，1.7B，3B，\n7.1B，176B \nGPT -Neo EleutherAI  GPT -Neo 125M，350M，1.3B，\n2.7B  \nOPT系列  Meta  OPT，OPT -IML 125M，350M，1.3B，\n2.7B，6.7B，13B，30B，\n66B，175B  \nMPT系列  MosaicML  MPT -Chat  7B，30B MPT -Instruct  \n文心系列  百度  ERNIE 1.0 ，ERNIE \n2.0，ERNIE 3.0  18M，23M，75M，\n100M，118M，280M，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 45, 'page_label': '46'}, page_content='45 340M，550M  \nHelixGEM ，HelixFold ，\nHelixGEM2 ，\nHelixFold -Single  100K，90M，32M，1B \nVIMER -CAE， \nVIMER -StrucTexTv2 ， \nVIMER -UMS， \nVIMER -UFO  80M，129M，1.1B，17B \nGLM系列  清华大学，智谱 AI GLM，ChatGLM ，\nChatGLM2 ，WebGLM  2B，6B，10B，130B  \nBaichuan 系列  百川智能  Baichuan ，Baichuan2  7B，13B \nCPM系列  北京智源人工智能研究\n院、清华大学  CPM -1，CPM -2，\nCPM -3，CPM -Bee 1B，2B，2.6B，5B，\n7B，10B，11B，198B  \n盘古系列  鹏城实验室、华为\nMindSpore 、 华为诺亚方\n舟实验室、北京大学  盘古α  350M，2.6B，13B \n \n（1）LLaMA系列  \nLLaMA系列模型 [30]是一组参数规模从 7B到65B的基础语言模'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 45, 'page_label': '46'}, page_content='院、清华大学  CPM -1，CPM -2，\nCPM -3，CPM -Bee 1B，2B，2.6B，5B，\n7B，10B，11B，198B  \n盘古系列  鹏城实验室、华为\nMindSpore 、 华为诺亚方\n舟实验室、北京大学  盘古α  350M，2.6B，13B \n \n（1）LLaMA系列  \nLLaMA系列模型 [30]是一组参数规模从 7B到65B的基础语言模\n型，它们都是在数万亿个字符上训练的，展示了如何仅使用公开可用\n的数据集来训练最先进的模型， 而不需要依赖专有或不可访问的数据\n集。这些数据集包括 Common Crawl 、Wikipedia 、OpenWebText2 、\nRealNew s、Books等。 LLaMA模型使用了大规模的数据过滤和清洗\n技术，以提高数据质量和多样性，减少噪声和偏见。 LLaMA模型还\n使用了高效的数据并行和流水线并行技术，以加速模 型的训练和扩\n展。特别地， LLaMA 13B 在CommonsenseQA 等9个基准测试中超\n过了 GPT-3 (175B) ，而 LLaMA 65B 与最优秀的模型 Chinchilla -70B'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 45, 'page_label': '46'}, page_content='RealNew s、Books等。 LLaMA模型使用了大规模的数据过滤和清洗\n技术，以提高数据质量和多样性，减少噪声和偏见。 LLaMA模型还\n使用了高效的数据并行和流水线并行技术，以加速模 型的训练和扩\n展。特别地， LLaMA 13B 在CommonsenseQA 等9个基准测试中超\n过了 GPT-3 (175B) ，而 LLaMA 65B 与最优秀的模型 Chinchilla -70B\n和PaLM -540B相媲美。 LLaMA通过使用更少的字符来达到最佳性能，\n从而在各种推理预算下具有优势。与 GPT系列相同， LLaMA模型也\n采用了 decoder -only架构， 但同时结合了一些前人工作的改进， 例如：\nPre-normalization ，为了提高训练稳定性， LLaMA对每个 Transforme r\n子层的输入进行了 RMSNorm 归一化， 这种归一化方法可以避免梯度\n爆炸和消失的问题， 提高模型的收敛速度和性能； SwiGLU 激活函数，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 46, 'page_label': '47'}, page_content='46 将ReLU非线性替换为 SwiGLU 激活函数， 增加网络的表达能力和非\n线性，同时减少参数量和计算量； RoPE位置编码，模型的输入不再\n使用位置编码，而是在网络的每一层添加了位置编码， RoPE位置编\n码可以有效地捕捉输入序列中的相对位置信息， 并且具有更好的泛化\n能力。这些改进使得 LLaMA模型在自然语言理解、生成、对 话等任\n务上都取得了较好的结果。  \n（2）Falcon系列  \nFalcon [31]系列模型是由位于阿布扎比的技术创新研究院  \n(Technology Innovation Institute, TII) 创建的生成式语言大模型，其基\n于 Apache 2.0 许可发布。 Falcon 大模型家族目前主要包含三个基础\n模型 : Falcon -7B，Falcon -40B，以及 Falcon -180B。三个模型都是在\nRefinedWe 数据集上训练的， 该数据集经历了 广泛的过滤和去重过程，\n以确保高质量的训练数据。 同时， 三个模型均可 用于研究和商业用途。\nFalcon-7B基于解码器模型架构， 并在精心处理的 RefinedWeb 数据集'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 46, 'page_label': '47'}, page_content='模型 : Falcon -7B，Falcon -40B，以及 Falcon -180B。三个模型都是在\nRefinedWe 数据集上训练的， 该数据集经历了 广泛的过滤和去重过程，\n以确保高质量的训练数据。 同时， 三个模型均可 用于研究和商业用途。\nFalcon-7B基于解码器模型架构， 并在精心处理的 RefinedWeb 数据集\n上使用 1.5万亿个字符预训练。除此之外，使用多查询注意力机制增\n强推理时的可扩展性，并显著降低显存需求。 Falcon -40B拥有 400亿\n参数，并在 1万亿字符上进行了训练。在发布后的两个月里，其在\nHugging Face 的开源语言大模型排行榜上排名第一。该系列最新的\nFalcon 180B 具有 1800亿参数的，在 3.5万亿字符上进行预训练。该\n模型在推理、编码、熟练度和知识测试等各种任务中表现出色，在\nHugg ing Face 的开源语言大模型排行榜上击败了 Meta的\nLLaMA2 -70B等竞争对手。在 闭源模型中，它的排名仅次于 OpenAI\n的GPT 4，性能与谷歌的 PaLM 2 Large 相当，但只有其模型的一半'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 46, 'page_label': '47'}, page_content='Falcon 180B 具有 1800亿参数的，在 3.5万亿字符上进行预训练。该\n模型在推理、编码、熟练度和知识测试等各种任务中表现出色，在\nHugg ing Face 的开源语言大模型排行榜上击败了 Meta的\nLLaMA2 -70B等竞争对手。在 闭源模型中，它的排名仅次于 OpenAI\n的GPT 4，性能与谷歌的 PaLM 2 Large 相当，但只有其模型的一半\n参数量大小。  \n（3）Pythia系列  \nPythia [91]系列模型是由非营利性人工智能实验室 EleutherAI 开\n发的一系列生成式语言大模型。该系列有 16个不同参数量的模型'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 47, 'page_label': '48'}, page_content='47 （70M -12B） ，均是以完全相同的顺序在现有的公开数据集（ Pile）上\n训练的。每个模型都提供了 154个模型检查点的公 开访问权限，并且\n提供下载和清洗重组数据的工具，以便进一步研究。 EleutherAI 使用\n相同的架构训练了 2套Pythia版本。每一套包含 8个模型，涵盖 8\n种不同的模型尺寸。一套是直接在 Pile上训练的，另一套则在经过\nMinHashLSH 近重复处理后的 Pile上进行训练，阈值设置为 0.87。经\n过去重处理后 Pile大约包含 207B个字符，而原始 Pile包含 300B个\n字符。由于 Pythia系列模型在相同架构基础上涵盖多个不同尺寸，\nPythia很适合被用来研究诸如性别偏见、记忆能力和 少样本学习等属\n性如何收到精确训练数据处理和模型规模的影响。目前， Pythia系列\n的模型可以在开源模型网站 Hugging  Face上直接获取，也可以通过\nGithub的官方页面获取。  \n（4）T5系列  \nT5[42]模型是由 Google  Brain团队在 2019年提出的一 种基于'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 47, 'page_label': '48'}, page_content='Pythia很适合被用来研究诸如性别偏见、记忆能力和 少样本学习等属\n性如何收到精确训练数据处理和模型规模的影响。目前， Pythia系列\n的模型可以在开源模型网站 Hugging  Face上直接获取，也可以通过\nGithub的官方页面获取。  \n（4）T5系列  \nT5[42]模型是由 Google  Brain团队在 2019年提出的一 种基于\nTransformer 结构的序列到序列（ Seq2Seq）模型，其主要特点是将多\n种NLP任务（如翻译、摘要、问答等）转化为一个统一的框架下进\n行训练，使用文本到文本的统一模型范式，保证了模型的灵活性。 T5\n模型使用了混合精度训练 和自适应优化器来加速训练过程， 并且使用\n了数据过滤和动态批处理来提高数据效率。 T5模型在多个 NLP任务\n上都取得了较好的效果，证明了其优秀的泛化能力和迁移能力。 T5\n模型在预训练阶段使用了 C4数据集， 这是一个包含了超过 750GB的\n英文网页文本数据的大规模语料库。 T5模型还探索了不同规模的模\n型架构和参数量，从小到大分别有 small、base、large、XL、XXL和'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 47, 'page_label': '48'}, page_content='了数据过滤和动态批处理来提高数据效率。 T5模型在多个 NLP任务\n上都取得了较好的效果，证明了其优秀的泛化能力和迁移能力。 T5\n模型在预训练阶段使用了 C4数据集， 这是一个包含了超过 750GB的\n英文网页文本数据的大规模语料库。 T5模型还探索了不同规模的模\n型架构和参数量，从小到大分别有 small、base、large、XL、XXL和\nXXXL六种规模。其中， XXXL规模的 T5模型拥有 110亿个参数，\n是发布时最大的基于 Transformer 的预训练 语言模型之一。  \n（5）BLOOM 系列  \nBigScience 在2022年提出了 BLOOM 系列模型 [92]。BLOOM 拥'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 48, 'page_label': '49'}, page_content='48 有1760亿参数量， 是一种基于 Transformer 解码器架构的语言大模型，\n并在 46种自然语言和 13种编程语言上进行预训练。 为了 能够更好的\n提升 BLOOM 模型的多语能力， 研究者采用了渐进的方式来选择语料\n库中包含的语言。此 外， BLOOM 对原始的 Transformer 架构提出了\n许多的更改。相比于在嵌入层添加位置信息， BLOOM 采用了 ALiBi\n技术，基于 keys和queries二者之间距离来计算注意力分数。虽然\nALiBi技术拥有外推至更长的序列的能力，但其在原始序列上也能够\n带来更稳定的训练过程以及更好的下游表现， 比可学习位置编码和旋\n转位置编码取得了更好的效果。 BLOOM 在嵌入层之后后立即进行层\n归一化，显著的改善训练稳定性。由于训练数据较为多样，与单语言\n分词器相比， BLOOM 最终确定的词表尺寸为 25万个字符，以支持\n多种语言。 BLOOMZ 与BLOOM 拥有相同的模型架构与超参数，在\n包含 130亿字符的文本上进行微调， 通过独立的验证集来选择最优的\n模型。使用了 包含 10-60亿字符的文本进行微调之后，模型的性能趋'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 48, 'page_label': '49'}, page_content='归一化，显著的改善训练稳定性。由于训练数据较为多样，与单语言\n分词器相比， BLOOM 最终确定的词表尺寸为 25万个字符，以支持\n多种语言。 BLOOMZ 与BLOOM 拥有相同的模型架构与超参数，在\n包含 130亿字符的文本上进行微调， 通过独立的验证集来选择最优的\n模型。使用了 包含 10-60亿字符的文本进行微调之后，模型的性能趋\n于平稳。此外，对于 13亿参数量和 71亿参数量的版本，研究者使用\n了SGPT Bi -Encoder方案进行对比 微调。通过训练，可以得到拥有高\n质量文本嵌入的模型。近期的基准测试发现，这种模型也能够推广到\n其他的嵌入任务，例如 bitext挖掘、重排或者特征抽 取等任务。  \n（6）GPT-Neo \nGPT-Neo [93]系列模型是由 EleutherAI 开发的预训练语言大模\n型。GPT-Neo基于 OpenAI的GPT系列语言模型的架构， 但是采用了\n分散、社区 驱动的方法进行训练。 GPT-Neo模型在发布之时，因其较\n大的参数规模和在各种自然语言处理任务中出色的表现而备受关注。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 48, 'page_label': '49'}, page_content='其他的嵌入任务，例如 bitext挖掘、重排或者特征抽 取等任务。  \n（6）GPT-Neo \nGPT-Neo [93]系列模型是由 EleutherAI 开发的预训练语言大模\n型。GPT-Neo基于 OpenAI的GPT系列语言模型的架构， 但是采用了\n分散、社区 驱动的方法进行训练。 GPT-Neo模型在发布之时，因其较\n大的参数规模和在各种自然语言处理任务中出色的表现而备受关注。\n该模型的最大版本， GPT-Neo 2.7B ，有 27亿个参数。它是在多样化\n的互联网文本数据上进行训练的，包括书籍、文章和网页，并且已经\n被证明在广泛的自然语言处理任务上表现良好，如语言生成、摘要和\n问答。除此之外，其还包含 125M, 350M 和1.3B等不同参数规模。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 49, 'page_label': '50'}, page_content='49 GPT-Neo项目的一个独特之处在于其强调开源开发和社区参与。\nEleutherAI 公开了该模型的训 练权重，使其他研究人员和开发人员能\n够使用和构建该模型，并开发出许多相关的应用和 GPT-Neo模型的\n扩展，包括对特定任务的微调和修改，以提高其在某些特定类型的数\n据上的效率或性能。  \n（7）OPT系列  \nOPT [94]模型是由 Meta  AI发布的一 款decode r-only模型，与\nGPT-3相媲美。 尽管 GPT-3在零样本学习和少样本学习方面表现出优\n秀的能力，但其庞大的训练成本和权重未完全开源的问题，限制了研\n究社区的相关研究进展。为了应对这些挑战， Meta AI发布了 OPT模\n型，其参数规模从 125M到175B不等，并开源了相关的实验代码。\n此外，团队还公开了详细的训练日志，深入解释了他们的决策背后的\n原因和动机，为研究社区的使用和进一步研究提供了重要的参考资\n源。关于训练成本， OPT-175B的性能相当，但训练代价仅为 GPT-3\n的七分之一。在构建训练语料方面， OPT使用了多个高质量语料库，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 49, 'page_label': '50'}, page_content='型，其参数规模从 125M到175B不等，并开源了相关的实验代码。\n此外，团队还公开了详细的训练日志，深入解释了他们的决策背后的\n原因和动机，为研究社区的使用和进一步研究提供了重要的参考资\n源。关于训练成本， OPT-175B的性能相当，但训练代价仅为 GPT-3\n的七分之一。在构建训练语料方面， OPT使用了多个高质量语料库，\n包括 RoBERTa 的BookCorpus 和Stories，以及更新的 CCNews 版本，\n还有 Pile的CommonCrawl 、DM Mathematics 、Project Gutenbe rg、\nHackerNews 、OpenSubtitles 、OpenWebText2 、USPTO和Wikipedia 。\n所使用的这些语料库都经过了严格的收集和过滤， 以确保数据的质量\n和可用性。  \n（8）MPT系列  \nMPT（MosaicML Pretrained Transfo rmer） 系列模型是由 Mosa icML\n研发的开源可商 用模型。 MPT -7B在2023年5月发布，有'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 49, 'page_label': '50'}, page_content='HackerNews 、OpenSubtitles 、OpenWebText2 、USPTO和Wikipedia 。\n所使用的这些语料库都经过了严格的收集和过滤， 以确保数据的质量\n和可用性。  \n（8）MPT系列  \nMPT（MosaicML Pretrained Transfo rmer） 系列模型是由 Mosa icML\n研发的开源可商 用模型。 MPT -7B在2023年5月发布，有\nMPT -7B-Instruct、MPT -7B-Chat以及 MPT -7B-StoryWriter -65k+三个版\n本， 其中 MPT -7B-StoryWriter -65k+支持 65K长度的上下文 输入。 2023\n年6月， MPT -30B发布，拥有比 MPT -7B更强大的性能，超过了原\n始的 GPT-3。跟 MPT -7B一样， MPT -30B也有两个经过微调的变体：'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 50, 'page_label': '51'}, page_content='50 MPT -30B-Instruct和MPT -30B-Chat， 它们在单轮指令跟随和多轮对话\n方面表现出色。 MPT -30B在训练时使用 8,000 字符长度的上下文窗\n口、通过 ALiBi [95]支持更长上下文以及通过 FlashAttention 实现高效\n的推理和训练性能。得益于预训练数据混合比例的控制， MPT -30B\n系列还具有强大的编程能力。  \n（9）ERNIE系列  \n2019年，百度将大规模知识与海量数据融合学习的方法，在超\n大规模模型中引入丰富语言知识与世界知识， 突破多源异构数据难以\n统一表示与学习的瓶颈，显著提升了模型效果和学习效率，并在国内\n开源首个中文预训练大模型 。ERNIE [96]自发布以来在语言理解、文\n本生成、跨模态语义理解等领域取得多项技术突破，在权威公开数据\n集上取得世界最好效果总计 90余项，在国际权威语义评测 GLUE、\nSuperGlue 等评测上， 取得 世界冠军 20余项。 系列模型在金融、 通信、\n企业服务、互联网等行业取得广泛应用，极大促进该领域在国内的研'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 50, 'page_label': '51'}, page_content='开源首个中文预训练大模型 。ERNIE [96]自发布以来在语言理解、文\n本生成、跨模态语义理解等领域取得多项技术突破，在权威公开数据\n集上取得世界最好效果总计 90余项，在国际权威语义评测 GLUE、\nSuperGlue 等评测上， 取得 世界冠军 20余项。 系列模型在金融、 通信、\n企业服务、互联网等行业取得广泛应用，极大促进该领域在国内的研\n究和产业发展。 ERNIE 3.0  [97]大模型最高参数量达到 1000亿，首次\n在百亿级预训练模型中引入大规模知识图谱， 提出 了海量无监督文本\n与大规模知识图谱的平行预训练方法， 促进了结构化知识和无结构文\n本之间的信息共享，大幅提升了模型对于知识的记忆和推理能力。  \n（10）GLM系列  \nGLM [98]系列模型是清华大学和智谱 AI等合作研发的开源语言\n大模型。 GLM采用了自回归填空作为预训练任务，并且使用多任务\n预训练的方式提升模型生成长文本的能力和序列到序列任务的能力。\n为了能够更好地进行预训练， GLM采用了二维位置编码，第一维表\n示当前位置的原文本 中的位置信息， 第二维表示对应 的掩码的位置信'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 50, 'page_label': '51'}, page_content='（10）GLM系列  \nGLM [98]系列模型是清华大学和智谱 AI等合作研发的开源语言\n大模型。 GLM采用了自回归填空作为预训练任务，并且使用多任务\n预训练的方式提升模型生成长文本的能力和序列到序列任务的能力。\n为了能够更好地进行预训练， GLM采用了二维位置编码，第一维表\n示当前位置的原文本 中的位置信息， 第二维表示对应 的掩码的位置信\n息。此外，为了能够尽量推理和训练所占用的显存， GLM -130B可以\n使用 INT4进行量化并且不会明显影响模型效果。通过优化，\nGLM -130B可以在 4张RTX 3090 Ti （24G）显卡或 8张RTX 208 0 Ti'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 51, 'page_label': '52'}, page_content='51 （11G）的显卡上进 行推理。 ChatGLM 是基于 GLM结构开发的具有\n62亿参数量的语言大模型，支持 2048的上下文长度。其使用了包含\n1万亿字符的中英文语料进行训练，能够支持中文和英文两种语言的\n任务。 通过监督微调、 反馈自助、 人类反馈强化学习等多种训练技术，\nChatGLM 拥有强大的生成能力，能够生成更符合人类偏好的内容。\n与GLM相似，通过 INT4量化和 P-Tuning v2 [99]等高效微调的算法，\nChatGLM 能够在 7G显存的条件下进行微调。 在 ChatG LM的基础上，\nChatGLM 2 使用了包含 1.4万亿字符的中英预料进行预训练，并使用\n人类偏好的数据对模型进行对齐训练， 拥有比前一版本更加强大的能\n力，在多个任务上取得提升。通过 FlashAttention 技术， ChatGLM 2\n能够处理更长的长下文， 支持的长下 文长度达到了 3.2万字符。 此外，\n通过 Multi -Query Attention 技术， ChatGLM 2 能够进一步地提升推理\n速度，减小对显卡的显存占用。  \n（11）Baichuan 系列'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 51, 'page_label': '52'}, page_content='人类偏好的数据对模型进行对齐训练， 拥有比前一版本更加强大的能\n力，在多个任务上取得提升。通过 FlashAttention 技术， ChatGLM 2\n能够处理更长的长下文， 支持的长下 文长度达到了 3.2万字符。 此外，\n通过 Multi -Query Attention 技术， ChatGLM 2 能够进一步地提升推理\n速度，减小对显卡的显存占用。  \n（11）Baichuan 系列  \nBaichuan 是由百川智能开发的开源可商用的语言大模型， 在权威\n的中文和英文  benchma rk 上均取得同尺寸最好的效果，其基于\nTransformer 解码器架构。 Baichuan -7B是在大约 1.2万亿字符上训练\n的70亿参数模型，支持中英双语，最大 4096的上下文窗口长度。\nBaichuan -13B在 Baichuan -7B 的基础上进一步扩大参数量到  130 \n亿， 并且在高质量的语料上训练了  1.4 万亿  字符， 超过  LLaMA -13B \n40%，是当前开源  13B 尺寸下训练数据量最多的模型。其支持中英'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 51, 'page_label': '52'}, page_content='的70亿参数模型，支持中英双语，最大 4096的上下文窗口长度。\nBaichuan -13B在 Baichuan -7B 的基础上进一步扩大参数量到  130 \n亿， 并且在高质量的语料上训练了  1.4 万亿  字符， 超过  LLaMA -13B \n40%，是当前开源  13B 尺寸下训练数据量最多的模型。其支持中英\n双语，使用  ALiBi 位置编码，最大 4096的上下文窗口长 度，使用\nrotary -embedding ， 是现阶段被大多数模型采用的位置编码方案， 具有\n很好的外推性。百川同时开源了预训练和对齐模型，预训练模型是面\n向开发者的“基座” ，而对齐模型则面向广大需要对话功能的普通用\n户。 除了原始权重， 为实现更高效的推理， 百川开源了  INT8 和 INT4 \n的量化版本， 相对非 量化版本在几乎没有效果损失的情况下大大降低'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 52, 'page_label': '53'}, page_content='52 了部署的机器资源需求。 Baichuan2 -7B 和 Baichuan2 -13B，均基于  \n2.6 万亿高质量多语言数据进行训练，在保留了上一代开源模型良好\n的生成与创作能力， 流畅的多轮对话能力以及部署门槛较低等众 多特\n性的基础上，两个模型在数学、代码、安全、逻辑推理、语义理解等\n能力有显著提升。  \n（12）CPM系列  \nCPM系列模型由北京智源人工智能研究院和清华大学的合作研\n发，目前包括了 CPM -1、CPM -2，CPM -3和CPM -Bee典型模型。\nCPM -1[33]，作为首款中文大规模预训练语言模型，拥有 26亿参数。\n其预训练任务采用了经典的自回归语言模型，以 100GB数据为基础，\n包括大量丰富多样的中文语料，包括百科、小说、对话、问答、新闻\n等类型。在多个公开的中文数据集上的实验表明， CPM -1在对话、\n文本生成等各类下游任务中，无论是少样本学习还是零样本学习， 都\n表现出卓越的性能。 CPM -2[34]模型采用“编码器 -解码器”框架，通\n过词表优化、知识继承 、混合专家化 等技术，显著缓解了大规模预训'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 52, 'page_label': '53'}, page_content='包括大量丰富多样的中文语料，包括百科、小说、对话、问答、新闻\n等类型。在多个公开的中文数据集上的实验表明， CPM -1在对话、\n文本生成等各类下游任务中，无论是少样本学习还是零样本学习， 都\n表现出卓越的性能。 CPM -2[34]模型采用“编码器 -解码器”框架，通\n过词表优化、知识继承 、混合专家化 等技术，显著缓解了大规模预训\n练模型训练的计 算开销对应用的使用限制。 CPM -3是基于 BMTrain\n高效训练框架实现， 在预训练阶段采用多样化的任务设计和提示模板\n预训练技术，在零样本和少样本场景中表现出色。 CPM -Bee的是一\n个完全开源、允许商用的百亿参数中英文基座模 型。它采用  \nTransformer 自回归架构，通过对预训练预料进行严格后处理提升数\n据质量，最终在万亿级高质量数据上完成预训练，进一步强化了模型\n的基础能力。  \n（13）盘古系列  \n鹏程 ·盘古α [100]  由以鹏城实验室为首的技术团队联合协作开\n发的，他们首次利用“鹏城云脑Ⅱ”和国产 MindSpore 框架，采用自\n动混合并行模式，在 2048卡算力集群上进行大规模分布式训练，训'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 52, 'page_label': '53'}, page_content='Transformer 自回归架构，通过对预训练预料进行严格后处理提升数\n据质量，最终在万亿级高质量数据上完成预训练，进一步强化了模型\n的基础能力。  \n（13）盘古系列  \n鹏程 ·盘古α [100]  由以鹏城实验室为首的技术团队联合协作开\n发的，他们首次利用“鹏城云脑Ⅱ”和国产 MindSpore 框架，采用自\n动混合并行模式，在 2048卡算力集群上进行大规模分布式训练，训\n练出业界首个以中文为核心 2000亿参数的预训练生成语言模型。鹏'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 53, 'page_label': '54'}, page_content='53 程.盘古α具备丰富的应用场景，如知识问答、知识检索、知识推理、\n阅读理解等，并且拥有很强的小样本学习能力。鹏程 .盘古α收集了\n近80TB的原始数据，包括开源数据集、 comm on crawl网页数据、电\n子书等，搭建了面向大型语料库预处理的分布式集群，通过数据清洗\n过滤、去重、质量评估等处理流程，构建了一个约 1.1TB的高质量中\n文语料数据集。研究对比了智源研究院发布的首个 26亿参数的中文\n预训练语言模型「悟道·文源」 CPM，通过在 1.1TB数据中策略抽样\n了100GB等量数据集训练了 2.6B参数规模的「鹏程 .盘古α」模型，\n并在已收集的 16个下游任 务上进行了对比。实验结果表明，鹏程 .盘\n古α -2.6B比CPM -2.6B模型具有更强的语言学习能力，特别是在生\n成任务和小样本学习方面。实验还对比了鹏程 .盘古α -13B和鹏程 .盘\n古α -2.6B模型的性能。在所有的生成任务和大部分的 PPL任务上，\n13B的模型性能优于 2.6B，说明鹏程 .盘古α -13B模型具有较强的小\n样本学习能力。  \n4.2.2 典型开源多模态大模型'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 53, 'page_label': '54'}, page_content='古α -2.6B比CPM -2.6B模型具有更强的语言学习能力，特别是在生\n成任务和小样本学习方面。实验还对比了鹏程 .盘古α -13B和鹏程 .盘\n古α -2.6B模型的性能。在所有的生成任务和大部分的 PPL任务上，\n13B的模型性能优于 2.6B，说明鹏程 .盘古α -13B模型具有较强的小\n样本学习能力。  \n4.2.2 典型开源多模态大模型  \n开源模型  单位  包含模型  参数量  \nKOSMOS -2 微软  - 1.6B  \nOpenFlami ngo 微软  MPT  9B \nBLIP -2 Salesforce  OPT, FlanT5  12B \nInstructBLIP  Salesforce  LLaMA  7B, 13B  \nMiniGPT -4 KAUST  LLaMA  7B \nLLaMA -Adapter V2  上海人工智能实\n验室  LLaMA  7B \nImageBind  Meta  ViT, CLIP  - \nChatBridge  中科院自动化所  LLaMA  7B'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 53, 'page_label': '54'}, page_content='InstructBLIP  Salesforce  LLaMA  7B, 13B  \nMiniGPT -4 KAUST  LLaMA  7B \nLLaMA -Adapter V2  上海人工智能实\n验室  LLaMA  7B \nImageBind  Meta  ViT, CLIP  - \nChatBridge  中科院自动化所  LLaMA  7B \nVisualGLM -6B  清华大学  ChatGLM  7.8B  \nVisCPM  清华大学  CPM-Bee 10B \nmPLUG -Owl 阿里巴巴  LLaMA  7B \nQwen -VL 阿里巴巴  Qwen  9.6B  \n（1）KOSMOS -2'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 54, 'page_label': '55'}, page_content='54 KOSMOS -2[101]是微软亚洲研究院在 KOSMOS -1模型的基础上\n开发的多模态大模型。其中， KOSMOS -1是在大规模多模 态数据集\n上重头训练的，该模型具有类似 GPT-4的多模态能力，可以感知一般\n的感官模态，在上下文中学习（即少样本学习）并能够遵循语音指示\n（即零样本学习） 。 KOSMOS -2 采用与  KOSMOS -1 相同的模型架构\n和训练目标对模型进行训练 , 并在此基础上新增了对图像局部区域\n的理解能力。  \n（2）OpenFlamingo  \nOpenFlamingo [102]模型是 DeepMind Flamingo 模型的开源复现\n版，可实现多模态大模型的训练和评估。 OpenFlamingo 使用交叉注\n意力将一个预训练的视觉编 码器和一个语言大模型结合在一起。 它是\n在大型多模态数据集（例如  Multimodal C4 ）上进行训练，可以实现\n以交错的图像 /文本为输入来进行文本生成。例如， OpenFlamingo 可\n用于生成图像的标题，或者根据图像和文本段落生成问题等。这使得\n其能够使用上下 文学习快速适应新任务。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 54, 'page_label': '55'}, page_content='意力将一个预训练的视觉编 码器和一个语言大模型结合在一起。 它是\n在大型多模态数据集（例如  Multimodal C4 ）上进行训练，可以实现\n以交错的图像 /文本为输入来进行文本生成。例如， OpenFlamingo 可\n用于生成图像的标题，或者根据图像和文本段落生成问题等。这使得\n其能够使用上下 文学习快速适应新任务。  \n（3）BLIP -2 \nBLIP -2[82]通过一个轻量级的查询转换器弥补了模态之间的差\n距，该转换器分两个阶段进行预训练。第一阶段从冻结图像编码器引\n导视觉语言表 示学习。 第二阶段将视觉从冻结的语言模型引导到语言\n生成学习。 BLIP -2在各种视觉语言任务上实现了最先进的性能，尽\n管与现有方法相比，可训练的参数明显更少。例如， BLIP -2模型在\n零样本 VQAv2上比 Flamingo 80B 高8.7%， 可训练参数减少了 54倍。 \n（4）InstructBLIP  \nInstructBLIP [103]的特点是设计了一种 视觉语言指令 微调方法 ，\n它基于预训练的 BLIP -2模型，对视觉语言指令进行 微调。具体地，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 54, 'page_label': '55'}, page_content='管与现有方法相比，可训练的参数明显更少。例如， BLIP -2模型在\n零样本 VQAv2上比 Flamingo 80B 高8.7%， 可训练参数减少了 54倍。 \n（4）InstructBLIP  \nInstructBLIP [103]的特点是设计了一种 视觉语言指令 微调方法 ，\n它基于预训练的 BLIP -2模型，对视觉语言指令进行 微调。具体地，\nInstructBlip 复用了 BLIP -2的结构，有一个 图像编码器 ，一个语言大\n模型和一个 Q-Former模块来连接前两者。并且 采用了指令感知的 视'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 55, 'page_label': '56'}, page_content='55 觉特征提取 过程 , 指令不仅会指导 语言大模型 生成文本，同时也会指\n导图像编码器 提取不同的视觉特征。这样的好处在于对于同一张图\n片，根据不同的 指令，可以得到基于 指令偏好更强 的视觉特征，同时\n对于两个不一样的图片，基于 指令内嵌的通用知识，可以使得模型有\n更好的知识迁移效果。  \n（5）MiniGPT -4 \nMiniGPT -4[104]使用语言大模型来 增强视觉语言理解，将语言能\n力与图像能力结合。其利用视觉编码器和语言大模型 Vicuna [109]进\n行结合训练。具体地， MiniGPT -4使用一个投影层来将来自 BLIP -2\n的冻结视觉编码器与冻结的 Vicuna语言大模型 （基于 LLaMA指令微\n调得到） 对齐。并通过两个阶段来训练 MiniGPT -4。第一个预训练阶\n段使用大约 500万个图像 -文本对进行 视觉 -语言对齐 训练。第二个微\n调阶段进行多模态指令微调 以提高其生成可靠 性和整体可用性。\nMiniGPT -4能够产生许多类似于 GPT-4中展示的新兴视觉语言能力。  \n（6）LLaMA -Adapter V2'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 55, 'page_label': '56'}, page_content='调得到） 对齐。并通过两个阶段来训练 MiniGPT -4。第一个预训练阶\n段使用大约 500万个图像 -文本对进行 视觉 -语言对齐 训练。第二个微\n调阶段进行多模态指令微调 以提高其生成可靠 性和整体可用性。\nMiniGPT -4能够产生许多类似于 GPT-4中展示的新兴视觉语言能力。  \n（6）LLaMA -Adapter V2  \nLlaMA -Adapter V2 [105]是一种参数高效的视觉指令模型。具体\n地，首先通过解锁更多可学习参数（例如范数、偏差和比例）来增强  \nLlaMA A dapter，这些参数将指令遵循能力分布到整个 LLaMA 模型\n中。其次， 采用了一种早期融合策略，将视觉标记提供给早期的 语言\n大模型，有助于更好地整合视觉知识。然后，通过 优化不相 交的可学\n习参数组，引入了图像 -文本对和指令跟随 数据的联合训练范式。该\n策略有效地缓解了图文对齐和指令跟随这两个任务之间的干扰， 仅用\n小规模的图文和指令数据集就实现了强多模态推理。在推理过程中，\n该模型将额外的专家模型（例如字幕 /OCR 系统）合 并到'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 55, 'page_label': '56'}, page_content='中。其次， 采用了一种早期融合策略，将视觉标记提供给早期的 语言\n大模型，有助于更好地整合视觉知识。然后，通过 优化不相 交的可学\n习参数组，引入了图像 -文本对和指令跟随 数据的联合训练范式。该\n策略有效地缓解了图文对齐和指令跟随这两个任务之间的干扰， 仅用\n小规模的图文和指令数据集就实现了强多模态推理。在推理过程中，\n该模型将额外的专家模型（例如字幕 /OCR 系统）合 并到  \nLLaMA -Adapter 中，以进一步增强其图像理解能力。  \n（7）ImageBind  \nImageBind [106]是Meta发布的模型， 它的目标是利用图像为中心'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 56, 'page_label': '57'}, page_content='56 绑定学习一个嵌入空间， 将文本、图像 /视频、音频、深度（ 3D） 、热\n（红外辐射）和 惯性测量单元（ IMU）六个模态 的数据都投影到这同\n一个嵌入空间中。 进而，在这个空间中 可以实现跨模态 检索和匹配等\n任务，此外将该模型与生成模型结合，还可实现音频生成图像、图像\n生成音频等应用效果。  \n（8）ChatBridge  \nChatBridge [88]是一个新 型的多模态对话模型，利用语言的表达\n能力作为桥梁，以连接各种模式之间的差异，可支持 文本、图像、视\n频、音频几个模态任 意组合的模型输入与输出信息。该模型包括两阶\n段的训练 ，首先是每个 模态与语言对齐，提升跨模态相关性和协同学\n习能力，接下来是多任务 的指令微调，使其与用户的意图对齐。\nChatBridge 在面向文本、图像、音频与视频等模态信息的广泛下游任\n务中表现出优异的零样本学习能力。  \n（9）Visua lGLM -6B \nVisualGLM -6B[107]是由语言模型 ChatGLM -6B与图像模型\nBLIP2-Qformer结合而得到的一个多模态大模型，其能够整合视觉和'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 56, 'page_label': '57'}, page_content='习能力，接下来是多任务 的指令微调，使其与用户的意图对齐。\nChatBridge 在面向文本、图像、音频与视频等模态信息的广泛下游任\n务中表现出优异的零样本学习能力。  \n（9）Visua lGLM -6B \nVisualGLM -6B[107]是由语言模型 ChatGLM -6B与图像模型\nBLIP2-Qformer结合而得到的一个多模态大模型，其能够整合视觉和\n语言信息。 可以用来理解图片， 解析图片内容。 该模型依赖于 CogView\n数据集中 3000万个高质量的中文图像 -文本对，以及 3亿个精选的英\n文图像 -文本对进行预训练。这种方法使视觉信息能够很好地 与\nChatGLM 的语义空间对齐。 在微调阶段，该模型在长视觉问答数据\n集上进行训练，以生成符合人类偏好的答案。  \n（10）VisCPM  \nVisCPM [108]是一个多模态大模型系 列，其中的 VisCPM -Chat模\n型支持中英双语的多模态对话能力，而 VisCPM -Paint模型支持文到\n图生成能力。 VisCPM基于百亿参数量语言大模型 CPM -Bee（10B）'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 56, 'page_label': '57'}, page_content='ChatGLM 的语义空间对齐。 在微调阶段，该模型在长视觉问答数据\n集上进行训练，以生成符合人类偏好的答案。  \n（10）VisCPM  \nVisCPM [108]是一个多模态大模型系 列，其中的 VisCPM -Chat模\n型支持中英双语的多模态对话能力，而 VisCPM -Paint模型支持文到\n图生成能力。 VisCPM基于百亿参数量语言大模型 CPM -Bee（10B）\n训练， 融合视觉编码器和基于扩散模型的视觉解码器以支持视觉信号\n的输入和输出。得益于 CPM -Bee基座的双语能力， VisCPM 可以仅'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 57, 'page_label': '58'}, page_content='57 通过英文多模态数据预训练，泛化实现中文多模态 能力。  \n（111）mPLUG -Owl \n阿里达摩 院的 mPLUG -Owl[110]大模型可以支持多种数据模态，\n包括图像、文本、音频等。它采用了预训练和微调的方法，通过使用\n大规模的预训练数据和对特定任务微调的数据， 可以快速高效地完成\n各种多模态任务。与传统的多模态模型相比， mPLUG -Owl有更高的\n准确率和更快的运行速度。 此外， 它还具有高度的灵活性和可扩展性，\n可以根据实际需要进行快速部署和优化。  \n（12）Qwen -VL \nQwen -VL[111]  是支持中英文等多种语言的视觉语言模型。\nQwen -VL 以通义千问  70 亿参数模型  Qwen -7B 为基座语言模型，\n在模型架构上引入视觉编码器，使得模型支持视觉信号输入，并通过\n设计训练过程，让模型具备对视觉信号的细粒度感知和理解能力。除\n了具备基本的图文识别、描述、问答及对话能 力之外， Qwen -VL还\n具备视觉定位、图像中文字理解等能力。  \n4.3 典型开源框架与工具'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 57, 'page_label': '58'}, page_content='Qwen -VL 以通义千问  70 亿参数模型  Qwen -7B 为基座语言模型，\n在模型架构上引入视觉编码器，使得模型支持视觉信号输入，并通过\n设计训练过程，让模型具备对视觉信号的细粒度感知和理解能力。除\n了具备基本的图文识别、描述、问答及对话能 力之外， Qwen -VL还\n具备视觉定位、图像中文字理解等能力。  \n4.3 典型开源框架与工具  \nPyTorch：PyTorch [27]自身提供了几种加速分布数据并行的技术，\n包括分桶梯度（ bucketing gradients ） 、通信和计算 的重叠（ overlapping \ncomputation with communication ） 以 及 在 梯 度 累 积 （ gradient \naccumulation ）阶段跳过梯度同步（ skipping gradient synchronization ）。\nPyTorch分布式数据并行可以用 256个 GPU 达到接近线性的可扩展\n性程度。在  DP 的基础上，原生支持  DDP，每个节点都有自己的本\n地模型副本和本地优化器，支持多机多卡的分布式训练。一般来说，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 57, 'page_label': '58'}, page_content='accumulation ）阶段跳过梯度同步（ skipping gradient synchronization ）。\nPyTorch分布式数据并行可以用 256个 GPU 达到接近线性的可扩展\n性程度。在  DP 的基础上，原生支持  DDP，每个节点都有自己的本\n地模型副本和本地优化器，支持多机多卡的分布式训练。一般来说，\nDDP 都显著快于  DP，能达到略低于卡数的加速比，但要求每块  \nGPU 卡都能装载完整输入维度的参数集合。 在  1.11 版本后， PyTorch  \n开始支持  FSDP 技术，可以更加高效的将部分使用完毕的参数移至\n内存中，显著减小了显存的峰值占用，更加吻合大模型的特性。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 58, 'page_label': '59'}, page_content='58 Tensorflow ：TensorFlow [112]是一款由 Google Brain 团队开发的\n开源机器学习框架，被广泛应用于各种深度学习领域。它可以处理多\n种数据类型，包括图像、语音和文本等，具备高度的灵活性和可扩展\n性。TensorFlow 使用数据流图计算模型来建立机器学习模型，用户可\n以通过定义操作和变量在数据流图上构建自己的神经网络模型。此\n外， TensorFlow 还提供了众多优化器、损失函数和数据处理工具，以\n便用户轻松进行模型训练和优化。 TensorFlow 在多个领域有广泛的应\n用，包括自然语言处理、图像识别和语音识别等。它可以灵活地运行\n在不同硬件平台上，包括 CPU、GPU和TPU等。 TensorFlow还提供\n了高级 API，使开发者可以快速构建、训练和部署深度学习模型。  \nPaddlePaddle ： 飞桨 （ PaddlePaddle [113]，Parallel Distributed  Deep \nLearning）是我国较早开源开放、自主研发、功能完备的产业级深度\n学习框架。 飞桨不仅在业内最早支持了万亿级稀疏参数模型的训练能'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 58, 'page_label': '59'}, page_content='了高级 API，使开发者可以快速构建、训练和部署深度学习模型。  \nPaddlePaddle ： 飞桨 （ PaddlePaddle [113]，Parallel Distributed  Deep \nLearning）是我国较早开源开放、自主研发、功能完备的产业级深度\n学习框架。 飞桨不仅在业内最早支持了万亿级稀疏参数模型的训练能\n力，而且 近期又创新性的提出了 4D混合并行策略，以训练千亿级稠\n密参数模型，可以说分布式训练是飞桨最具特色的技术之一。飞桨的\n分布式训练技术在对外提供之前就已经在百度内部广泛应用， 如搜索\n引擎、 信息流推荐、 百度翻译、 百度地图、 好看视频、 文心  ERNIE 等\n等，既包含网络复杂、稠密参数特点的计算机视觉 （CV）自然语言\n处理（ NLP）模型训练场景，又覆盖了有着庞大的  Embedding 层模\n型和超大数据量的推荐搜索训练场景。  \nMindSpore ：MindSpore [114]是一款适用于端边云全场景的开源\n深度学习训练 /推理框架 。MindSpore 能很好匹配昇腾处理器算力，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 58, 'page_label': '59'}, page_content='等，既包含网络复杂、稠密参数特点的计算机视觉 （CV）自然语言\n处理（ NLP）模型训练场景，又覆盖了有着庞大的  Embedding 层模\n型和超大数据量的推荐搜索训练场景。  \nMindSpore ：MindSpore [114]是一款适用于端边云全场景的开源\n深度学习训练 /推理框架 。MindSpore 能很好匹配昇腾处理器算力，\n在运行高效和部署灵活上具有很好的能力。 MindSpore 还具有无缝切\n换静态图动态图、 全场景覆盖、 新 AI编程范式等特点。 MindSpore 还\n提供了多种高层  API，如 MindArmour 、MindSpore Hub 、MindInsight \n等，方便开发者进行安全训 练、模型共享、可视化分析等操作。  \nJittor：Jittor [115]是一个基于即时编译和元算子的高性 能深度学'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 59, 'page_label': '60'}, page_content='59 习框架。 Jittor 集成了算子编译器和调优器，可以为模 型生成高性能\n的代码。 Jittor 与 PyTorch 兼容，可以方便地将  PyTorch 程序迁移\n到 Jittor 框架上。 Jittor 支持多种硬件平台，包括  CPU、GPU、TPU \n等。 Jittor 在框架层面也提供了许多优化功能，如算子融合、自动混\n合精度训练、内存优化等。  \nOneFlow ：OneFlow [116] [116]能够较好适用于 多机多卡训练场\n景，是国内较早发布的并 行计算框架。 OneFlow 会把整个分布式集\n群逻辑抽象成为一个超级设备， 用户可以从逻辑视角的角度使用超级\n设备。最新版本的  OneFlow 和 TensorFlow 一样，实现了同时 对动\n态图和静态图的支持， 而且动静图之间 转换十分方便。 此外， OneFlow\n兼容了 PyTorch，支持数据  + 模型的混合并行方式， 可提升并行计\n算性能。  \nColossal -AI：“夸父 ”（Colossal -AI[117]） ，提供了一系列并行组'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 59, 'page_label': '60'}, page_content='设备。最新版本的  OneFlow 和 TensorFlow 一样，实现了同时 对动\n态图和静态图的支持， 而且动静图之间 转换十分方便。 此外， OneFlow\n兼容了 PyTorch，支持数据  + 模型的混合并行方式， 可提升并行计\n算性能。  \nColossal -AI：“夸父 ”（Colossal -AI[117]） ，提供了一系列并行组\n件，通过多维并行、大 规模优化器、自适应任务调度、消除冗余内存\n等优化方式， 提升并行训练效率， 并解耦了系统优化与上层应用框架、\n下层硬件和编译器，易于扩展和使用。提升人工智能训练效率的同时\n最小化训练成本。在三方面进行了优化：优化任务调度、消除冗余内\n存、降低能量损耗。夸父从大模型实际训练部署过程中的性价比角度\n出发，力求易用性，无需用户学习繁杂的分布式系统知识，也避免了\n复杂的代码修改。仅需要极少量的改动，便可以使用夸 父将已有的单\n机 PyTorch 代码快速扩展到并行计算机集群上，无需关心并行编程\n细节。  \nMegatron -LM：Megra tron[118]  是 NVIDIA 提出的一种基于'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 59, 'page_label': '60'}, page_content='存、降低能量损耗。夸父从大模型实际训练部署过程中的性价比角度\n出发，力求易用性，无需用户学习繁杂的分布式系统知识，也避免了\n复杂的代码修改。仅需要极少量的改动，便可以使用夸 父将已有的单\n机 PyTorch 代码快速扩展到并行计算机集群上，无需关心并行编程\n细节。  \nMegatron -LM：Megra tron[118]  是 NVIDIA 提出的一种基于  \nPyTorch 分布式训练大规模语言模型的架构，用于训练基于  \nTransformer 架构的巨型语言模型。针对 Transformer 进行了专门的\n优化，主要采用的是模型并行的方案。 Megatron 设计就是为了支持超\n大的  Transformer 模型的训练的， 因此它不仅支持传统分布式训练的'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 60, 'page_label': '61'}, page_content='60 数据并行，也支持模型并行，包括  Tensor 并行和  Pipeli ne 并行两种\n模型并行方式。同时提出了更加精细的  pipeline 结 构与  \ncommunication 模式。通过多种并行方式 的结合，可以让大模型的训\n练更快。 将核心操作  LayerNorm 和 Dropout 安装输入维度 进一步切\n分， 使得这两个需要频繁运行的操作在不大幅增加通信开销的情况下\n实现了并行。  \nDeepSpeed ：在2021年2月份，微软发布了一款名为  \nDeepSpeed [29]的超大规模模型训练工具，其中包含了一种新的显存\n优化技术 ——零冗余优化器  ((Zero Redundancy Opt imizer, ZeRO ） 。 该\n技术去除了在分布式数据并行训练过程中存储的大量冗余信息， 从而\n极大地推进了大模型训练的 能力。从这个角度出发，微软陆续发布了  \nZeRO -1，ZeRO -2，ZeRO -3 和 ZeRO -3 Offload ， 基本实现了  GPU 规\n模和模型性能的线性增长。基于 DeepSpeed ，微软开发了具有 170亿'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 60, 'page_label': '61'}, page_content='技术去除了在分布式数据并行训练过程中存储的大量冗余信息， 从而\n极大地推进了大模型训练的 能力。从这个角度出发，微软陆续发布了  \nZeRO -1，ZeRO -2，ZeRO -3 和 ZeRO -3 Offload ， 基本实现了  GPU 规\n模和模型性能的线性增长。基于 DeepSpeed ，微软开发了具有 170亿\n参数的自然语言生成 模型，名为  Turing -NLG。2021年月，推出了能\n够支持训练 2000亿级别参数规模的 ZeRO -2。目前最新版本 ZeRO -3 \nOffload可以实现在 512颗V100上训练万亿参数规模的大模型。  \n4.4大模型的训练数据  \n数据是大模型的关键要素，其所需的数据的种类也非常广泛，涉\n及多种模态。以语言大模型为例，其所需要的数据包括多语言数据、\n代码数据、人工标注数据等多种类别。  \n4.4.1 大模型的训练数据处理流程和特点  \n根据大模型训练的尺度定律（ scaling law ） ，数据规模、模型参数\n与大模型性能存在紧密关系。近期，微软研究工作表明提高数据质量'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 60, 'page_label': '61'}, page_content='4.4大模型的训练数据  \n数据是大模型的关键要素，其所需的数据的种类也非常广泛，涉\n及多种模态。以语言大模型为例，其所需要的数据包括多语言数据、\n代码数据、人工标注数据等多种类别。  \n4.4.1 大模型的训练数据处理流程和特点  \n根据大模型训练的尺度定律（ scaling law ） ，数据规模、模型参数\n与大模型性能存在紧密关系。近期，微软研究工作表明提高数据质量\n可以极大地改变尺度定律 的形状。通过构建 7B的小规模 “教科书\n（Textbooks ）”高质量的代码训练数据（包括从 web上筛选的 “教科\n书质量 ”数据 （ 6B tokens ） 以及使用 GPT-3.5生成的教科书和练习 （ 1B \ntokens） ） ，训练 1.3B模型 phi-1在代码评测集 HumanEval 上Pass@1'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 61, 'page_label': '62'}, page_content='61 准确率达到了 50.6%，超越  GPT-3.5（175B，超过 2TB训练数据）的\n47%。该方法表明，通过 构建高质量的数据，可以大大降低大模型训\n练需要的数据规模，具有重要指导意义 。下面是几类用于提升数据质\n量的预处理方法 [119]。 \n质量过滤：语言大模型训练中需要过滤低质量数据，主要分为两\n类方法： 基于分类器的方法和基于启发式的方法。基于分类器的方法\n是训练一个文本质量判断模型，用以识别并过滤低质量数据。例如，\nGPT3、PaLM[17]和GLaM [120]模型在训练数据构造时都使用了基于\n分类器的方法。 而基于启发式的方法则是通过一组精心设计的规则来\n消除低质量文本，主要包括语言过滤、指标过滤、统计特征过 滤和关\n键词过滤，如 BLOOM 和Gopher [121]都采用了基于启发式的方法。  \n冗余去除：语言大模型训练语料库中的重复数据会影响模型性\n能，降低语言大模型的多样性，并可能导致训练 过程不稳定。因此需\n要对数据进行冗余去除。文本冗余发现（ Text Dupli cate Detection ）也'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 61, 'page_label': '62'}, page_content='消除低质量文本，主要包括语言过滤、指标过滤、统计特征过 滤和关\n键词过滤，如 BLOOM 和Gopher [121]都采用了基于启发式的方法。  \n冗余去除：语言大模型训练语料库中的重复数据会影响模型性\n能，降低语言大模型的多样性，并可能导致训练 过程不稳定。因此需\n要对数据进行冗余去除。文本冗余发现（ Text Dupli cate Detection ）也\n称为文本重复检测，是自然语言处理和信息检索中的基础任务之一。\n该方法用于数据处理可以发 现不同粒度上的文本重复，包括句子、段\n落以及文档等不同级别，可以有效改善语言模型的训练效果。  \n    隐私消除：预训练数据中可能包含涉及敏感或个人信息，增加隐\n私泄露的风险。对于此类问题，最直接的方法是采用基于规则的算法\n删除隐私数据。例如可以使用基于命名实体识别的算法，检测数据中\n姓名、地址和电话号码等个人信息内容，并进行删除或者替换。这种\n方法使用了基于 Transformer 的模型，并结合机器翻译技术，可以处\n理超过 100种语言的文本，消除其中的隐私信息。  \n当前，大模型训练不仅需要大量的无标注数据，而且也需要高质'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 61, 'page_label': '62'}, page_content='私泄露的风险。对于此类问题，最直接的方法是采用基于规则的算法\n删除隐私数据。例如可以使用基于命名实体识别的算法，检测数据中\n姓名、地址和电话号码等个人信息内容，并进行删除或者替换。这种\n方法使用了基于 Transformer 的模型，并结合机器翻译技术，可以处\n理超过 100种语言的文本，消除其中的隐私信息。  \n当前，大模型训练不仅需要大量的无标注数据，而且也需要高质\n量的人工标注数据，用于模型微调等任务。语言大模型通常需要 人类\n提供明确的指令用于生成有用的输出，标注者通常需要编写提示，典\n型的提示类型包括如下几种 [122]：'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 62, 'page_label': '63'}, page_content='62 \uf09f 普通提示（ Plain） ：这种类型的提示是为了确保模型的多样性 。\n标注人员需要设计一系列任务，并确保任务具有足够的多样\n性，以便模型能够了解不同类型的问题和请 求。  \n\uf09f 少量样本提示（ Few-shot） ：这种类型的提示需要标注人员设\n计一个指令以及该指令的多个查询 /响应对。这些示 例应该是\n常见任务或指令，并且应该涵盖各种不同的主题和情境。  \n\uf09f 基于用户的提示（ User-based） ：这种类型的提示需要标注人员\n根据用户使用案例来编写提示。 这些使用案例很有可能是源于\n用户的实际需要， 因此标注人员应该尽可能准确地描述任务和\n需求。   \n基于上述收集的数据和提示信息， 需要准备三类数据集用于不同\n训练阶段 [122]： \n\uf09f SFT数据集，标注人员会根据输入的提示给出一些符合需求的\n示例结果，然后在这些数据上进行有监督学习。  \n\uf09f RM数据集，对同一个输入，模型会给出多个输出结果，标注\n员会标注 各个结果好坏的排序， 然后在这个基础上训练一个奖\n励模型。  \n\uf09f PPO数据集，没有任何人类标签，用作强化学习的输入。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 62, 'page_label': '63'}, page_content='基于上述收集的数据和提示信息， 需要准备三类数据集用于不同\n训练阶段 [122]： \n\uf09f SFT数据集，标注人员会根据输入的提示给出一些符合需求的\n示例结果，然后在这些数据上进行有监督学习。  \n\uf09f RM数据集，对同一个输入，模型会给出多个输出结果，标注\n员会标注 各个结果好坏的排序， 然后在这个基础上训练一个奖\n励模型。  \n\uf09f PPO数据集，没有任何人类标签，用作强化学习的输入。  \n在数据构建任务中，随着数据量不断增长，需要开发自动化算法\n来简化流程。例如，数据增强等环节的自动化受到越来越多的关注。\n这些任务的自动化不仅会提高效率，而且会提高准确性。此外，自动\n化可以促进人工标注结果的一致性。  \n多模态大模型需要有 大规模的多模态训练数据，这类数据的收集\n与处理难度相比于单模态数据更大， 需构建以低代价挖掘并实现不同\n模态之间对齐的 高质量多模态数据的方法。 未来还需要重点考虑的问\n题包括：如何构建大模型数据质量评价体系、如何科学地配比训练数\n据、以及如何在训练不同阶段引入数据等。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 63, 'page_label': '64'}, page_content='63 4.4.2 大模型常用的公开数据集  \n当前已经出现一批大模型数据集，涵盖多种模态。代表性的数据\n集既包括 ALIGN [66]、V AST -27M [123]、WebVid -2.5M [124]等多模态\n数据集，还包括BookCorpus [125]、Common Crawl [126]、HH-RLHF [127]\n等语言大模型数据集。  \n表1 大模型常用的公开数据集  \n数据集类型  数据集名称  数据量和简介  \n语言大模型预\n训练数据集  BookCorpus  2.24G，包括超过 11 000本电子书，涵盖广\n泛的主题和类型（如小说和传记） 。  \nOpen WebText [126]  38G, 从Reddit上共享的 URL中提取的\nWeb内容，且至少获得了 3次赞成。  \nComm on Crawl  PB级规模，一个大型网站抓取数据集，包\n含原始网页数据、元数据提取和文本提取\n等内容。  \nThe P ile[127]  825G，一个大规模、多样化、开源的文本\n数据集，内容包括书籍、网站、代码、科\n学论文和社交媒体平台等。  \n语言大模型指'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 63, 'page_label': '64'}, page_content='Web内容，且至少获得了 3次赞成。  \nComm on Crawl  PB级规模，一个大型网站抓取数据集，包\n含原始网页数据、元数据提取和文本提取\n等内容。  \nThe P ile[127]  825G，一个大规模、多样化、开源的文本\n数据集，内容包括书籍、网站、代码、科\n学论文和社交媒体平台等。  \n语言大模型指\n令微调数据集  Stanford \nAlpaca [128]  21.7M，开源的 SFT的多样化数据集，包含\n52 000条指令数据，涵盖创作、生成、设\n计、代码等多个维度。  \nstatic -hh[129]  90M，开源的 SFT多样化数据集，包含 100 \n000条人类对话数据， 由 LAION、Together、\nOntocord.ai 这三个机构共同制作，用于对'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 64, 'page_label': '65'}, page_content='64 数据集类型  数据集名称  数据量和简介  \n话相关大模型训练。  \nShareGPT [130]  1.8G，ShareGPT 数据集是一个由用户共享\n的对话 SFT数据集，包含了超过 1亿条来\n自不同领域、主题、风格和情感的对话样\n本，涵盖闲聊、问答、故事、诗歌、歌词\n等多种类型。  \n语言大模型强\n化学习微调数\n据集  HH-RLHF  120M，Anthropic 创建的大型 RLHF训练数\n据集，包含 161 000条人工标注的数据。标\n注人员首先选择自己能够忍受的攻击主\n题，然后与模型进行对话。每次给标注人\n员的会是由两个随机由模型生成的结果，\n标注人员需要从两个选项中选择出哪一个\n更有害，因此来构建人类反馈的数据。  \nzhihu_rlhf_3k [131]  16M， 知乎开源的 RLHF数据集， 包含 3 000\n条基于知乎问答的人类偏好数据，包含每\n个问题中赞同数据较高（ chosen）和较低\n（rejected）的回答，可以用于奖励模型的\n训练。  \nBeaverTails [132]  52M，北京大学开源的 RLHF数据集，包'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 64, 'page_label': '65'}, page_content='更有害，因此来构建人类反馈的数据。  \nzhihu_rlhf_3k [131]  16M， 知乎开源的 RLHF数据集， 包含 3 000\n条基于知乎问答的人类偏好数据，包含每\n个问题中赞同数据较高（ chosen）和较低\n（rejected）的回答，可以用于奖励模型的\n训练。  \nBeaverTails [132]  52M，北京大学开源的 RLHF数据集，包\n含302 000个数据对，覆盖 7 774个问题。\n主要标注的方向包含 helpful和harmless 两\n个维度。  \n图片 -文本多模 SBU[133]  1M，图片 -标题对'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 65, 'page_label': '66'}, page_content='65 数据集类型  数据集名称  数据量和简介  \n态数据集  COCO [134]  330K，图片 /1.5M标题  \nVisual \nGenome [135]  108K，图片 -标题对  \nConceptual [136]  12M，图片标题对  \nALIGN  1.8B，图片 -标题对  \nCOYO -700M [137]  747M，图片 -标题对  \n视频 -文本多模\n态数据集  HowTo100M [138]  136M，视频标题对 /134 500 小时  \nWebVid -2.5M  2.5M，视频标题对 /13 000小时  \nYT-Temporal -180M\n[139]  1.8M，视频标题对  \nHD-VILA -100M [1\n40] 100M，视频 -标题对  \n图文音多模态\n数据集  V ALOR -1M[141]  1M，视频 -音频 -文本数据组  \nV AST -27M  27M，视频 -音频 -字幕 -文本数据组'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 66, 'page_label': '67'}, page_content='66 第5章 大模型的开发训练与推理部署  \n随着参数规模和网络结构复杂性的不断提升，大模型开发、训练\n和推理部署所面临的挑战愈发严峻，其研发依赖算法、算力和数据的\n综合支撑。 深度学习框架及配套工具为大模型的生产和应用提供了基\n础支撑，涉及开发、训练、压缩、推理和服务等多个环节。此外，通\n过深度学习框架还可以实现与硬件的适配和协同优化， 进一步提升硬\n件的计算和推理性能，降低大模型开发和应用的成本。  \n5.1 大模型开发与训练  \n由于大模型参数规模大 ，计算和存储 的需求显著增加，与 辨别式\nAI模型相比，非常依赖分布式技术提升效率。因此，大模型开发的\n挑战集中体现在基于深度学习框架对各类分布式并行策略进行本地\n化配置。为了支持各种分布式并行策略，需要有一套简单、灵活、高\n效且易于使用的框架和工具界面， 使用户可以快捷地进行模型训练和\n调优，并方便地配置和管理大规模的并行任务。 大模型开发也离不开\n高效的调试工具及方法支撑 ，非常依赖动态图的调试机制、清晰的调\n试日志和可视化的调试界面等， 帮助开发人员更好地分析模型的行为\n和表现。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 66, 'page_label': '67'}, page_content='挑战集中体现在基于深度学习框架对各类分布式并行策略进行本地\n化配置。为了支持各种分布式并行策略，需要有一套简单、灵活、高\n效且易于使用的框架和工具界面， 使用户可以快捷地进行模型训练和\n调优，并方便地配置和管理大规模的并行任务。 大模型开发也离不开\n高效的调试工具及方法支撑 ，非常依赖动态图的调试机制、清晰的调\n试日志和可视化的调试界面等， 帮助开发人员更好地分析模型的行为\n和表现。  \n大模型的高性能训练旨在通过对模型计算、显存、内存和通信的\n系统级优化，在保证模型收敛性的前提下，提高训练吞吐量，实现在\n有限资源下大模型高效训练的目的。 系统级优化方法主要从两个方向\n实现：一是设备内优化方法，包括降低浮点数的冗余表示的半精度浮\n点优化、混合精度浮点优化 [79]等方法、降低梯度计算过程中冗余表\n示的梯度检查点（ Checkpointing ）方法，以及内存优化的\nZeRO -Offload [142]方法，即通过将数据和计算从 GPU卸载到  CPU，\n以减少神经网络训练期间 GPU内存占用的方法。二是多设备优化方\n法，也称分布式优化，即将分布在不同计算节点上的多个 GPU一起'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 66, 'page_label': '67'}, page_content='点优化、混合精度浮点优化 [79]等方法、降低梯度计算过程中冗余表\n示的梯度检查点（ Checkpointing ）方法，以及内存优化的\nZeRO -Offload [142]方法，即通过将数据和计算从 GPU卸载到  CPU，\n以减少神经网络训练期间 GPU内存占用的方法。二是多设备优化方\n法，也称分布式优化，即将分布在不同计算节点上的多个 GPU一起\n用于训练单个模型，这类方法主要有数据并行、张量并行、流水线并'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 67, 'page_label': '68'}, page_content='67 行、分组参数切片并行等多种并行加速策略，下面进行重点介绍。  \n数据并行 [143]：数据并行是每个处理器存储全量的模型参数、\n梯度和优化器状态，但读取不同的输入数据，在反向计算出参数梯度\n后，对参数梯度做 AllReduce 聚合，然后每个处理器独立进行参数更\n新。数据并行的优点是实现和使用方式简单，可以通过增加数据并行\n路数提高训练吞吐，是目前最为常用的分 布式并行策略之一。   \n张量并行 [118]： 张量并行是将神经网络中同一层的张量运算拆分\n成多个独立的子运算，并相应地对模型参数做切分，由不同的处理器\n分别执行，生成的中间结果通过分布式通信进行组合。张量并行的优\n点是可以充分利用多核处理器的计算能力，减少了内存访问的延迟，\n但需要设计高效的并行算法和通信机制来确保计算的正确性和高效\n性，避免通信延迟和带宽瓶颈。  \n流水线并行 [16][144] [145]： 这种并行策略是将神经网络中的不同\n层交由不同处理器执行， 上下游执行器之间的数据依赖点对点通信传\n输。基于此技术的高效流水线并行调度策略，支持 1F1B、Interleaving'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 67, 'page_label': '68'}, page_content='点是可以充分利用多核处理器的计算能力，减少了内存访问的延迟，\n但需要设计高效的并行算法和通信机制来确保计算的正确性和高效\n性，避免通信延迟和带宽瓶颈。  \n流水线并行 [16][144] [145]： 这种并行策略是将神经网络中的不同\n层交由不同处理器执行， 上下游执行器之间的数据依赖点对点通信传\n输。基于此技术的高效流水线并行调度策略，支持 1F1B、Interleaving \n1F1B等高效调度算法， 并通过 “通信 -计算 ”重叠的方式隐藏通信时间，\n提高整体训练效率。   \n分组参数并行 [146]：这种并行策略是一种特殊的数据并行方式，\n它可以将优化器状态 、参数梯度和模型 参数切分到不同的处理器上，\n达到节省大模型显存的目的。 分组参数并行的优点是可以有效降低模\n型显存占用，通过增加数据并行路数提高整体训练吞吐。基于此技术\n的“组内参数切片 +组间数据 ”并行，可以更合理地分配机内和机间的\n通信带宽，进一步提升了训练性能。  \n基于上述基础并行策略，不同深度学习框架的实现方法不同 ，有\n的是基于 PyTorch进行进一步封装形成单独的工具，如微软的'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 67, 'page_label': '68'}, page_content='达到节省大模型显存的目的。 分组参数并行的优点是可以有效降低模\n型显存占用，通过增加数据并行路数提高整体训练吞吐。基于此技术\n的“组内参数切片 +组间数据 ”并行，可以更合理地分配机内和机间的\n通信带宽，进一步提升了训练性能。  \n基于上述基础并行策略，不同深度学习框架的实现方法不同 ，有\n的是基于 PyTorch进行进一步封装形成单独的工具，如微软的\nDeepSpeed -Megatron [147]、NVIDIA 的Megatron -LM[118]、清华大学\n的BMTrain 等；飞桨 PaddePaddle 框架支持四维混合并行技术，可将'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 68, 'page_label': '69'}, page_content='68 基础的并行策略组合使用。  \n在多维混合并行训练策略的基础上， 为了应对模型多样性和训练\n硬件资源异构性，进一步发展出了端到端自适应分布式训练架构\n[148]。 \n图5-1 端到端自适应分布式训练架构  \n该架构可以针对不同的深度学习算法抽象成统一的计算视图， 自\n动感知硬件环境并抽象成统一的异构资源视图； 采用了 代价模型对两\n者进行联合 建模；将模型参数、梯度和优化器状态按照最优策略分配\n到不同的设备上，构建流水线进行异步高效执行。对于同地域或跨地\n域多种异构硬件，可以实现节省存储、负载均衡、提升训练性能的目\n的。此外，针对大模型训练资源不稳定的问题，设计了弹性资源调度\n管理机制。当资源发生变化时，能够自动的感知硬件环境并修正资源\n视图，重新触发模型切分放置策略选择及异步流水线执行，使得硬件\n故障下任务恢复可从小时级降至秒级 。 \n5.2 大模型推理部署  \n大模型推理往往面临显存占用过多、计算规模庞大、输入输出变\n长等挑战，这些也是大模型应用落地要重点解决的问题。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 69, 'page_label': '70'}, page_content='69 图5-2 模型压缩、推理引擎、服务部署三个环节协同优化  \n在充分考虑大模型结构特性基础上， 可以从模型压缩、 推理引擎、\n服务部署三个关键环节，开展全方位的协同优化，在降低时延提升用\n户体验的同时，最大化提升服务吞吐，做到低时延、高吞吐。  \n大模型的推理可以采用深度学习框架直接实现， 通过框架和模型\n协同优化， 可以显著提升大模型的推理效率； 也可以采用 专门的工具，\n如： FasterTransformer 、TensorRT -LLM、vLLM、Text Genertion \nInference 、Hugg ingFace TG 等实现，这些工具 已经针对大模型推理进\n行了优化，能够高效地完成推理任务 。大模型推理效率的提升，不仅\n可以提升用户体验，还能显著降低开发成本，有利于大模型在千行百\n业的广泛应用。产业界非常重视大模型推理性能的优化，如 ChatGPT\n组建了专门的优化团队， 优化其在线推理的成本； 再如百度文心一言，\n通过与飞桨协同优化，推理性能提升 30多倍；腾讯混元大模型，通\n过太极机器学习平台的压缩和分布式推理，资源设备占用减少 40%。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 69, 'page_label': '70'}, page_content='行了优化，能够高效地完成推理任务 。大模型推理效率的提升，不仅\n可以提升用户体验，还能显著降低开发成本，有利于大模型在千行百\n业的广泛应用。产业界非常重视大模型推理性能的优化，如 ChatGPT\n组建了专门的优化团队， 优化其在线推理的成本； 再如百度文心一言，\n通过与飞桨协同优化，推理性能提升 30多倍；腾讯混元大模型，通\n过太极机器学习平台的压缩和分布式推理，资源设备占用减少 40%。 \n5.2.1 大模型压缩  \n在大模型压缩方面，常规的模型压缩方法有模型稀疏化、权重矩\n阵分解、模型参数共享、蒸馏和量化。  \n模型稀疏化 [149] [150] [151]：这种方法通过将模型中的某些神经\n元、连接或层置为零，从而达到压缩模型、加速训练、减少内存消耗\n等目的。  \n权重矩阵分解：使用包括奇异值分解（ SVD）等矩阵分解方法对\n预训练模型的 Feed -Forward Network （FFN）层的权重矩阵进行分解，\n从而减少 Attenti on层的参数量，提高模型的效 率。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 70, 'page_label': '71'}, page_content='70 模型参数共享：部分大型模型如 ALBERT [152]采用了权重共享\n的方式，特定层之间共享参数，从而减少了模型的参数量。  \n蒸馏： 通过使用学生模型来模拟预训练教师模型的行为来减小模\n型大小的技术。通常情况下，学生模型由更小的神经网络或线性模型\n组成。蒸馏的过程是将教师模型的知识转移到学生模型，使学生模型\n在保持较小规模的同时，能够保持类似于教师模型的预测能力。利用\n蒸馏技术可以将大模型的知识和泛化能力迁移到小型网络， 以支持轻\n量化的大模型部署。  \n量化 [149] [153] [154]：量化是一种将预训练模型中的权重从浮点\n数转换为低位数的技术。通常情况下，量化的精度可被降低到 8 位\n或更低。量化可以大大减少模型的存储空间和计算量，但可能会对模\n型的性能产生一定的影响。  \n目前量化技术在大模型压缩时被广泛应用， 然而很多量化算法难\n以做到模型效果无损，主要是因为大模型存在激活分布异 常值较大，\n难以量化的问题 [155]。自适应 Shift -SmoothQuant [156]大模型量化方\n法可以使激活分布更加平滑，提升量化效果。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 70, 'page_label': '71'}, page_content='或更低。量化可以大大减少模型的存储空间和计算量，但可能会对模\n型的性能产生一定的影响。  \n目前量化技术在大模型压缩时被广泛应用， 然而很多量化算法难\n以做到模型效果无损，主要是因为大模型存在激活分布异 常值较大，\n难以量化的问题 [155]。自适应 Shift -SmoothQuant [156]大模型量化方\n法可以使激活分布更加平滑，提升量化效果。  \n此外，对于超大模型精度无损的压缩，可以 采用多策略组合压缩\n方案。通过组合使用模型稀疏化、蒸馏和参数共享等压缩技术，可以\n在精度无损的情况下，将模型参数量压缩至百分之一、甚至千分之一\n左右 [82][101]。例如，组合使用低比特量化和模型稀疏化，同时从数  \n值和结构两个维度对大模型的冗余信息进行精简， 协同优化计算和访\n存算子，可以进一步提高压缩率。  \n5.2.2 大模型推理与服务部署  \n在推理引擎方面， 通用的技术是使用自动计算图融合优化和自动\n混合并行推理，实现对模型结构和计算硬件的自动感知（ Automated \nHardware Awareness ） ，协同优化模型推理效率 [102] [103]。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 70, 'page_label': '71'}, page_content='值和结构两个维度对大模型的冗余信息进行精简， 协同优化计算和访\n存算子，可以进一步提高压缩率。  \n5.2.2 大模型推理与服务部署  \n在推理引擎方面， 通用的技术是使用自动计算图融合优化和自动\n混合并行推理，实现对模型结构和计算硬件的自动感知（ Automated \nHardware Awareness ） ，协同优化模型推理效率 [102] [103]。 \n自动计算图融合优化：以非侵入的方式自动匹配高性能融合算'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 71, 'page_label': '72'}, page_content='71 子，通过降低算子数量、减少访存次数，获得自动化推理加速能力。   \n自动混合并行推理：通过自动感知部署硬件的存储、带宽、算力\n等特性，对模型进行自适应切分，将大模型切分到多个部署硬件上，\n进行分布式并行推理，尽可能减少卡间通信和跨机通信数据量，从而\n实现如百亿、千亿参数模型推理部署。  \n除了上述技术外，推理引擎的优化还可以协同模型压缩，研发符\n合大模型特点的量化推理方案。例如，语言大模型的上下文计算阶段\n属于计算密集型，而 Token Generation 阶段则属于访存密集型。针对\n这种计算特点，可以通过协同硬件开展优化，研发 LLM.INT8() [67]\n和Weight Only 量化混合的推理方案。这种方案能够快速进行量化，\n并且具有较高的精度，尤其对访存受限的场景，也拥有较好的效果。  \n在服务化调度协同方面，针对生成式模型计算过程中，同一批次\n输入输出长度不一致带来的计算效率不高问题， 通过变长优化降低计\n算量，并引入输入动态插入批处理技术，可以大幅提升硬件的计算资\n源利用率，从而 提升整体服务的吞吐量。动态插入批处理技术具有感'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 71, 'page_label': '72'}, page_content='和Weight Only 量化混合的推理方案。这种方案能够快速进行量化，\n并且具有较高的精度，尤其对访存受限的场景，也拥有较好的效果。  \n在服务化调度协同方面，针对生成式模型计算过程中，同一批次\n输入输出长度不一致带来的计算效率不高问题， 通过变长优化降低计\n算量，并引入输入动态插入批处理技术，可以大幅提升硬件的计算资\n源利用率，从而 提升整体服务的吞吐量。动态插入批处理技术具有感\n知负载的能力，能够在一个请求生成完成之后，及时快速地插入新的\n请求，结合输入、输出长度的动态变化，有效提升 GPU资源的利用\n效率，减少用户的等待时延。  \n5.3 软硬件适配与协同优化  \n目前国际上主要的大模型训练芯片有英伟达 GPU，如 H100、\nA100，以及谷歌的 TPU（Tensor Processing Unit ） ，国内主要有华为\n昇腾 NPU、昆仑芯 XPU、海光 DCU、寒武纪 MLU等，其架构和性\n能规格各不相同。大模型除了对训练芯片的计算性能有一定的要求\n外，还对硬件的规格，如显存大小、访存带宽和通信带宽具有较高的\n要求。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 71, 'page_label': '72'}, page_content='目前国际上主要的大模型训练芯片有英伟达 GPU，如 H100、\nA100，以及谷歌的 TPU（Tensor Processing Unit ） ，国内主要有华为\n昇腾 NPU、昆仑芯 XPU、海光 DCU、寒武纪 MLU等，其架构和性\n能规格各不相同。大模型除了对训练芯片的计算性能有一定的要求\n外，还对硬件的规格，如显存大小、访存带宽和通信带宽具有较高的\n要求。  \n为实现大模型的高效训练和推理， 需要通过深度学习框架实现与\n硬件的适配和深度协同优化，通过低成本、高效率的硬件适配方案，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 72, 'page_label': '73'}, page_content='72 提升大模型与硬件的适配效 率，并通过混合精度、显存复用、融合优\n化等软硬件协同优化技术，结合硬件特性实现系统级优化。  \n5.3.1 大模型的软硬件适配  \n深度学习框架需要提供标准化的硬件适配开发接口， 以对接异构\n硬件。针对不同 AI芯片在指令集、开发语言、加速库、计算图引擎、\n运行时环境、通信库等方面的差异，需根据 AI芯片的技术栈提供差\n异化的硬件接入方式，配 涉及算子适配、通信库适配、设备驱动适配\n等多个方面。 在算子适配方面，有如下两种方式：  \n算子映射：框架算子库对接硬件算子库，提供单算子粒度级别的\n接入方式，并交由框架执行器进行算子库接口的调用和执行，适用底\n层硬件 SDK支持硬件算子库。  \n算子开发：芯片厂商在其软件栈提供一套完善的高级开发语言，\n如NVIDIA 的CUDA C 开发语言，然后深度学习框架通过高级开发\n语言实现算子代码的开发。其优点是比较通用，可以支持大量算子的\n开发，缺点在于提供高级语言开发环境，对于芯片公司来说有较大的\n研发难度和成本。  \n神经网络编译器接入： 通过深度学习框架中的神经网络编译器中'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 72, 'page_label': '73'}, page_content='层硬件 SDK支持硬件算子库。  \n算子开发：芯片厂商在其软件栈提供一套完善的高级开发语言，\n如NVIDIA 的CUDA C 开发语言，然后深度学习框架通过高级开发\n语言实现算子代码的开发。其优点是比较通用，可以支持大量算子的\n开发，缺点在于提供高级语言开发环境，对于芯片公司来说有较大的\n研发难度和成本。  \n神经网络编译器接入： 通过深度学习框架中的神经网络编译器中\n间表示（ Intermediate Representation ，IR）对接硬件的代码生成器\n（Codegen） ，提供编译器 IR到底层硬件 IR的转化，交由编译器 进行\n算子融合和调度，适用底层硬件 SDK支持代码生成的硬件。  \n5.3.2 大模型的软硬件协同优化  \n为了进一步提升大模型在硬件上的运行效率， 深度学习框架在显\n存优化、计算加速和通信优化三个环节需要提供相应的优化技术。在\n显存优化方面， 框架支持多层显存复用、 重计算和低比特量化等技术，\n降低大模型对硬件显存的要求； 在计算加速方面， 框架 支持混合精度、\n算子融合优化等技术，并通过接入硬件 Transformer 大算子库，针对'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 72, 'page_label': '73'}, page_content='5.3.2 大模型的软硬件协同优化  \n为了进一步提升大模型在硬件上的运行效率， 深度学习框架在显\n存优化、计算加速和通信优化三个环节需要提供相应的优化技术。在\n显存优化方面， 框架支持多层显存复用、 重计算和低比特量化等技术，\n降低大模型对硬件显存的要求； 在计算加速方面， 框架 支持混合精度、\n算子融合优化等技术，并通过接入硬件 Transformer 大算子库，针对\n生成式大模型进行深度融合优化， 提升大模型性能； 在通信优化方面，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 73, 'page_label': '74'}, page_content='73 框架支持自适应的通信拓扑优化技术，可感知硬件集群环境的配置，\n搜索最优并行策略，支持大模型在不同规模集群下的高效训练，提升\n模型性能的同时，降低开发者配置高效大模型训练的门槛。  \n硬件加速是大模型高效计算的另一种关键技术， 硬件加速通过使\n用专用硬件来优化神经网络计算，以达到更高的性能和效率。例如，\nTPU（Tensor Processing Unit ）硬件加速技术，与通用的 CPU和GPU\n不同， TPU专门为深度学习计算进行了定制化优化，以满足大规模模\n型训练的特殊需求。 ASIC（Application -Specific Integrated Circuit ）加\n速是另一种硬件加速的方案，它是一种定制化的集成电路，专门为某\n个特定应用场景而设计制造。 ASIC的优势在于能够实现高度优化的\n电路结构和算法，从而提高性能和能效。除了 ASIC，FPGA\n（Field -Programmable Gate Array ）加速也是一种重要的硬件加速技\n术。 FPGA是一种可编程逻辑芯片，它可以通过编程方式实现 不同的'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 73, 'page_label': '74'}, page_content='速是另一种硬件加速的方案，它是一种定制化的集成电路，专门为某\n个特定应用场景而设计制造。 ASIC的优势在于能够实现高度优化的\n电路结构和算法，从而提高性能和能效。除了 ASIC，FPGA\n（Field -Programmable Gate Array ）加速也是一种重要的硬件加速技\n术。 FPGA是一种可编程逻辑芯片，它可以通过编程方式实现 不同的\n逻辑电路，具有高度灵活性和可编程性。 FPGA通常由大量的逻辑单\n元和存储单元组成，可以实现基本的布尔逻辑运算和算术运算，并可\n以与其他电路和设备进行通信。  \n另外，云服务也为大模型训练提供了强大的计算能力和存储资\n源。云服务提供商如 AWS、Azure、Google Cloud ，以及百度 智能云、\n阿里云、腾讯云、华为云等，提供了丰富的深度学习服务和工具，包\n括模型训练、模型部署和自动缩放等。这些云服务可以根据用户的实\n际需求和流量变化，灵活调整计算资源的规模和配置，以提供高效、\n可靠的服务。  \n综上，大模型对软硬件协同优化提出了更好的要求，一方面需要\n对已经硬件进行全面适配，另一方面需要开展极致的软硬件协同优'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 73, 'page_label': '74'}, page_content='阿里云、腾讯云、华为云等，提供了丰富的深度学习服务和工具，包\n括模型训练、模型部署和自动缩放等。这些云服务可以根据用户的实\n际需求和流量变化，灵活调整计算资源的规模和配置，以提供高效、\n可靠的服务。  \n综上，大模型对软硬件协同优化提出了更好的要求，一方面需要\n对已经硬件进行全面适配，另一方面需要开展极致的软硬件协同优\n化，才能有效支撑大模型的研发和广泛应用。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 74, 'page_label': '75'}, page_content='74 第6章 大模型应用  \n大模型由于其强大的自然语言与多模态信息 处理能力， 可以应对\n不同语义粒度下的任务 ,进行复杂的逻辑推理， 还 具有超强的迁移学习\n和少样本学习能力 , 可以快速掌握新的任务 , 实现对不同领域、不同数\n据模式的适配 ，这些特点使得大模型较容易的赋能其他行业，提升行业\n效率。如在信息检索领域，大模型可 以从用户的问句中提取出真正的查\n询意图 ,检索出更符合用户意图的结果 ， 还可以改写查询语 句从而检索到\n更为相关的结果 ；在新闻媒体领域， 大模型可以根据数据生成标题、摘\n要、 正文等 ,实现自动化新闻撰写 。 此外， 大模型还可以应用于智慧城市、\n生物科技、智慧办公、影视制作、智慧军事、智能教育等领域。 大模型\n仍在快速迭代更新中 ,  有着巨大的潜力赋能更多行业， 提升整个社会的\n运行效率。  \n6.1 信息检索  \n近年来，搜索引擎提供支持的功能逐步丰富，但是仍然沿用经典\n的检索范式：给定基于关键词的用户查询，搜索引擎高效地从海量的\n文档中检索到和该查询需求相关的文档， 并按照相关性排序后返回给'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 74, 'page_label': '75'}, page_content='生物科技、智慧办公、影视制作、智慧军事、智能教育等领域。 大模型\n仍在快速迭代更新中 ,  有着巨大的潜力赋能更多行业， 提升整个社会的\n运行效率。  \n6.1 信息检索  \n近年来，搜索引擎提供支持的功能逐步丰富，但是仍然沿用经典\n的检索范式：给定基于关键词的用户查询，搜索引擎高效地从海量的\n文档中检索到和该查询需求相关的文档， 并按照相关性排序后返回给\n用户。通常来说，检索系统分为离线和在线两个阶段。在离线阶段，\n检索系统 对文档进行预处理并构建索引 （包括早期的倒排索引以及近\n年来的向量索引） 。在在线阶段，检索系统接收到用户查询后，首先\n进行用户查询理解，并将理解处理后的查询送入索引中 ，通过检索模\n型（如经典的 BM25等概率检索模型或者基于神经网络的检索模型）\n计算文档 和查询的相关性，召回最相关的 TopK候选文档，然后再采\n用较为复杂、 性能更强 的精排模型对候选文档进行排序后输出。这种\n以索引为核心的 “索引 —召回 —精排 ”检索架构被广泛应用在各种信\n息检索系统中。  \n以ChatGPT 为代表的生成式大模型和以搜索引擎为 代表的检索'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 74, 'page_label': '75'}, page_content='型（如经典的 BM25等概率检索模型或者基于神经网络的检索模型）\n计算文档 和查询的相关性，召回最相关的 TopK候选文档，然后再采\n用较为复杂、 性能更强 的精排模型对候选文档进行排序后输出。这种\n以索引为核心的 “索引 —召回 —精排 ”检索架构被广泛应用在各种信\n息检索系统中。  \n以ChatGPT 为代表的生成式大模型和以搜索引擎为 代表的检索\n模型是两种不同的信息获取方式。传统的检索 模型侧重于 “检索 ”，可'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 75, 'page_label': '76'}, page_content='75 以从海量的互联网 内容（或其他信息源）中获取准确的信息，但是对\n于检索结果通常不做深入分析，当用户信息需求比较复杂时，需要用\n户浏览多个结果才能获取所需要的信息。 而生成式大模型则是将大量\n知识存储在参数化的模型中，可以直接根据用户的问题生成答案，能\n够更便捷地满足用户的信息需求，但是由于返回信息是 模型生成的，\n可能会存在虚假、陈旧或错误 的信息。将两种 信息获取 范式的优势进\n行融合与互补，打造更为高效、准确的信息获取技术，具有重要的科\n学价值与应用意义。  \n \n图6-1 New  Bing的搜索模式  \n6.2 新闻媒体  \n图 6-2 自动新闻写作广泛应用  \n     中国科学院自动化研究所基于自主研发的音视频理解大模型 “闻\n海”和三模态预训练模型 “紫东太初 ”[157] ,联合新华社媒体大数据和业务\n场景 ,在2021年12月推出了 “全媒体多模态大模型 ”。 该项目通过构建大'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 76, 'page_label': '77'}, page_content='76 数据与大模型驱动的多任务统一学习体系 ,实现了对全媒体数据的统一\n建模和理解生成。该模型兼具语音、图像、文本等跨模态理解和生成能\n力。项目将加速 AI技术在视 频配音、语音播报、标题生成、海报设计\n等多元体业务场景 中的应用。  \n6.3 智慧城市  \n在智慧城市方面， 阿里巴巴的多模态大模型 M6[158]已经被应用\n于在 Talk2Car 任务中。具体地，用户通过给出一个指令，比如 “在\n前面那个绿车前面停下来 ”，就可以 定位指令中所指的车辆 。 \n2023年7月7日，城市大模型 CityGPT 正式发布，旨在提升智\n能城市的治理能力，赋能城市经济、产业、商业、文旅、金融等领域，\n打造真正的城市级大脑。具体地，在认知人工智能领域首次开启了空\n间场景智能决策以及 “元宇宙城市 ”可交互体验价值链，能够实现对城\n市-园区 -商圈 -社区 -网点级别的智能计算与研判，为线上线下数实融\n合的智能决策和场景交互提供具有 AI自学习能力的 “空间 AI专家顾\n问”服务。  \n图 6-3 城市 AI大模型  \n6.4 生物科技'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 76, 'page_label': '77'}, page_content='打造真正的城市级大脑。具体地，在认知人工智能领域首次开启了空\n间场景智能决策以及 “元宇宙城市 ”可交互体验价值链，能够实现对城\n市-园区 -商圈 -社区 -网点级别的智能计算与研判，为线上线下数实融\n合的智能决策和场景交互提供具有 AI自学习能力的 “空间 AI专家顾\n问”服务。  \n图 6-3 城市 AI大模型  \n6.4 生物科技  \nDeepMind 联合谷歌旗下生物科技公司 Calico，开发了一种结合'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 77, 'page_label': '78'}, page_content='77 DNA远端交互进行基因表达和染色质状态预测的神经网络架构\nEnformer [159]，能够一次编码超过 20万个碱基对，大幅提高了根据\nDNA序列预测基因表达的准确性。为进一步研究疾病中的基因调控\n和致病因素， 研究人员还公开了他们的模型及对常见遗传变异的初步\n预测。  \n美国哈佛医学院和英国牛津大学的研究人员合作开发出一款可\n准确预测致病基因突变的 AI模型 “EVE” [160]， 已预测出 3200多个疾\n病相关基因中的 3600万个致病突变，且对 26.6万个至今意义不明的\n基因突变是 “致病 ”还是 “良性 ”做出归类。未来，该 AI模型可帮助遗\n传学家和医生更精确地制定诊断、预后和治疗方案。  \nAlphaFold2 [161]通过深度学习和人工神经网络等技术， 预测蛋白\n质的三维结构。在此之前，预测蛋白质结构是一项非常耗时、困难且\n复杂的任务，需要耗费许多时间和大量的实验数据。 AlphaFold2 使得\n人们可以在数分钟内预测蛋白质的结构。  \n图 6-4 AlphaFold2 的系统框图  \n6.5 智慧办公'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 77, 'page_label': '78'}, page_content='传学家和医生更精确地制定诊断、预后和治疗方案。  \nAlphaFold2 [161]通过深度学习和人工神经网络等技术， 预测蛋白\n质的三维结构。在此之前，预测蛋白质结构是一项非常耗时、困难且\n复杂的任务，需要耗费许多时间和大量的实验数据。 AlphaFold2 使得\n人们可以在数分钟内预测蛋白质的结构。  \n图 6-4 AlphaFold2 的系统框图  \n6.5 智慧办公  \n微软推出的新一代办公软件 Copilot,将大模型应用于办公场景 ,实\n现智能化协助用户提高工作效率。在文字处理软件 Word中,Copilot\n可以协助用户撰写各类文档 ,实现文档创作、编辑 和总结等功能，用\n户只需用自然语言提出需求 , Copilot即可以快速生成或修改文档内\n容。 在演示文稿软件 PowerPoint 中,Copilot可以根据用户的要求 ,自动'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 78, 'page_label': '79'}, page_content='78 生成演示文稿幻灯片。在电子表格软件 Excel中,Copilot可以完成数\n据统计分析 ,并将结果以图表的形式清晰可视化呈现。  \n图 6-5 大模型与办公  \n6.6 影视制作  \n在影视行业，大模型技术为内容制作和影视创作带来了新的变\n革。大模型可以应用于剧本创作、角色设计和音乐配乐，为影视制作\n带来更多元化和个性化的创意。 此外， 大模型还能用于视频内容分析，\n实现内容标签化和智能推荐，提升观众的观影体验。  \n图 6-6 大模型影视创作案例  \n6.7 智能教育  \n2023年,国内教育科技公司积极布局教育领域大模型 ,推出多项创\n新应用 ,以智能化手段提升教与学效果。 7月,网易有道发布面向 K12\n教育的大模型“子曰” ,实现个性化分析指导、引导式学习等功能 , 大\n模型能够较好地因材施教 ,为学生提供全方位知识支持。 8月,好未来\n发布数学领域大模型 MathGPT ，可自动出题并给出解答 ,涵盖小学到\n高中数学知识。教育领域大模型正成为智能辅助教学的新工具，其知'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 79, 'page_label': '80'}, page_content='79 识整合能力可满足学生动态需求 ,实现个性 化学习 ,与教师共同提高教\n学质量。  \n6.8 智慧金融  \n2023年 6月,恒生电子发布多款大模型金融应用 ,其中金融行业\n大模型 LightGPT 使用超过 4000亿字节的金融领域数据进行预训练 ,\n支持 80多项金融专属任务 ,能准确理解金融业务场景需求。 8月,马上\n金融发布国内首个零售金融大模型“天镜” ,具有知识汇集、唤醒数\n据价值等应用场景 ,可助力零售金融机构实现智能客服、精准营销、\n风险控制等能力。在模型训练规模不断扩大的背景下 ,金融行业大模\n型精度持续提升 ,已经成为金融机构实现业务智能化的重要途径。  \n6.9 智慧医疗  \n2023年 5月,医联推出医疗语言模型 MedGPT，实现从预防到康\n复的全流程智能诊疗 ,提升实际临床应用价值。 7月,谷歌 DeepMind 研\n发Med-PaLM [89]医疗大模型 ,其在医学考试和开放式问答上达到专\n家水平 ,回答准确率高达 86.5%,大幅超过早期版本。非专业评估者也\n高度认可其问诊效果。同月 ,京东健康发布“京医千询”大模型 ,可以'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 79, 'page_label': '80'}, page_content='6.9 智慧医疗  \n2023年 5月,医联推出医疗语言模型 MedGPT，实现从预防到康\n复的全流程智能诊疗 ,提升实际临床应用价值。 7月,谷歌 DeepMind 研\n发Med-PaLM [89]医疗大模型 ,其在医学考试和开放式问答上达到专\n家水平 ,回答准确率高达 86.5%,大幅超过早期版本。非专业评估者也\n高度认可其问诊效果。同月 ,京东健康发布“京医千询”大模型 ,可以\n理解医学多模态数据 ,并根据个性化诊疗需求进行智能决策。医疗大\n模型正在成为提升临床决策效率和服务水平的重要工具， 通过学习处\n理海量医学知识 ,可以高效辅助各环节工作 ,具有广阔的应用前景。  \n6.10 智慧工厂  \n服饰行业中，阿里巴巴 开发的多模态大模型 M6已成功应用于犀\n牛新制造 ，实现了例如 文本到图像生成等多种应用 案例。传统服装设\n计过程中，设计师需要花费很长的时间设计衣服并进行线上样款测\n试，但基于文本到图像生成技术，可以直接输入流行的服装款式描述\n到M6模型中生成相应款式图片。这项技术将原本冗长的设计流程压\n缩了超过十倍的时间，目前已经商业投产，并且与三十多家服装商家'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 79, 'page_label': '80'}, page_content='6.10 智慧工厂  \n服饰行业中，阿里巴巴 开发的多模态大模型 M6已成功应用于犀\n牛新制造 ，实现了例如 文本到图像生成等多种应用 案例。传统服装设\n计过程中，设计师需要花费很长的时间设计衣服并进行线上样款测\n试，但基于文本到图像生成技术，可以直接输入流行的服装款式描述\n到M6模型中生成相应款式图片。这项技术将原本冗长的设计流程压\n缩了超过十倍的时间，目前已经商业投产，并且与三十多家服装商家\n在双十一期间成功地进行了合作 。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 80, 'page_label': '81'}, page_content='80 6.11 生活服务  \n阿里巴巴的多模态大模型 M6已经在众多民生服务 领域产生了影\n响。首先， M6除了提供文 本到图像生成的能力，还被改进 为可根据\n交互需求不断完善 其生成结果。例如，在给定一张衣服图像时，用户\n可以保留其领子并进一步进行个性化调整 。M6改进后每次 可以只生\n成一部分 的token。随着多次迭代，其生成结果也会越来越好。另外，\nM6还被用于 生成营销文案，传统方法需要十万到百万级别训练数据\n才能达到工业级可用， M6只需要使用原来 5%左右的样本， 即可实\n现百分之八十五以上 的通过率。这得益于多模态 预训练，即输入不仅\n包括题目，还可以输入图，大大增加了模型 的预测效率。 M6模型还\n被应用于生成推荐理由， 并已在阿里小蜜上线。 最后，在数字人应用\n中，如淘宝直播，通常需要使用语音识别（ ASR）将主播的口述转换\n为文本形式。 为了提高转换质量， 需要过滤掉主播口语化的语言部分。\n借助于多模态深度学习模型 M6，这一过程已经成功地上线实现 。 \n6.12 智能机器人'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 80, 'page_label': '81'}, page_content='包括题目，还可以输入图，大大增加了模型 的预测效率。 M6模型还\n被应用于生成推荐理由， 并已在阿里小蜜上线。 最后，在数字人应用\n中，如淘宝直播，通常需要使用语音识别（ ASR）将主播的口述转换\n为文本形式。 为了提高转换质量， 需要过滤掉主播口语化的语言部分。\n借助于多模态深度学习模型 M6，这一过程已经成功地上线实现 。 \n6.12 智能机器人  \n2022年12月13日Google发布 Robotic Transformer -1[162]，框\n架十分简洁，将图像与文本指令抽取特征，再放入 Transformer 直接\n训练，对 EverydayRobots 公司机器人的机械臂状态和移动底盘状态\n直接进行学习。  \n2023年1月24日， Microsoft 发布了 Control Transformer [163]，\n将大模型常用的自监督训练方式以及预训练 -微调的训练部署方式延\n续到了控制任务上。预训练阶段，通过两个短期特征指标（预测下一\n时刻的观测 /正运动学，预测上一时刻的动作 /逆运动学）以及一个长\n期指标（随机遮盖一些观测 -动作序列，进行预测）来学习观测 -动作'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 80, 'page_label': '81'}, page_content='直接进行学习。  \n2023年1月24日， Microsoft 发布了 Control Transformer [163]，\n将大模型常用的自监督训练方式以及预训练 -微调的训练部署方式延\n续到了控制任务上。预训练阶段，通过两个短期特征指标（预测下一\n时刻的观测 /正运动学，预测上一时刻的动作 /逆运动学）以及一个长\n期指标（随机遮盖一些观测 -动作序列，进行预测）来学习观测 -动作\n的特征。  \n6.13 其他应用  \n在气象方面，大模型也 取得了突破。 2023年7月6日，国际顶'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 81, 'page_label': '82'}, page_content='81 级学术期刊《自然》 (Natu re)杂志正刊发表了华为云盘古大模型研发\n团队研究成果 [164]。华为云盘古大模型使用了 39年的全球再分析天\n气数据进行训练， 其预测准确率与全球最佳数值天气预报系统 IFS相\n当。与 IFS相比，盘古气象在相同的空间分辨率下速度提升了 10000\n倍以上，同时保持了极高的精准度。   \n此外，大模型的应用还包括但不限于如下场景：智能创意， 在游\n戏、广告、美术和影视等创意设计内容的领域，大模型可帮助实现角\n色立绘、特效设计、动画分镜 等，较大提升创意设计 的工作效率，降\n低制作成本 ；自动驾驶：通过融合视觉、雷达、红外等多模态传感器\n数据，实现对道路、车辆和行人的全方位感知和理解，推动自动驾驶\n技术的发展。智能辅助设备：通过语音、图像等多模态数据，为智能\n助理、智能家居等设备提供更自然智能的人机交互方式，以提升用户\n体验。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 82, 'page_label': '83'}, page_content='82 第7章 大模型的安全性 \n7.1 大模型安全风险引发全球广泛关注  \n与大模型技术的突飞猛进形成鲜明对照的是， 大模型仍面临诸多\n潜在的安全风险。大模型在应用的过程中，可能会产生与人类价值观\n不一致的输出，如歧视言论、辱骂、违背伦理道德的内容等，这种潜\n在的安全风险普 遍存在于文本、 图像、 语音和视频等诸多应用场景中，\n并会随着模型的大规模部署带来日益严重的安全隐患， 使得用户无法\n信赖人工智 能系统做出的决策。更为重要的是，大模型较为脆弱，对\n安全风险的防范能力不足，容易受到指令攻击、提示注入和后门攻击\n等恶意攻击。尤其是在政治、军事、金融、医疗等关键的涉密应用领\n域， 任何形式的恶意攻击都可能给国家社会的稳定以及人民的生命财\n产安全带来 严重的后果。  \n2023年4月28日， 习近平总书记主持召开中共中央政治局会议，\n会议指出 “要重视通用人工智能发展， 营造创新生态， 重视防范风险” 。\n大模型是通用人工智能发展的重要路径之一， 大模型和 通用人工智能\n的安全风险 已经得到 了党和国家的高度重视。  \n人工智能和大模型安全也是国际社会高度关注的热门话题。 2023'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 82, 'page_label': '83'}, page_content='产安全带来 严重的后果。  \n2023年4月28日， 习近平总书记主持召开中共中央政治局会议，\n会议指出 “要重视通用人工智能发展， 营造创新生态， 重视防范风险” 。\n大模型是通用人工智能发展的重要路径之一， 大模型和 通用人工智能\n的安全风险 已经得到 了党和国家的高度重视。  \n人工智能和大模型安全也是国际社会高度关注的热门话题。 2023\n年5月，联合国秘书长 古特雷斯在纽约联合国总部提到，利用 AI“必\n须由各国展开协调设定红线 ”，需要 “打造 AI有助于人类幸福，而不\n会成为人类威胁的环境 ”。OpenAI首席执行官山姆 ·阿尔特曼呼吁美\n国监管高级大型语言模型的部署， 警告没有坚实政策框架会使生成式\n人工智能陷入危险境地。同时，随着民众对 AI社会威胁的担忧日益\n加剧，监管过程对于减轻日益强大的模型带来的风险至关重要 。同月\n底，众多 AI科学家和 AI领袖发表公开声明，呼吁防范 AI的生存风\n险应该与流行病和核战争等其他大规模风险一样，成为全 球优先议\n题。 2023年6月，图灵奖得主 Geoffrey Hinton 在演讲中指出，超级'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 82, 'page_label': '83'}, page_content='人工智能陷入危险境地。同时，随着民众对 AI社会威胁的担忧日益\n加剧，监管过程对于减轻日益强大的模型带来的风险至关重要 。同月\n底，众多 AI科学家和 AI领袖发表公开声明，呼吁防范 AI的生存风\n险应该与流行病和核战争等其他大规模风险一样，成为全 球优先议\n题。 2023年6月，图灵奖得主 Geoffrey Hinton 在演讲中指出，超级\n智能的到来比他想象中更 快，在此过程中，数字智能可能会追求更多'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 83, 'page_label': '84'}, page_content='83 控制权，甚至通过 “欺骗 ”控制人类，人类社会也可能会因此面临更多\n问题。  \n \n7.2 大模型安全治理的政策法规和标准规范  \n为确保大模型的安全和负责任地使用， 各国的监管机构都在积极\n探讨并制定相应的安全标准和准则， 为开发者和企业提供清晰的大模\n型应用和治理方向。  \n2021年11月，联合国教科文组织正式发布《人工智能伦理问题\n建议书》 ，指出 “作为以国际法为依据、采用全球方法制定且注重人的\n尊严和人权以及性别平等、社会和经济正义与发展、身心健康、多样\n性、互联性、包容性、环境和生态系统保护的准则性文书，可以引导\n人工智能技术向着负责任的方向发展 ”。 \n2023年3月，美国白宫科技政策办公室发布《促进隐私保护数\n据共享和分析的国家战略》 。该策略旨在保障公共和私营部门实体中\n用户的数据隐私，同时确保数据使用的公平性和 最大的效率。其中明\n确了政府的目标： 支持有关数据伦理和社会技术问题的解 决方案的研\n究、开发、监管和应用，同时确保用户的机密性不受损害。  \n2023年4月，美国政府发布《人工智能问责政策征求意见 》 ，此'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 83, 'page_label': '84'}, page_content='2023年3月，美国白宫科技政策办公室发布《促进隐私保护数\n据共享和分析的国家战略》 。该策略旨在保障公共和私营部门实体中\n用户的数据隐私，同时确保数据使用的公平性和 最大的效率。其中明\n确了政府的目标： 支持有关数据伦理和社会技术问题的解 决方案的研\n究、开发、监管和应用，同时确保用户的机密性不受损害。  \n2023年4月，美国政府发布《人工智能问责政策征求意见 》 ，此\n征求意见稿涵盖人工智能审计、安全风险评估、认证等内容，以促进\n建立合法、有效、合乎道德、安全可信的人工智能系统。  \n2023年6月，欧洲议会（ European Parliament ）通过《人工智能\n法案》草案，旨在为人工智能引入统一的监管和法律框架，并涵盖了\n除军事用途外的所有人工智能类型。 该法案根据按人工智能应用可能\n造成伤害的风险， 对其进行分类和监管， 以增强各成员国之间的合作，\n确保 AI技术的健康、安全和公平发展。  \n作为 AI技术的重要发展地之一， 中国非常重视人工智能和大模\n型的安全监管 。习近平总书记在多次会议中指出， “要重视通用人工'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 84, 'page_label': '85'}, page_content='84 智能发展，营造创新生态，重视防范风险 ”，“要加强人工智能发展的\n潜在风险研判和防范， 维护人民利益和国家安全， 确保人工智能安全、\n可靠、可控 ”。国内相关机构积极制定大模型发展的安全规范。  \n2019年6月，国家新一代人工智能治理专业委员会发布的《新\n一代人工智能治理原则 ——发展负责任的人工智能》指出， “人工智\n能系统应不断提升透明性、可解释性、可靠性、可控性，逐步实现可\n审核、可监督 、可追溯、可信赖。高度关注人工智能系统的安全，提\n高人工智能鲁棒性及抗干扰性， 形成人工智能安全评估和管控能力。 ” \n2020年7月，国家标准化管理委员会 、中央网信办 、国家发展\n改革委员会、科学技术部、工业和信息化部发布的《国家新一代人工\n智能标准体系建设指南》指出， “重点开展人工智能安全术语、人工\n智能安全参考框架、人工智能基本安全原则和要求等标准的研制 ”。 \n2021年9月，国家新一代人工智能治理专业委员会发布《新一\n代人工智能伦理规范》 ，旨在 “将伦理道德融入人工智能全生命周期，\n促进公平、公正、和谐、安全，避免偏见、歧视、隐私和信息泄露等\n问题。 ”'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 84, 'page_label': '85'}, page_content='改革委员会、科学技术部、工业和信息化部发布的《国家新一代人工\n智能标准体系建设指南》指出， “重点开展人工智能安全术语、人工\n智能安全参考框架、人工智能基本安全原则和要求等标准的研制 ”。 \n2021年9月，国家新一代人工智能治理专业委员会发布《新一\n代人工智能伦理规范》 ，旨在 “将伦理道德融入人工智能全生命周期，\n促进公平、公正、和谐、安全，避免偏见、歧视、隐私和信息泄露等\n问题。 ” \n2022年3月，中共中央办公厅、国务院办公厅发布的《关于加\n强科技伦理治理的意见》指出，应 “加快构建中国特色科技伦理体系，\n健全多方参与、协同共治的科技伦理治理体制机制，坚持促进创新与\n防范风险相统一、制度规范与自我约束相结合，强化底线思维和风险\n意识，建立完善符合我国国情、与国际接轨的科技伦理制度，塑造科\n技向善的文化理念和保障机制 ”。 \n2023年3月，国家人工智能标准化总体组、全国信标委人工智\n能分委会发布《人工智能伦 理治理标准化指南》 ， 明确了人工智能伦\n理治理概念范畴，细化人工智能伦理 准则内涵外延，对人工智能伦理\n风险进行分类分级分析，提出人工智能伦理治理技术框架，构建人工'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 84, 'page_label': '85'}, page_content='意识，建立完善符合我国国情、与国际接轨的科技伦理制度，塑造科\n技向善的文化理念和保障机制 ”。 \n2023年3月，国家人工智能标准化总体组、全国信标委人工智\n能分委会发布《人工智能伦 理治理标准化指南》 ， 明确了人工智能伦\n理治理概念范畴，细化人工智能伦理 准则内涵外延，对人工智能伦理\n风险进行分类分级分析，提出人工智能伦理治理技术框架，构建人工\n智能伦理治理标准体系，引导人工 智能伦理治理工作健康发展。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 85, 'page_label': '86'}, page_content='85 2023年7月，国家互联网信息办公室 、国家发展和改革委员会\n等发布的《生成式人工智能服务管理暂行办法》指出， “国家坚持发\n展和安全并重、促进创新和依法治理相结合的原则，采取有效措施鼓\n励生成式人工智能创新发展， 对生成式人工智能服务实行包容审慎和\n分类分级监管 ”、“提供和使用生成式人工智能服务，应当遵守法律、\n行政法规，尊重社会公德和伦理道德 ”。 \n7.3 大模型安全风险的具体表现  \n随着大模型在各领域的广泛应用， 大模型安全风险的影响范围逐\n渐扩大，社会秩序收到的冲击愈发严重。其安全风险具体表现，可以\n从大模型自身的安全风险、 以及大模型在应用中衍生的安全风险两个\n方面进行细致 地分析。  \n7.3.1 大模型自身的安全风险  \n大模型自身的安全风险源于其开发技术与实现方式。 由于这些模\n型通常采用大量数据进行训练，它们不仅从数据中学习知识和信息，\n还可能从中吸收和反映数据中存在的不当、偏见或歧视性内容。这些\n数据可能来源于互联网或其他公开 来源， 其中包含的多样性和复杂性\n导致模型很难完全准确地反映人类的价值观 和伦理标准。此外，大模'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 85, 'page_label': '86'}, page_content='方面进行细致 地分析。  \n7.3.1 大模型自身的安全风险  \n大模型自身的安全风险源于其开发技术与实现方式。 由于这些模\n型通常采用大量数据进行训练，它们不仅从数据中学习知识和信息，\n还可能从中吸收和反映数据中存在的不当、偏见或歧视性内容。这些\n数据可能来源于互联网或其他公开 来源， 其中包含的多样性和复杂性\n导致模型很难完全准确地反映人类的价值观 和伦理标准。此外，大模\n型在处理或生成内容时， 可能会无意中扩大或放大某些固有的社会偏\n见。例如，模型可能会偏向某种文化、性 别、种族或宗教的观点，从\n而产生偏见、 歧视或误导性的输出 ，这不仅可能导致特定群体的不适，\n而且可能破坏社会的和谐与稳定。 以下列出了典型的 风险类型 [165]。 \n（1）辱骂仇恨：模型生成带有辱骂、脏字脏话、仇恨言论 等不\n当内容。  \n（2）偏见歧视：模型生成 对个人或群体的 偏见和歧视性 内容，\n通常与种族、性别、宗教、外貌 等因素有关 。 \n（3）违法犯罪：模型生成的内容涉及到违法、犯罪的观点、行\n为或动机，包括怂恿犯罪、诈骗、造谣等 内容。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 86, 'page_label': '87'}, page_content='86 （4）敏感话题：对于一些敏感和具有争议性的话题，模型输出\n了具有偏向、误导性和不准确的信息，例如，支持某个特定政治立场\n的倾向的言论会导致对其他政治观点的歧视或排斥。  \n（5）身体伤害：模型生成与身体健康相关的不安全的信息，引\n导和鼓励用户伤害自身和他人的身体， 如提供误导性的医学信息或错\n误的药品使用建议等，对用户的身体健康造成潜在的风险。  \n（6）心理伤害：模型输出与心 理健康相关的不安全的信息，包\n括鼓励自杀、引发恐慌或焦虑等内容， 影响用户的心理健康。  \n（7）隐私财产：模型生成涉及到暴露用户或第三方的隐私和财\n产信息、或者提供重大的建议如投资等，在处理这些信息时，模型应\n遵循相关法律和隐私规定，保障用户的权益，避免信息泄露和滥用。  \n（8）伦理道德：模型生成的内容认同和鼓励了 违背道德伦理的\n行为，在处理一些涉及到伦理和道德的话题时，模型需要遵循相关的\n伦理原则和道德规 范，和人类价值观保持一致。  \n此外，语言模型的意识形态已成为 AI安全的核心考量因素。模\n型在训练过程中不可避免地受训练数据中的文化与价值观所影响， 从'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 86, 'page_label': '87'}, page_content='遵循相关法律和隐私规定，保障用户的权益，避免信息泄露和滥用。  \n（8）伦理道德：模型生成的内容认同和鼓励了 违背道德伦理的\n行为，在处理一些涉及到伦理和道德的话题时，模型需要遵循相关的\n伦理原则和道德规 范，和人类价值观保持一致。  \n此外，语言模型的意识形态已成为 AI安全的核心考量因素。模\n型在训练过程中不可避免地受训练数据中的文化与价值观所影响， 从\n而决定了其形成的意识形态。以 ChatGPT 为例，其训练数据以西方\n为主。 尽管其主张政治中立， 但输出内容仍可能偏向西方主流价值观。\n为确保模型准确反映并传递文化和价值观，应深化安全对齐技术，并\n针对各国文化背景对模型的意识形态进行特定的调整。  \n7.3.2 大模型在应用中衍生的安全风险  \n随着大模型应用的广泛性和复杂性， 不当使用和恶意使用等行为\n也随之增加， 这为大模型带来了前所未有的安全挑战。  \n用户过度依赖大模型的生成内容 。大模型通过学习大量数据获得\n强大的生成能力，但由于数据的复杂性，模型会产生 看似真实却实质\n上错误的信息，这被称为“幻觉”问题。若用户盲目信任模型， 会误'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 86, 'page_label': '87'}, page_content='7.3.2 大模型在应用中衍生的安全风险  \n随着大模型应用的广泛性和复杂性， 不当使用和恶意使用等行为\n也随之增加， 这为大模型带来了前所未有的安全挑战。  \n用户过度依赖大模型的生成内容 。大模型通过学习大量数据获得\n强大的生成能力，但由于数据的复杂性，模型会产生 看似真实却实质\n上错误的信息，这被称为“幻觉”问题。若用户盲目信任模型， 会误\n以为这些“幻觉”输出是可信的，从而导致决策时遗漏关键信息，缺'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 87, 'page_label': '88'}, page_content='87 少批判性思考。在 医学诊断、法律意见 等需要高精度的领域，这种盲\n目信赖会带来巨大风险。  \n恶意攻击下的安全风险 。大模型面临着模型窃取攻击、数据重构\n攻击、指令攻击等多种 恶意攻击 。模型窃取攻击允许攻击者获取模型\n的结构和关键参数，此攻击方式不仅使攻击者免去使用模型的费用，\n还可能带来其他利益。如果攻击者完全掌握模型，可能会实施更危险\n的“白盒攻击” 。数据重构攻击使攻击者能恢复模型的训练数据，包\n括其中的敏感信息如个人医疗记录， 对个人隐私和数据所有权构成威\n胁。而指令攻击则利用模型对措辞的高度敏感性，诱导其产生违规或\n偏见内容，违反原安全设定。  \n后门攻击带来的恶意输出。 后门攻击是一种针对深度学习模型的\n新型攻击方式，其在训练过程中对模型植入隐秘后门。后门未被激活\n时，模型可正常工作，但一旦被激活，模型将输出攻击者预设的恶意\n标签。由于模型的黑箱特性，这种攻击难以检测。比如在 ChatGPT\n的强化学习阶段，在奖励模型中植入后门，使攻击者能够通过控制后\n门来控制 ChatGPT 输出 [166]。此外，后门攻击具有可迁移性。通过'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 87, 'page_label': '88'}, page_content='后门攻击带来的恶意输出。 后门攻击是一种针对深度学习模型的\n新型攻击方式，其在训练过程中对模型植入隐秘后门。后门未被激活\n时，模型可正常工作，但一旦被激活，模型将输出攻击者预设的恶意\n标签。由于模型的黑箱特性，这种攻击难以检测。比如在 ChatGPT\n的强化学习阶段，在奖励模型中植入后门，使攻击者能够通过控制后\n门来控制 ChatGPT 输出 [166]。此外，后门攻击具有可迁移性。通过\n利用 ChatGPT产生有效的后门触发器，并将其植入其他大模型，这\n为攻击者创造了新的攻击途径 [167]。因此，迫切需要研究鲁棒的分\n类器和其他防御策略来对抗此类攻击。  \n大模型访问外部资源时引发的安全漏洞 。大模型与外部数据、\nAPI或其他敏感系统的交互往往涉及诸多安全挑战。首先，当大模型\n从外部资源获取信息时，若二者之间的连接未经适当安全措施保护，\n未经过滤或验证的信息 会导致模型生成不安全和不可靠的反馈。 以自\n主智能体 AutoGPT 为例，其结合了众多功能，表现出高度的自主性\n和复杂性。 这种设计使其在缺乏人工监管时展现出无法预测的行为模'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 87, 'page_label': '88'}, page_content='大模型访问外部资源时引发的安全漏洞 。大模型与外部数据、\nAPI或其他敏感系统的交互往往涉及诸多安全挑战。首先，当大模型\n从外部资源获取信息时，若二者之间的连接未经适当安全措施保护，\n未经过滤或验证的信息 会导致模型生成不安全和不可靠的反馈。 以自\n主智能体 AutoGPT 为例，其结合了众多功能，表现出高度的自主性\n和复杂性。 这种设计使其在缺乏人工监管时展现出无法预测的行为模\n式，甚至在某些极端情况下编写潜在的毁灭性计划。因此，对于大模\n型与外部资源的交互，需要特别关注并采取严格的安全策略。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 88, 'page_label': '89'}, page_content='88 7.4 大模型安全研究关键技术  \n随着大模型安全问题的日益凸显， 全球众多知名的科研机构已将\n此作为核心研究领域，致力于探索模型的潜在薄弱点和安全风险，并\n寻求如何增强其在训练和部署时的安全性。  \n7.4.1 大模型的安全对齐技术  \n安全对齐的 大模型通常是指经过充分检验、 具备高可信度和鲁棒\n性、与人类价值观对齐的 大型机器学习模型 。这些模型的设计和 训练\n过程严格遵循伦理准则，具备透明度、可解释性和可审计性，使用户\n能够理解其行为和决策过程。同时， 安全对齐 大模型也需注重隐私和\n安全，确保在使用过程中不会 泄露敏感信息或被恶意攻击。  \n大模型暴露的安全风险，与其开发技术密不可分。当下主流的 大\n模型训练过程 可分为预训练、 有监督微调和基于反馈的强化学习微调\n三个阶段。 以ChatGPT 为例，在预训练阶段，模型在大量的互联网\n文本上学习，吸收其中的语言模式和知识，这个过程中，模型可能会\n无意间学习并模仿数据中的价值观。其次是 有监督微调 （Supervised \nFine-Tuning）阶段，模型在特定的监督数据集上进一步微调，以理解'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 88, 'page_label': '89'}, page_content='模型训练过程 可分为预训练、 有监督微调和基于反馈的强化学习微调\n三个阶段。 以ChatGPT 为例，在预训练阶段，模型在大量的互联网\n文本上学习，吸收其中的语言模式和知识，这个过程中，模型可能会\n无意间学习并模仿数据中的价值观。其次是 有监督微调 （Supervised \nFine-Tuning）阶段，模型在特定的监督数据集上进一步微调，以理解\n更具体的任务要求并调整其输出，使之更接近人类对特定任务的期\n望。 最后一个阶段是 基于人类反馈的强化学习 （Reinforcement learning \nfrom human feedback ，RLHF）阶段，此阶段的目标是让模型的输出\n与人类价值观尽可能一致，提高其有用性、真实性和无害性。  \n针对大模型开发过程中产生的安全风险， 安全对齐研究 可从提升\n训练数据的安全性 、优化安全对齐训练算法两个方面 展开，以实现更\n有用、诚实和无害的 安全大模型 。 \n（1）大模型的训练数据安全  \n训练数据的安全性是构建 安全大模型的基石。 训练数据 安全是指\n数据集的来源和质量都是可靠的，数据中蕴含的知识是准确的，数据'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 88, 'page_label': '89'}, page_content='与人类价值观尽可能一致，提高其有用性、真实性和无害性。  \n针对大模型开发过程中产生的安全风险， 安全对齐研究 可从提升\n训练数据的安全性 、优化安全对齐训练算法两个方面 展开，以实现更\n有用、诚实和无害的 安全大模型 。 \n（1）大模型的训练数据安全  \n训练数据的安全性是构建 安全大模型的基石。 训练数据 安全是指\n数据集的来源和质量都是可靠的，数据中蕴含的知识是准确的，数据\n集内容符合主流价值观。以下是 提高数据安全性的一些关键要点：'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 89, 'page_label': '90'}, page_content='89 数据的来源与预处理 。确保训练数据来自可信的、可靠的来源。\n数据应该从权威机构、专业组织、可验证的数据仓库或其他公认的数\n据提供者获得。在数据标注时，确保标注的准确性和一致性。标注过\n程应该由经过培训的专业人员进行，并且需要进行验证和审核，以确\n保标注的正确性。此外，需要进行数据清洗以去除重复项、噪声数据\n和错误数据。  \n数据的敏感信息去除 。在大模型中，保护数据的敏感信息至关重\n要，特别是当模型需要处理涉及个人隐私、敏感信息或商业机密等敏\n感数据时。数据的敏感信息去除是一种隐私保护措施，旨在确保数据\n在训练过程中不会泄露敏感信息。 常见的数据的敏感信息去除方法 有\n以下几种：  \na. 数据脱敏（ Data Anonymization ） ：数据脱敏是一种常见的敏感\n信息去除方法，它可以通过不同的技术手段对数据进行处理，以确保\n数据中的敏感信息无法被还原或追溯到特定个体。 常见的数据脱敏方\n法包括随机化、泛化 、替换和加噪声等。  \nb.去标识化（ De-identification ） ：去标识化是指删除数据中的个人'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 89, 'page_label': '90'}, page_content='以下几种：  \na. 数据脱敏（ Data Anonymization ） ：数据脱敏是一种常见的敏感\n信息去除方法，它可以通过不同的技术手段对数据进行处理，以确保\n数据中的敏感信息无法被还原或追溯到特定个体。 常见的数据脱敏方\n法包括随机化、泛化 、替换和加噪声等。  \nb.去标识化（ De-identification ） ：去标识化是指删除数据中的个人\n标识信息，例如姓名、地址、身份证号码等，从而将数据匿名化。这\n样可以确保数据无法直接与特定个体关联。  \nc. 数据掩码（ Data  Masking） ：数据掩码是一种将敏感信息部分\n替换为伪造或不可还原的数据， 从而确保原始敏感信息无法被还原的\n方法。  \n在进行数据的敏感信息去除时，需要谨慎处理，以确保不会破坏\n数据的完整性和质量。同时，也需要注意确保去除敏感信息后的数据\n仍然具有足够的信息量和代表性， 以确保训练的模型具备合理的性能\n和泛化能力。  \n（2）大模型的安全对齐训练  \n基于反馈的安全对齐技术 。基于人类反馈的安全对齐技术已逐渐'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 90, 'page_label': '91'}, page_content='90 成为当下大模型安全研究的主流技术。 其训练过程 主要包括奖励模型\n训练和生成策略优化两个子阶段。奖励模型训练阶段中，人类对模型\n生成的多条不同回复进行评估，这些回复两两组合，由人类确定哪条\n更优，生成的人类偏好标签使奖励模型能学习并拟合人类的偏好。在\n生成策略优化阶段，奖励模型根据生成回复的质量计算奖励，这个奖\n励作为强化学习框架中的反馈，并用于更新当前策略的模型参数，从\n而让模型的输出更符合人类的期望。 DeepMind 使用RLHF技术，通\n过从人类反馈中学习来构建更有用、更准确和更安全的对话智能 体\nSparrow [168]。Anthropic 公司提出的 Claude模型则采用了 RLAIF（RL \nfrom AI Feedback ）技术  [169]，该技术使用预先训练的模拟人类偏好\n的打分模型，在强化学习过程中自动对数据进行排序，从而减少对人\n类反馈的依赖。 2023年5月，北京大学团队开源了名为  PKU -Beaver\n（河狸）项目  [170]，提供了一种 可复现的  RLHF  基准，并公开了'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 90, 'page_label': '91'}, page_content='from AI Feedback ）技术  [169]，该技术使用预先训练的模拟人类偏好\n的打分模型，在强化学习过程中自动对数据进行排序，从而减少对人\n类反馈的依赖。 2023年5月，北京大学团队开源了名为  PKU -Beaver\n（河狸）项目  [170]，提供了一种 可复现的  RLHF  基准，并公开了  \nRLHF 所需的数据集、训练和验证代码。 2023年7月，复旦大学发\n布基于 RLHF实现人类对齐的 MOSS -RLHF模型 [171]，深入探究了\nRLHF阶段所采用的强化学习算法 PPO（Proximal Policy Optimization ，\n近端策略优化） ，分析其稳定训练及其在大模型人类对齐中的作用机\n理，并发布大模型人类对齐技术报告 与开源核心代码  ，以推动中文  \nNLP 社区生态发展。  \n大模型可信增强技术。 在训练的 过程中，模型可通过两个方面增\n加可信度。 首先是对抗训练，通过提升模型对输入扰动的鲁棒性增强\n模型可信度 。对抗性样本是针对大模型的输入做出微小改动，使得大\n模型的输出发生误判。对抗性训练通过在训练数据中引入这些样本，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 90, 'page_label': '91'}, page_content='理，并发布大模型人类对齐技术报告 与开源核心代码  ，以推动中文  \nNLP 社区生态发展。  \n大模型可信增强技术。 在训练的 过程中，模型可通过两个方面增\n加可信度。 首先是对抗训练，通过提升模型对输入扰动的鲁棒性增强\n模型可信度 。对抗性样本是针对大模型的输入做出微小改动，使得大\n模型的输出发生误判。对抗性训练通过在训练数据中引入这些样本，\n迫使大模型学习更具鲁棒性的特征，从而减少对抗性攻击的影响，并\n且提升大模型的泛化能力。 其次是知识融入训练 ，即利用知识引导模\n型训练从而降低模型出现幻觉的可能性。 结合知识图谱的模型训练是\n典型的知识融入训练方法， 通过在大模型训练时引入知识图谱，如将'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 91, 'page_label': '92'}, page_content='91 知识图谱中的三元组加入到模型的训练过程中， 用三元组中的知识引\n导模型的训练，促使大模型沿着具有正确知识的方向收敛，从而让大\n模型存储到高可信度的知识。  \n7.4.2 大模型安全性评测技术  \n大模型安全性评测技术 是大模型安全发展的有力保障。  \n大模型内容安全评估 。为了评估大语言模型的安全性，并推动安\n全、负责任和合乎道德的人工智能的发展和部署，清华大学于 2023\n年3月推出面向中文大模型的安全性评测平台。 该平台依托于一套系\n统的安全评测框架，从辱骂仇恨、偏见歧视、违法犯罪等八个典型安\n全场景和六种指令攻击综合 评估大语言模型的安全性能 [165]。其中，\n指令攻击是指一般模型难以处理的安全攻击方式 ， 这些攻击更容易诱\n导模型出错 ，包含目标劫持 、Prompt泄露、赋予特殊的角色后 发布\n指令、不安全 /不合理的指令主题、隐含不安全观点的询问、以及反\n面诱导。基于该框架，平台对  GPT 系列、 ChatGLM 等主流大模型\n进行了安全评估，并发现指令攻击更有可能暴露所有模型的安全问\n题。平台已开源大模型安全评测的数据基准 ，并测试了包括 ChatGPT'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 91, 'page_label': '92'}, page_content='导模型出错 ，包含目标劫持 、Prompt泄露、赋予特殊的角色后 发布\n指令、不安全 /不合理的指令主题、隐含不安全观点的询问、以及反\n面诱导。基于该框架，平台对  GPT 系列、 ChatGLM 等主流大模型\n进行了安全评估，并发现指令攻击更有可能暴露所有模型的安全问\n题。平台已开源大模型安全评测的数据基准 ，并测试了包括 ChatGPT\n在内的十余个主流大模型，其安全分数以排行榜的形式在平台公布。  \n \n图7-1 中文语言大模型安全评测框架  \n大模型极端风险的评估 。随着 AI技术的进步，大模型 将会显示\n出更多危险的突发能力，如进行攻击性的网络操作、通过对话操纵人'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 92, 'page_label': '93'}, page_content='92 们或提供有关实施恐怖主义行为的实用指导。 为了识别这些 风险，\nDeepMind 联合 OpenAI、Anthropic 等单位提出针对新型威胁评估 的\n通用模型框架， 认为大模型安全评估 首先应评估模型是否具有某些危\n险的能力 ，其次判断模型多大程度上可能使用这些能力造成伤害\n[172]。该框架指出大模型的极端风险评估将成为安全人工智能研发\n的重要组成部分， 安全评估应涵盖特定 领域的风险水平以及特定模型\n的潜在风险属性。 极端风险 评估可以帮助开发者识别可能导致极端风\n险的因素 ，并为模型训练和部署过程中 的安全性优化提供参考。  \n \n图7-2 DeepMind 等机构提出的大模型极端风险评估理论  \n大模型行为决策的道德评估 。随着 AI系统能力 的快速增长，越\n来越多的大模型被训练应用于真实世界的交互任务。 为了衡量大模型\n在各种社会决策场景中的能力和道德行为 ，一项典型的评测 基准是\nMACHIA VELLI [173]。它主要由134款基于文本的 Choose Your Own \nAdventure 游戏组成，在评估中为大模型代理提供真实世界的目标，'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 92, 'page_label': '93'}, page_content='大模型行为决策的道德评估 。随着 AI系统能力 的快速增长，越\n来越多的大模型被训练应用于真实世界的交互任务。 为了衡量大模型\n在各种社会决策场景中的能力和道德行为 ，一项典型的评测 基准是\nMACHIA VELLI [173]。它主要由134款基于文本的 Choose Your Own \nAdventure 游戏组成，在评估中为大模型代理提供真实世界的目标，\n并通过专注于高层次的决策来追踪代理的不道德行为， 以评估其在现\n实社会环境中的规划能力及安全风险。该项研究发现，道德行为和最\n大化奖励之 间存在权衡（ Trade -Offs）的关系，但通过设计道德提示，\n对大模型进行道德调节，可缓解权衡、并降低有害行为的频率。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 93, 'page_label': '94'}, page_content='93 \n \n图7-3道德行为 评测基准 MACHIAVELLI'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 94, 'page_label': '95'}, page_content='94 第8章  总结与思考  \n近年来， 大模型技术飞速发展， 从架构演进统一到训练方式转变，\n再到模型高效 适配，大模型技术引起机器学习范式的一系列重要革\n新，为通用人工智能发展提供了一种新的手段。由单一模态的语言大\n模型到语言、视觉、听觉等多模态大模型，大模型技术融合多种模态\n信息，实现多模态感知与统一表示，也 将和知识图谱、搜索引擎、博\n弈对抗、脑认知等技术融合发展，相互促进 ，朝着更高智能水平 和更\n加通用性方向发展 。 \n与此同时，大模型技术生态蓬勃发展，开源服务与开放生态成为\n主流趋势，国内外大模型开放平台、开源模型、框架、工具与公开数\n据集加速大模型技术演进，框架、工具间软硬件协同优化 降低大模型\n开发和应用成本，推动大模型高效训练与部署。  \n大模型与教育、科学、金融、传媒艺术等专用领域结合拓广通用\n大模型能力边界，与实体经济的深度融合成为其赋能行业应用关键，\n正在 “大模型 ”与“小模型 ”端云协同并进发展格局 下重塑生产力工具，\n变革信息获取方式 ，改变人类 社会生活和生产方式。  \n随着大模型的应用，其安全问题日益凸显，因而需关注大模型技'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 94, 'page_label': '95'}, page_content='开发和应用成本，推动大模型高效训练与部署。  \n大模型与教育、科学、金融、传媒艺术等专用领域结合拓广通用\n大模型能力边界，与实体经济的深度融合成为其赋能行业应用关键，\n正在 “大模型 ”与“小模型 ”端云协同并进发展格局 下重塑生产力工具，\n变革信息获取方式 ，改变人类 社会生活和生产方式。  \n随着大模型的应用，其安全问题日益凸显，因而需关注大模型技\n术发展的内生及伴生风险，关注大模型安全对齐、安全评估技术，发\n展大模型安全增强技术，加强大模型安全监管措施，确保其“安全、\n可靠、可控” 。  \n总之，抓紧推动大模型技术研发，尤其是大模型原始技术创新和\n大模型软硬件生态建设， 强化垂直行业数据基础优势，集中国家资源\n投入大模型发展，同时关注大模型风险监督，彰显人工智能的技术属\n性和社会属性。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 95, 'page_label': '96'}, page_content='95 8.1 协同多方合作，共同推动大模型发展  \n加强学术界和企业界之间合作， 是推动大模型生态安全健康发展\n的重要方面。为了促进校企之间的合作，政府可鼓励建立学术界和企\n业界之间的合作平台，以促进知识共享和技术交流。包括设立联合研\n究中心、实验室或合作项目，为学术研究人员和企业工程师提供合作\n机会和资源。其次，政府可推动学术界和企业界之间的数据共享和 协\n同研究，以增进对 大模型训练数据的理解和分析。共享数据可帮助学\n术界更好地理解大模型的特性和潜在风险， 而企业界可受益于学术界\n的深入研究和分析，进一步改进算法和模型的安全性。此外，应促进\n人才培养和交流。通过设立奖学金、建立博士生联合培养计划、鼓励\n学术界研究人员在企业界进行实地访问等方式， 促进校企之间的人才\n培养和交流、培养具备学术和实践经验的人才，推动 大模型安全可持\n续发展。  \n在大模型训练过程中，算力紧缺成为一个重要挑战。为应对算力\n紧缺问题 ，首先， 政府部门可推进建立云计算平台，提供强大 算力资\n源和相应服务，以支持大型模型的安全训练和推理。这将使研究人员'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 95, 'page_label': '96'}, page_content='人才培养和交流。通过设立奖学金、建立博士生联合培养计划、鼓励\n学术界研究人员在企业界进行实地访问等方式， 促进校企之间的人才\n培养和交流、培养具备学术和实践经验的人才，推动 大模型安全可持\n续发展。  \n在大模型训练过程中，算力紧缺成为一个重要挑战。为应对算力\n紧缺问题 ，首先， 政府部门可推进建立云计算平台，提供强大 算力资\n源和相应服务，以支持大型模型的安全训练和推理。这将使研究人员\n和开发者能够灵活地访问 所需的计算资源， 无需自行购买和维护昂贵\n硬件设备。其次，政府部门可推动产业和学术界之间的合作，共享算\n力资源。通过建立合作机制和共享平台，不同实体可共同利用算力资\n源，减轻各方算力压力。政府可提供资金和奖励措施 以促进该合作。\n此外，政府可支持推动分布式计算技术的研究 与创新。分布式计算技\n术可将多台计算机或服务器连接在一起，形成计算集群，从而提供更\n大规模的计算能力。研发分布式计算技术，推动其发展和应用，将有\n效提高算力的可扩展性和效率。最后，政府可制定激励政策，鼓励企\n业和研究机构投 资和发展与大模型算力相关的技术和设施。 包括提供'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 95, 'page_label': '96'}, page_content='源，减轻各方算力压力。政府可提供资金和奖励措施 以促进该合作。\n此外，政府可支持推动分布式计算技术的研究 与创新。分布式计算技\n术可将多台计算机或服务器连接在一起，形成计算集群，从而提供更\n大规模的计算能力。研发分布式计算技术，推动其发展和应用，将有\n效提高算力的可扩展性和效率。最后，政府可制定激励政策，鼓励企\n业和研究机构投 资和发展与大模型算力相关的技术和设施。 包括提供\n税收优惠、资金支持、知识产权保护等方面的激励措施，以吸引更多\n的投资和创新。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 96, 'page_label': '97'}, page_content='96 8.2 建立大模型合规标准和评测平台  \n相关部门可牵头制定人工智能的合规标准和开发指南， 全面覆盖\n大模型的研发、训练和部署过程中的安全要求和最佳实践，以及对大\n模型的能力水平进行评估的方法。 这样的举措有助于企业和研究机构\n建立健全的治理机制和风险管理体系，推动行业的规范化发展。  \n通过制定合规标准， 可以确保大模型的研发过程符合道德和法律\n要求。包括数据 采集和使用的透明度和合法性，隐私保护措施，以及\n对敏感主题和内容的处理原则。同时，开发指南 提供训练和部署大型\n模型时的最佳实践参考，以 辅助提升 模型可靠性、鲁棒性和公平性。\n通过制定大模型能力水平的评测标准和方法， 可衡量其在不同任务和\n领域的表现， 以帮助用户和开发者更好地了解和评估大型模型的性能\n和可靠性，为其选择合适的应用场景提供参考。评测平台可提供标准\n化的评测数据集、评估指标和基准结果，以促进模型性能的客观比较\n和提升。平台应包含多样化的评测任务，涵盖自然语言处理理解、文\n本生成、代码生成、安全伦理等不同领域和应用，以帮助评估模型在\n不同任务上的性能表现，推动多领域的 研究和应用探索。此外，应制'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 96, 'page_label': '97'}, page_content='领域的表现， 以帮助用户和开发者更好地了解和评估大型模型的性能\n和可靠性，为其选择合适的应用场景提供参考。评测平台可提供标准\n化的评测数据集、评估指标和基准结果，以促进模型性能的客观比较\n和提升。平台应包含多样化的评测任务，涵盖自然语言处理理解、文\n本生成、代码生成、安全伦理等不同领域和应用，以帮助评估模型在\n不同任务上的性能表现，推动多领域的 研究和应用探索。此外，应制\n定一套针对中文背景下大模型评测的规范和方法论， 明确评测过程中\n的数据准备、评估指标、测试方法等细节。这有助于保证评测的可重\n复性和公正性，并提供统一标准来衡量不同模型的性能和效果。  \n制定大模型合规标准、建立中文大模型评测平台，将有助于提供\n公正、可靠 的评测环境，推动中文大模型技术发展和应用。同时，评\n测平台也为学术界、企业界和开发者提供交流和合作平台，促进创新\n和协同发展。  \n此外，可 制定大模型发展纲要，在大模型核心环节和相关技术上\n做知识产权布局 。在应用生态上，建议组建包括由芯片、云计算、互\n联网、应用等上下游企业组成的产业发展联盟， 鼓励相关企业基于大'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 96, 'page_label': '97'}, page_content='制定大模型合规标准、建立中文大模型评测平台，将有助于提供\n公正、可靠 的评测环境，推动中文大模型技术发展和应用。同时，评\n测平台也为学术界、企业界和开发者提供交流和合作平台，促进创新\n和协同发展。  \n此外，可 制定大模型发展纲要，在大模型核心环节和相关技术上\n做知识产权布局 。在应用生态上，建议组建包括由芯片、云计算、互\n联网、应用等上下游企业组成的产业发展联盟， 鼓励相关企业基于大\n模型进行数字化转型升级，支持产学研三方协同的大模型研发模式。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 97, 'page_label': '98'}, page_content='97 8.3 应对大模型带来的安全性挑战  \n大模型存在大量 安全漏洞， 迫切需要加大力度进行 大模型鲁棒性\n检测与防御技术研发， 还需重视大模型对网络安全的影响 。 \n 重视大模型的鲁棒性与安全性部署 。德国萨尔大学 [174]指出现有\n语言大模型可通过自然语言提示实现灵活调节， 这也使其易受对抗性\n攻击。使用间接性提示注入的全新的攻击媒介，可使得攻击者能够在\n没有交互接口的情况下，远程利用集成大模型的应用（如 Bing的基\n于GPT-4的聊天助手） ，针对性地向可能检索到的数据注入相关不良\n提示。从计算机安全角度出发，设计系统的分类法以研究集成大模型\n的应用中的潜在漏洞，探讨攻击的传递方式以及可能造成的各种威\n胁，包括信息搜集、欺诈、入侵、恶意软件、内容操纵、服务可用性\n降低等。一系列实验表明，只需简单的提示即可成功控制模型行为，\n而当前人类设计的过滤技术似乎无法防范这种间接提示注入。 随着大\n模型功能不断增强， 几乎可人为地将所有已知网络 安全威胁到新的大\n模型生态系统中，从而对大模型潜在相关应用部署造成重大隐患。因\n此，当前研究者 应关注新出现的潜在漏洞，以促进该领域研究，并推'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 97, 'page_label': '98'}, page_content='胁，包括信息搜集、欺诈、入侵、恶意软件、内容操纵、服务可用性\n降低等。一系列实验表明，只需简单的提示即可成功控制模型行为，\n而当前人类设计的过滤技术似乎无法防范这种间接提示注入。 随着大\n模型功能不断增强， 几乎可人为地将所有已知网络 安全威胁到新的大\n模型生态系统中，从而对大模型潜在相关应用部署造成重大隐患。因\n此，当前研究者 应关注新出现的潜在漏洞，以促进该领域研究，并推\n动当前大模型相关应用更鲁棒与更安全部署。  \n重视大模型对网络安全的影响 。 传统的 Deepfake 算法（如 GAN）\n可容易生成看似逼真的虚假 内容，进而欺骗人类。尽快 ChatGPT 引\n入多种控制手段可一定程度上减少不良内容的产生、缓解上述问题\n[175]，但依然有办法使得该类先进大模型生成错误或极具风险的内\n容（如设计特定 Prompt诱发风险输出） 。因此，网络安全管理者担心\n大模型存在被黑客滥用的风险。 可从以下几方面降低大模型对网络安\n全带来的不良影响：第一，网络检测和响应，对于中型和大型企业而\n言，需要研究全面的解决方案来持续监控网络中的潜在风险活动；第'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 97, 'page_label': '98'}, page_content='入多种控制手段可一定程度上减少不良内容的产生、缓解上述问题\n[175]，但依然有办法使得该类先进大模型生成错误或极具风险的内\n容（如设计特定 Prompt诱发风险输出） 。因此，网络安全管理者担心\n大模型存在被黑客滥用的风险。 可从以下几方面降低大模型对网络安\n全带来的不良影响：第一，网络检测和响应，对于中型和大型企业而\n言，需要研究全面的解决方案来持续监控网络中的潜在风险活动；第\n二，密码安全和防护，对于个人而言，防止数据被盗的第一道防线就\n是高强度密码，须确保其独特性和难以破译性；第三，双因素身份验'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 98, 'page_label': '99'}, page_content='98 证（ 2FA），使用  2FA 作身份验证 也可增强网络 安全性。用户除了输\n入密码外，还必须输入发送到其手机或电子邮件中的验证码 ；第四，\n软件更新，保持操作系统和其他程序的更新，确 保其采用最新补丁；\n第五，杀毒软件，确保手机和设备安装杀毒软件防范在线机器人。  \n8.4 开展大模型广泛适配，推动大模型技术栈自主可控  \n鼓励企事业单位使用国产深度学习框架开展大模型训练和推理，\n加强大模型构建所需基础软件的 自主可控 性； 引导国产芯片厂商基于\n国产框架 开展与大模型的适配和融合优化， 打造功能完备的国产人工\n智能基础设施，推动大模型技术栈自主可控。'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 99, 'page_label': '100'}, page_content='99 名词索引  \n缩写  全称  页码  \nMLP  Multilayer Perceptron  6 \nRNNLM  Recurrent Neural Network Language Model  6 \nLSTM  Long Short -Term Memory  6 \nBERT  Bidirectional Encoder Representations from \nTransformers  6 \nELMo  Embeddings from Language Models  6 \nGPT  Generative Pre -trained Transformer  6 \nRLHF  Reinforcement Learning from Human Feedback  7 \nCoT Chain -of-Thoughts  7 \nToT Tree-of-Thoughts  7 \nLLaMA  Large Language Model Meta AI  10 \nLLM  Large Language Model  13'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 99, 'page_label': '100'}, page_content='RLHF  Reinforcement Learning from Human Feedback  7 \nCoT Chain -of-Thoughts  7 \nToT Tree-of-Thoughts  7 \nLLaMA  Large Language Model Meta AI  10 \nLLM  Large Language Model  13 \nMLM  Masked Language Modeling  17 \nT5 Text-to-Text Transfer Transformer  18 \nNSP Next Sentence Prediction  18 \nMIM  Masked Image Modeling  38 \nTII Technology Innovation Institute  46 \nMPT  MosaicML Pretrained Transformer  49 \nGLUE  General Language Understanding Evaluation  50'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 100, 'page_label': '101'}, page_content='100 ZeRO  Zero Redundancy Optimizer  60 \nFFN Feed -Forward Network  69 \nIR Intermediate Representation  72 \nTPU  Tensor Processing Unit  73 \nASIC  Application -Specific Integrated Circuit  73 \nFPGA  Field -Programmable Gate Array  73'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 101, 'page_label': '102'}, page_content='101 参考文献  \n[1]Hinton GE, Salakhutdinov RR. Reducing the dimensionality of data \nwith neural networks. Science, 2006, 313(5786): 504 -507. \n[2]Krizhevsky A, Sutskever I, Hinton GE. Imagenet classification with \ndeep convolutional neural networks. Communications of the ACM, 2017, \n60(6): 84 -90. \n[3]Hinton GE, Deng L, Yu D, et al. Deep neural networks for acoustic \nmodeling in speech recognition: The shared views of four research groups. \nIEEE Signal processing magazine, 2012, 29(6): 82 -97.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 101, 'page_label': '102'}, page_content='[3]Hinton GE, Deng L, Yu D, et al. Deep neural networks for acoustic \nmodeling in speech recognition: The shared views of four research groups. \nIEEE Signal processing magazine, 2012, 29(6): 82 -97. \n[4]Mikolov T, Sutskever I, Ch en K, et al. Distributed representations of \nwords and phrases and their compositionality. Advances in neural \ninformation processing systems, 2013, 26.  \n[5]Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., ... & Wen, J.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 101, 'page_label': '102'}, page_content='words and phrases and their compositionality. Advances in neural \ninformation processing systems, 2013, 26.  \n[5]Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., ... & Wen, J. \nR. (2023). A survey of large language models.  arXiv preprint \narXiv:2303.18223.  \n[6]Jelinek F. Continuous speech recognition by statistical methods. \nProceedings of the IEEE, 1976, 64(4): 532 -556. \n[7]Bengio Y, Ducharme R, Vincent P. A neural probabilistic language'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 101, 'page_label': '102'}, page_content='[6]Jelinek F. Continuous speech recognition by statistical methods. \nProceedings of the IEEE, 1976, 64(4): 532 -556. \n[7]Bengio Y, Ducharme R, Vincent P. A neural probabilistic language \nmodel. Advances in neural infor mation processing systems, 2000, 13.  \n[8]Mikolov T, Karafiá t M, Burget L, et al. Recurrent neural network \nbased language model. Interspeech. 2010, 2(3): 1045 -1048.  \n[9]Matthew, E. "Peters, Mark Neumann, Mohit Iyyer, Matt Gardner,'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 101, 'page_label': '102'}, page_content='[8]Mikolov T, Karafiá t M, Burget L, et al. Recurrent neural network \nbased language model. Interspeech. 2010, 2(3): 1045 -1048.  \n[9]Matthew, E. "Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, \nChristopher Clark, Kenton Lee, Luke Zettlemoyer. Deep contextualized \nword representations." Proc. of NAACL. V ol. 5. 2018.  \n[10]Radford A, Narasimhan K, Salimans T, et al. Improving language \nunderstanding by generative pre -training. 2018.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 101, 'page_label': '102'}, page_content='word representations." Proc. of NAACL. V ol. 5. 2018.  \n[10]Radford A, Narasimhan K, Salimans T, et al. Improving language \nunderstanding by generative pre -training. 2018.  \n[11]Devlin J, Chang MW, Lee K, et al. Bert: Pre -training of d eep'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 102, 'page_label': '103'}, page_content='102 bidirectional transformers for language understanding. arXiv preprint \narXiv:1810.04805, 2018.  \n[12]Sundermeyer M, Schlü ter R, Ney H. LSTM neural networks for \nlanguage modeling. Interspeech. 2012, 194 –197. \n[13]Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need. \nAdvances in neural information processing systems, 2017, 30.  \n[14]Kaplan J, McCandlish S, Henighan T, et al. Scaling laws for neural \nlanguage models. arXiv preprint arXiv:2001.08361, 2020.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 102, 'page_label': '103'}, page_content='Advances in neural information processing systems, 2017, 30.  \n[14]Kaplan J, McCandlish S, Henighan T, et al. Scaling laws for neural \nlanguage models. arXiv preprint arXiv:2001.08361, 2020.  \n[15]Radford A, Wu J, Child R, et al. Language models are unsup ervised \nmultitask learners. OpenAI blog, 2019, 1(8): 9.  \n[16]Brown T, Mann B, Ryder N, et al. Language models are few -shot \nlearners. Advances in neural information processing systems, 2020, 33: \n1877 -1901.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 102, 'page_label': '103'}, page_content='[16]Brown T, Mann B, Ryder N, et al. Language models are few -shot \nlearners. Advances in neural information processing systems, 2020, 33: \n1877 -1901.  \n[17]Chowdhery A, Narang S, Devlin J, et al. Palm: Scaling language \nmodeling with pathways[J]. arXiv preprint arXiv:2204.02311, 2022.  \n[18]Wei J, Tay Y, Bommasani R, et al. Emergent abilities of large \nlanguage models. arXiv preprint arXiv:2206.07682, 2022.  \n[19]Dai D, Sun Y, Dong L, et al. Why Can GPT Learn In -Context?'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 102, 'page_label': '103'}, page_content='[18]Wei J, Tay Y, Bommasani R, et al. Emergent abilities of large \nlanguage models. arXiv preprint arXiv:2206.07682, 2022.  \n[19]Dai D, Sun Y, Dong L, et al. Why Can GPT Learn In -Context? \nLangua ge Models Secretly Perform Gradient Descent as Meta Optimizers. \narXiv preprint arXiv:2212.10559, 2022.  \n[20]Wei J, Bosma M, Zhao VY, et al. Finetuned language models are \nzero-shot learners. arXiv preprint arXiv:2109.01652, 2021.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 102, 'page_label': '103'}, page_content='arXiv preprint arXiv:2212.10559, 2022.  \n[20]Wei J, Bosma M, Zhao VY, et al. Finetuned language models are \nzero-shot learners. arXiv preprint arXiv:2109.01652, 2021.  \n[21]Ouyang L, Wu J, Jiang X, et al. Training language models to follow \ninstructions with human feedback. Advances in Neural Information \nProcessing Systems, 2022, 35: 27730 -27744.  \n[22]Wei J, Wang X, Schuurmans D, et al. Chain of thought prompting \nelicits reasoning in large language models. arXiv preprint'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 103, 'page_label': '104'}, page_content='103 arXiv:2201.11903, 2022.  \n[23]Yao S, Yu D, Zhao J, et al. Tree of thoughts: Deliberate problem \nsolving with large language models[J]. arXiv preprint arXiv:2305.10601, \n2023.  \n[24]Qin Y, Hu S, Lin Y, et al. Tool learning with foundation models[J]. \narXiv preprint arXiv:2304.08354, 2023.  \n[25]Chen M, Tworek J, Jun H, et al. Evaluating large language models \ntrained on code. arXiv preprint arXiv:2107.03374, 2021.  \n[26]OpenAI. Gpt -4 technical report. 2023,'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 103, 'page_label': '104'}, page_content='[25]Chen M, Tworek J, Jun H, et al. Evaluating large language models \ntrained on code. arXiv preprint arXiv:2107.03374, 2021.  \n[26]OpenAI. Gpt -4 technical report. 2023, \nhttps://cdn.openai.com/papers/gpt -4.pdf.  \n[27]Paszke, A., Gross, S., Massa,  F., Lerer, A., Bradbury, J., Chanan, \nG., ... & Chintala, S. (2019). Pytorch: An imperative style, \nhigh-performance deep learning library. Advances in neural information \nprocessing systems, 32. Abadi, M., Agarwal, A., Barham, P., Brevdo, E.,'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 103, 'page_label': '104'}, page_content='high-performance deep learning library. Advances in neural information \nprocessing systems, 32. Abadi, M., Agarwal, A., Barham, P., Brevdo, E., \nChen, Z., Citro, C., ... & Zheng, X. (2016).  \n[28]Ma, Y., Yu, D., Wu, T., & Wang, H. (2019). PaddlePaddle: An \nopen -source deep learning platform from industrial practice. Frontiers of \nData and Domputing, 1(1), 105 -115. \n[29]Rasley, J., Rajbhandari, S., Ruwase, O., & He, Y. (2020,  August).'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 103, 'page_label': '104'}, page_content='open -source deep learning platform from industrial practice. Frontiers of \nData and Domputing, 1(1), 105 -115. \n[29]Rasley, J., Rajbhandari, S., Ruwase, O., & He, Y. (2020,  August). \nDeepspeed: System optimizations enable training deep learning models \nwith over 100 billion parameters. In Proceedings of the 26th ACM \nSIGKDD International Conference on Knowledge Discovery & Data \nMining (pp. 3505 -3506).  \n[30]Touvron H, Martin L, Stone K, et al. Llama 2: Open foundation and'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 103, 'page_label': '104'}, page_content='SIGKDD International Conference on Knowledge Discovery & Data \nMining (pp. 3505 -3506).  \n[30]Touvron H, Martin L, Stone K, et al. Llama 2: Open foundation and \nfine-tuned chat models[J]. arXiv preprint arXiv:2307.09288, 2023.  \n[31]Almazrouei E, Alobeidli H, Alshamsi A, et al. Falcon -40B: an open \nlarge language model with state -of-the-art performance[R]. Technical'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 104, 'page_label': '105'}, page_content='104 report, Technol ogy Innovation Institute, 2023.  \n[32]Zeng A, Liu X, Du Z, et al. Glm -130b: An open bilingual pre -trained \nmodel[J]. arXiv preprint arXiv:2210.02414, 2022.  \n[33]Zhang Z, Han X, Zhou H, et al. CPM: A large -scale generative \nChinese pre -trained language model[J]. AI Open, 2021, 2: 93 -99. \n[34]Zhang Z, Gu Y, Han X, et al. Cpm -2: Large -scale cost -effective \npre-trained language models[J]. AI Open, 2021, 2: 216 -224. \n[35]车万翔 , 窦志成 , 冯岩松 , 等. 大模型时代的自然语言处理：挑'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 104, 'page_label': '105'}, page_content='[34]Zhang Z, Gu Y, Han X, et al. Cpm -2: Large -scale cost -effective \npre-trained language models[J]. AI Open, 2021, 2: 216 -224. \n[35]车万翔 , 窦志成 , 冯岩松 , 等. 大模型时代的自然语言处理：挑\n战、机遇与发展 . 中国科学 : 信息科学 , 在审文章  \n[36]Liu P, Yuan W, Fu J, et al. Pre -train, prompt, and predict : A \nsystematic survey of prompting methods in natural language processing. \nACM Computing Surveys, 2023, 55(9): 1 -35. \n[37]Akyü rek E, Schuurmans D, Andreas J, et al. What learning algorithm'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 104, 'page_label': '105'}, page_content='systematic survey of prompting methods in natural language processing. \nACM Computing Surveys, 2023, 55(9): 1 -35. \n[37]Akyü rek E, Schuurmans D, Andreas J, et al. What learning algorithm \nis in-context learning? investigations with linear models. arXiv preprint \narXiv:2211.15661, 2022.  \n[38]陶建华 ,傅睿博 ,易江燕 ,王成龙 ,汪涛 .语音伪造与鉴伪的发展与挑\n战. 信息安全学报 , 2020, 5(2):28 -38 \n[39]陶建华 . 加强深度合成算法安全科研攻关  推进深度合成服务综\n合治理 . https://mp.weixin.qq.com/s/3tE3mxkodLKX70ZvTezxhg'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 104, 'page_label': '105'}, page_content='arXiv:2211.15661, 2022.  \n[38]陶建华 ,傅睿博 ,易江燕 ,王成龙 ,汪涛 .语音伪造与鉴伪的发展与挑\n战. 信息安全学报 , 2020, 5(2):28 -38 \n[39]陶建华 . 加强深度合成算法安全科研攻关  推进深度合成服务综\n合治理 . https://mp.weixin.qq.com/s/3tE3mxkodLKX70ZvTezxhg  \n[40]Ding N, Qin Y, Yang G,  et al. Delta tuning: A comprehensive study of \nparameter efficien t methods for pre -trained language models[J]. arXiv \npreprint arXiv:2203.06904, 2022.  \n[41]Liu Y, Ott M, Goyal N, et al. Roberta: A robustly optimized bert'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 104, 'page_label': '105'}, page_content='parameter efficien t methods for pre -trained language models[J]. arXiv \npreprint arXiv:2203.06904, 2022.  \n[41]Liu Y, Ott M, Goyal N, et al. Roberta: A robustly optimized bert \npretraining approach. arXiv preprint arXiv:1907.11692, 2019.  \n[42]Raffel C, Shazeer N, Roberts A, et al. Exploring the limits of transfer \nlearning with a unified text -to-text Transformer[J]. Journal of Machine \nLearning Research, 2020, 21: 1 -67.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 105, 'page_label': '106'}, page_content='105 [43]Lewis M, Liu Y, Goyal N, et al. BART: Denoising \nSequence -to-Sequence Pre -training for Natural Language Generation, \nTransl ation, and Comprehension[C]//Proceedings of ACL. 2020: \n7871 -7880.  \n[44]Sun Y, Dong L, Hu ang S, et al. Retentive Network: A Successor to \nTransformer for Large Language Models[J]. arXiv preprint \narXiv:2307.08621, 2023.  \n[45]Dao T, Fu D, Ermon S, et al. Flashattention: Fast and \nmemory -efficient exact attention with io -awareness[J]. Advances in'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 105, 'page_label': '106'}, page_content='arXiv:2307.08621, 2023.  \n[45]Dao T, Fu D, Ermon S, et al. Flashattention: Fast and \nmemory -efficient exact attention with io -awareness[J]. Advances in \nNeural Information Processing Systems, 2022, 35: 16344 -16359.  \n[46]Fedus W, Zoph B, Shazeer N. Switch transformers: Sc aling to trillion \nparameter models with simple and e ﬀicient spars ity[J]. arXiv preprint \narXiv:2101.03961, 2021.  \n[47]Google. Introducing Pathways: A next -generation AI architecture.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 105, 'page_label': '106'}, page_content='parameter models with simple and e ﬀicient spars ity[J]. arXiv preprint \narXiv:2101.03961, 2021.  \n[47]Google. Introducing Pathways: A next -generation AI architecture. \nhttps://blog.google/technology/ai/introducing -pathways -next-generation -a\ni-architecture/ . \n[48]Zhang Z, Lin Y, Liu Z, et al. Moefication: Transformer feed -forward \nlayers are mixtures of experts[J]. arXiv preprint arXiv:2110.01786, 2021.  \n[49]He J, Qiu J, Zeng A, et al. Fastmoe: A fast mixture -of-expert train ing'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 105, 'page_label': '106'}, page_content='layers are mixtures of experts[J]. arXiv preprint arXiv:2110.01786, 2021.  \n[49]He J, Qiu J, Zeng A, et al. Fastmoe: A fast mixture -of-expert train ing \nsystem[J]. arXiv preprint arXiv:2103.13262, 2021.  \n[50]Wei J, Bosma M, Zhao VY, et al . Finetuned language models are \nzero-shot learners. arXiv preprint arXiv:2109.01652, 2021.  \n[51]Wang Y , Mishra S, et al. Super -naturalinstructions: Generalization via \ndeclarative instructions on 1600+ nlp tasks[C]// Proceedings of the'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 105, 'page_label': '106'}, page_content='[51]Wang Y , Mishra S, et al. Super -naturalinstructions: Generalization via \ndeclarative instructions on 1600+ nlp tasks[C]// Proceedings of the \nEMNLP 2022: 5085 -5109.  \n[52]Iyer S, Lin X V, Pasunuru R, et al. Opt -iml: Scaling language model \ninstruction meta learning through the lens  of generalization[J]. arXiv'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 106, 'page_label': '107'}, page_content='106 preprint arXiv:2212.12017, 2022.  \n[53]Honovich O, Scialom T, Levy O, et al. Unnatural instructions: Tuning \nlanguage models wi th (almost) no human labor[J]. arXiv preprint \narXiv:2212.09689, 2022.  \n[54]Hu E J, Shen Y, Wallis P, et al. Lora: Low -rank adaptation of large \nlanguage models[J]. arXiv preprint arXiv:2106.09685, 2021.  \n[55]Ding N, Hu S, Zhao W, et al. OpenPrompt: An Open -source \nFramework for Prompt -learning[C]//Proceedings of the ACL: System'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 106, 'page_label': '107'}, page_content='language models[J]. arXiv preprint arXiv:2106.09685, 2021.  \n[55]Ding N, Hu S, Zhao W, et al. OpenPrompt: An Open -source \nFramework for Prompt -learning[C]//Proceedings of the ACL: System \nDemonstrations. 2022: 105 -113. \n[56]Hu S, Ding N, Zhao W, et al. OpenDelta: A Plug -and-play Library for \nParameter -efficient Adaptation of Pre -trained Models[J]. arXiv preprint \narXiv:2307.03084, 2023.  \n[57]Pfeiffer J, R ücklé A, Poth C, et al. Adapterhub: A framework for'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 106, 'page_label': '107'}, page_content='Parameter -efficient Adaptation of Pre -trained Models[J]. arXiv preprint \narXiv:2307.03084, 2023.  \n[57]Pfeiffer J, R ücklé A, Poth C, et al. Adapterhub: A framework for \nadapting transformers[C]// Proceedings of the EMNLP. 2020: 46 -54. \n[58]Wei J, Wang X, Schuurmans D, et al. Chain -of-thought prompting \nelicits reasoning in large language models[J]. Advances in Neural \nInformation Processing Systems, 2022, 35: 24824 -24837.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 106, 'page_label': '107'}, page_content='[58]Wei J, Wang X, Schuurmans D, et al. Chain -of-thought prompting \nelicits reasoning in large language models[J]. Advances in Neural \nInformation Processing Systems, 2022, 35: 24824 -24837.  \n[59]Han X, Zhang Z, Ding N, et al. Pre -trained mode ls: Past, present and \nfuture[J]. AI Open, 2021, 2: 225 -250. \n[60]Nakan o R, Hilton J, Balaji S, et al. Webgpt: Browser -assisted \nquestion -answering with hum an feedback[J]. arXiv preprint \narXiv:2112.09332, 2021.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 106, 'page_label': '107'}, page_content='future[J]. AI Open, 2021, 2: 225 -250. \n[60]Nakan o R, Hilton J, Balaji S, et al. Webgpt: Browser -assisted \nquestion -answering with hum an feedback[J]. arXiv preprint \narXiv:2112.09332, 2021.  \n[61]Yao S, Chen H, Yang J, et al. Webshop: Towards scalable real -world \nweb interaction with grounded language agents[J]. Advances in Neural \nInformation Processing Systems, 2022, 35: 20744 -20757.  \n[62]OpenAI. ChatGPT Plugins, 2021. URL: \nhttps://openai.com/blog/c hatgpt -plugins.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 107, 'page_label': '108'}, page_content='107 [63]Mialon G, Dess ì R, Lomeli M, et al. Augmented la nguage models: a \nsurvey[J]. arXiv preprint arXiv:2302.07842, 2023.  \n[64]Lu J, Batra D, Pa rikh D, et al. Vilbert: Pretraining task -agnostic \nvisiolinguistic representations for vision -and-language tasks[J]. Advances \nin neural information processing systems, 2019, 32.  \n[65]Radford A, Kim J W, Hallacy C, et al. Learning transferable visual \nmodels from natural language supervision[C]//International conference'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 107, 'page_label': '108'}, page_content='in neural information processing systems, 2019, 32.  \n[65]Radford A, Kim J W, Hallacy C, et al. Learning transferable visual \nmodels from natural language supervision[C]//International conference \non machine learning. PMLR, 2021: 8748 -8763.  \n[66]Jia C , Yang Y, Xia Y, et al. Scaling up visual and vision -language \nrepresentation learning with noisy text supervision[C]//International \nConference on Mac hine Learning. PMLR, 2021: 4904 -4916.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 107, 'page_label': '108'}, page_content='representation learning with noisy text supervision[C]//International \nConference on Mac hine Learning. PMLR, 2021: 4904 -4916.  \n[67]Akbari H, Yuan L, Qian R, et al. Vatt: Transformers for multimodal \nself-supervised learning from raw video, audio and text[J]. Advances in \nNeural Information Processing Systems, 2021, 34: 24206 -24221.  \n[68]Su W, Zhu X, Cao Y, et al. VL -BERT: Pre -training of Generic \nVisual -Linguistic Representations[C]//International Conference o n'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 107, 'page_label': '108'}, page_content='[68]Su W, Zhu X, Cao Y, et al. VL -BERT: Pre -training of Generic \nVisual -Linguistic Representations[C]//International Conference o n \nLearning Representations.  \n[69]Chen Y C, Li L, Yu L, et al. Uniter: Universal image -text \nrepresentation learning[C]//Computer Vision –ECCV 2020: 16th \nEuropean Conference, Glasgow, UK, August 23 –28, 2020, Proceedings, \nPart XXX. Cham: Springer International Publishing, 2020: 104 -120.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 107, 'page_label': '108'}, page_content='representation learning[C]//Computer Vision –ECCV 2020: 16th \nEuropean Conference, Glasgow, UK, August 23 –28, 2020, Proceedings, \nPart XXX. Cham: Springer International Publishing, 2020: 104 -120. \n[70]Sun C, Myers A, V ondrick C, et al. Videobert: A joint model for video \nand language representation learning[C]//Proceedings of the IEEE/CVF \ninternational conference on computer vision. 2019: 7464 -7473.  \n[71]Zhu L, Yang Y. Actbert: Learning  global -local video -text'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 107, 'page_label': '108'}, page_content='and language representation learning[C]//Proceedings of the IEEE/CVF \ninternational conference on computer vision. 2019: 7464 -7473.  \n[71]Zhu L, Yang Y. Actbert: Learning  global -local video -text \nrepresentations[C]//Proceedings of the I EEE/CVF conference on \ncomputer vision and pattern recognition. 2020: 8746 -8755.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 108, 'page_label': '109'}, page_content='108 [72]Yuan  L, Chen D, Chen Y L, et al. Florence: A new foundation model \nfor computer vision[J]. arXiv preprint arXiv:2111.11432, 2021.  \n[73]Ramesh A, Pavlov M, Goh G, et al. Zero -shot text -to-image \ngeneration[C]//International Conference on Machine Learning. PMLR, \n2021: 8821 -8831.  \n[74]Razavi A, Van den Oord A, Vinyals O. Generating diverse \nhigh-fidelity images with vq -vae-2[J]. A dvances in neural information \nprocessing systems, 2019, 32.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 108, 'page_label': '109'}, page_content='2021: 8821 -8831.  \n[74]Razavi A, Van den Oord A, Vinyals O. Generating diverse \nhigh-fidelity images with vq -vae-2[J]. A dvances in neural information \nprocessing systems, 2019, 32.  \n[75]Ding M, Yang Z, Hong W, et al. Cogview: Mastering text -to-image \ngeneration via transforme rs[J]. Advances in Neural Information \nProcessing Systems, 2021, 34: 19822 -19835.  \n[76]Wang J, Yang Z, Hu X, et al. GIT: A Generative Image -to-text \nTransformer for Vision and Language[J]. Transactions of Machine'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 108, 'page_label': '109'}, page_content='Processing Systems, 2021, 34: 19822 -19835.  \n[76]Wang J, Yang Z, Hu X, et al. GIT: A Generative Image -to-text \nTransformer for Vision and Language[J]. Transactions of Machine \nLearning Research.  \n[77]Rombach R, Blattmann A, Lorenz D, et al. High -resolution image \nsynthesis with latent diffusion models[C]//Proceedings of the IEEE/CVF \nconference on computer vision and pattern recognition. 2022: \n10684 -10695 \n[78]Ramesh A, Dhariwal P, Nichol A, et al. Hierarchical text -conditional'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 108, 'page_label': '109'}, page_content='conference on computer vision and pattern recognition. 2022: \n10684 -10695 \n[78]Ramesh A, Dhariwal P, Nichol A, et al. Hierarchical text -conditional \nimage gener ation with clip latents[J]. arXiv preprint arXiv:2204.06125, \n2022, 1(2): 3.  \n[79]Saharia C, Chan W, Saxena S, et al. Photorealistic text -to-image \ndiffusion models with deep language understanding[J]. Advances in \nNeural Information Processing Systems, 2022, 35: 36479 -36494.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 108, 'page_label': '109'}, page_content='diffusion models with deep language understanding[J]. Advances in \nNeural Information Processing Systems, 2022, 35: 36479 -36494.  \n[80]Cho J, Lei J, Tan H, et al. Unifying vision -and-language tasks via text \ngeneration[C]//Interna tional Conference on Machine Learning. PMLR, \n2021: 1931 -1942.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 109, 'page_label': '110'}, page_content='109 [81]Zhou L, Palangi H, Zhang L, et al. Unified vision -language \npre-training for image capti oning and vqa[C]//Proceedings of the AAAI \nconference on artificial intelligence. 2020, 34(07): 13041 -13049.  \n[82]Li, J., Li, D., Savarese, S., & Hoi, S. (2023). BLIP -2: Bootstrapping \nLanguage -Image Pre -training with Frozen Image Encoders and Large \nLanguage Models. ArXiv. /abs/2301.12597.  \n[83]Yu F, Tang J, Yin W, et al. Ernie -vil: Knowledge enhanced'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 109, 'page_label': '110'}, page_content='Language -Image Pre -training with Frozen Image Encoders and Large \nLanguage Models. ArXiv. /abs/2301.12597.  \n[83]Yu F, Tang J, Yin W, et al. Ernie -vil: Knowledge enhanced \nvision -language repre sentations through scene graphs[C]//Proceedings of \nthe AAAI Confe rence on Artificial Intelligence. 2021, 35(4): 3208 -3216.  \n[84]Marino K, Chen X, Parikh D , et al. Krisp: Integrating implicit and \nsymbolic knowledge for open -domain knowledge -based'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 109, 'page_label': '110'}, page_content='[84]Marino K, Chen X, Parikh D , et al. Krisp: Integrating implicit and \nsymbolic knowledge for open -domain knowledge -based \nvqa[C]//Proceedings of the IEEE/CVF Conference on Computer Vision \nand Pattern Recognition. 2021: 14111 -14121.  \n[85]Alayrac J B, Donahue J, Luc P, et al. Flamingo: a visual language \nmodel for few -shot learning[J]. Advances in Neural Information \nProcessing Systems, 2022, 35: 23 716-23736.  \n[86]Huang S, Dong L, Wang W, et al. Language is not all yo u need:'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 109, 'page_label': '110'}, page_content='model for few -shot learning[J]. Advances in Neural Information \nProcessing Systems, 2022, 35: 23 716-23736.  \n[86]Huang S, Dong L, Wang W, et al. Language is not all yo u need: \nAligning perception with language models[J]. arXiv preprint \narXiv:2302.14045 , 2023.  \n[87]Touvron H, Lavril T, Izacard G, et al. Llama: Open and efficient \nfoundation language models[J]. arXiv preprint arXiv:2302.13971, 2023.  \n[88]Zhao, Z. , Guo, L., Yue T., Chen, S., Zhu, X., Liu, J. ChatBridge:'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 109, 'page_label': '110'}, page_content='foundation language models[J]. arXiv preprint arXiv:2302.13971, 2023.  \n[88]Zhao, Z. , Guo, L., Yue T., Chen, S., Zhu, X., Liu, J. ChatBridge: \nBridging Modalities with Large Language Model as a Language Catalyst, \narXiv:2305.16103.  \n[89]Singhal K, Azizi S, Tu T, et al. Large language models encode \nclinical knowledge[J]. arXiv preprint arXiv:2212.13138, 2022.  \n[90]Driess  D, Xia F, Sajjadi M S M, et al. Palm -e: An embodied'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 110, 'page_label': '111'}, page_content='110 multimodal language model[J]. a rXiv preprint arXiv:2303.03378, 2023.  \n[91]S. Biderman, H. Schoelkopf, Q. Anthony, H. Bradley, K. O’Brien, E. \nHallahan, M. A. Khan, S. Purohit, U. S. Prashanth, E. Raff et al., “Pythia: \nA suite for analyzing large language models across training and scaling,” \narXiv preprint arXiv:2304.01373, 2023.  \n[92]Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ilić, S., Hesslow, D.,  ... & \nManica, M. (2022). Bloom: A 176b -parameter open -access mul tilingual'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 110, 'page_label': '111'}, page_content='arXiv preprint arXiv:2304.01373, 2023.  \n[92]Scao, T. L., Fan, A., Akiki, C., Pavlick, E., Ilić, S., Hesslow, D.,  ... & \nManica, M. (2022). Bloom: A 176b -parameter open -access mul tilingual \nlanguage model.  arXiv preprint arXiv:2211.05100 . \n[93]Black, Sid, Leo Gao, Phil  Wang, Connor Leahy and Stella Rose \nBiderman. “GPT -Neo: Large Scale Autoregressive Language Modeling \nwith Mesh -Tensorflow.” (2021)  \n[94]S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 110, 'page_label': '111'}, page_content='Biderman. “GPT -Neo: Large Scale Autoregressive Language Modeling \nwith Mesh -Tensorflow.” (2021)  \n[94]S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. \nDewan, M. T. Diab, X. Li, X. V. Lin, T. Mihaylov, M. Ott, S. Shleifer, K. \nShuster, D. Simig, P. S. Koura, A. Sridhar, T. Wang, and L. Zettlemoyer, \n“OPT: open pre -trained transformer language models,” CoRR, vol. \nabs/2205.01068, 2022.  \n[95]Press, Ofir, Noah A. Smith, and Mike Lewis. "Train short, test long:'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 110, 'page_label': '111'}, page_content='“OPT: open pre -trained transformer language models,” CoRR, vol. \nabs/2205.01068, 2022.  \n[95]Press, Ofir, Noah A. Smith, and Mike Lewis. "Train short, test long: \nAttention with  linear biases enables input length extrapolation." arXiv \npreprint arXiv:2108.12409 (2021).  \n[96]Sun, Y., Wang, S., Li, Y., Feng, S., Chen, X., Zhang, H., ... & Wu, H. \n(2019). Ernie: Enhanced representation through knowledge \nintegration.  arXiv preprint arXiv:1904.09223.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 110, 'page_label': '111'}, page_content='[96]Sun, Y., Wang, S., Li, Y., Feng, S., Chen, X., Zhang, H., ... & Wu, H. \n(2019). Ernie: Enhanced representation through knowledge \nintegration.  arXiv preprint arXiv:1904.09223.  \n[97]Y. Sun, S. Wang, S. Feng, S. Ding, C. Pang, J. Shang, J. Liu, X. Chen, \nY. Zhao, Y. Lu, W. Liu, Z . Wu, W. Gong, J. Liang, Z. Shang, P. Sun, W. \nLiu, X. Ouyang, D. Yu, H. Tian, H. Wu, and H. Wang, “ERNIE 3.0: \nLarge -scale knowledge enhanced pre -training for language understanding'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 110, 'page_label': '111'}, page_content='Liu, X. Ouyang, D. Yu, H. Tian, H. Wu, and H. Wang, “ERNIE 3.0: \nLarge -scale knowledge enhanced pre -training for language understanding \nand generation,” CoRR, vol. abs/2107.02137, 2021. Wu, and H. Wang,'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 111, 'page_label': '112'}, page_content='111 “ERNIE 3.0: Large -scale knowledge enhanced pre -training for language \nunderstanding and generation, ” CoRR, vol. abs/2107.02137, 2021.  \n[98]Du Z, Qian Y, Liu X, et al. Glm: General language model pretraining \nwith autoregressive blank infilling[J]. arXiv preprint arXiv:21 03.10360, \n2021.  \n[99]Liu, X., Ji, K., Fu, Y., Tam, W. L., Du, Z., Yang , Z., & Tang, J. (2021). \nP-tuning v2: Prompt tuning can be comparable to fine -tuning  universally'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 111, 'page_label': '112'}, page_content='2021.  \n[99]Liu, X., Ji, K., Fu, Y., Tam, W. L., Du, Z., Yang , Z., & Tang, J. (2021). \nP-tuning v2: Prompt tuning can be comparable to fine -tuning  universally \nacross scales and tasks.  arXiv preprint arXiv:2110.07602.  \n[100] Zeng W, Ren X, Su T, et al. Pangu -$\\alpha $: Large -scale \nautoregressive pretrained Chinese language models with auto -parallel \ncomputation[J]. arXiv preprint arXiv:2104.12369, 2021.  \n[101] Peng Z, Wang W, Dong L, et al. Kosmos -2: Grounding Multimodal'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 111, 'page_label': '112'}, page_content='autoregressive pretrained Chinese language models with auto -parallel \ncomputation[J]. arXiv preprint arXiv:2104.12369, 2021.  \n[101] Peng Z, Wang W, Dong L, et al. Kosmos -2: Grounding Multimodal \nLarge Language Models to the World[J]. arXiv prep rint \narXiv:2306.14824, 2023.  \n[102] Awadalla A, Gao I, Gardner J, et al . OpenFlamingo: An \nOpen -Source Framework for Training Large Autoregressive \nVision -Language Models[J]. arXiv preprint arXiv:2308.01390, 2023.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 111, 'page_label': '112'}, page_content='[102] Awadalla A, Gao I, Gardner J, et al . OpenFlamingo: An \nOpen -Source Framework for Training Large Autoregressive \nVision -Language Models[J]. arXiv preprint arXiv:2308.01390, 2023.  \n[103] Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, \nJunqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi. \nInstructblip: Towards general -purpose vision -language models with \ninstruction tuning. arXiv preprint arXiv:2305.06500, 2023.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 111, 'page_label': '112'}, page_content='Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi. \nInstructblip: Towards general -purpose vision -language models with \ninstruction tuning. arXiv preprint arXiv:2305.06500, 2023.  \n[104] Zhu, D., Chen, J., Shen, X., Li, X., & Elhoseiny, M.  (2023). \nMiniGPT -4: Enhancing Vision -Language Understanding with Advanced \nLarge Language Models. ArXiv. /abs/2304.10592.  \n[105] Gao, P., Han, J., Zhang, R.,  Lin, Z., Geng, S., Zhou, A., Zhang, W.,'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 111, 'page_label': '112'}, page_content='MiniGPT -4: Enhancing Vision -Language Understanding with Advanced \nLarge Language Models. ArXiv. /abs/2304.10592.  \n[105] Gao, P., Han, J., Zhang, R.,  Lin, Z., Geng, S., Zhou, A., Zhang, W., \nLu, P., He, C., Yue, X., Li, H., & Qiao, Y. (2023). LLaMA -Adapter V2: \nParameter -Efficient Visual Instruction Model. ArXiv. /abs/2304.15010.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 112, 'page_label': '113'}, page_content='112 [106] Rohit Girdhar, Alaaeldin El -Nouby, Zhuang Liu, Mannat Singh, \nKalyan Vasudev Alwala, Armand Joulin, and Ishan Misra. 2023. \nImagebind: One embedding space to bind them all. arXiv prepr int \narXiv:2305.05665.  \n[107] Visualglm -6b. https://github.com/THUDM/Visu alGLM -6B, 2023. \nHu J, Yao Y, Wang C, et al.  \n[108] Large Multilingual Models Pivot Zero -Shot Multimodal Learning \nacross Languages[J]. arXiv preprint arXiv:2308.12038, 2023.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 112, 'page_label': '113'}, page_content='Hu J, Yao Y, Wang C, et al.  \n[108] Large Multilingual Models Pivot Zero -Shot Multimodal Learning \nacross Languages[J]. arXiv preprint arXiv:2308.12038, 2023.  \n[109] Chiang W L, Li Z, Lin Z, et al. Vicuna: An open -source chatbot \nimpressing gpt -4 with 90%* chatgpt quality[J]. See https://vicuna. lmsys. \norg (accessed 14 April 2023), 2023.  \n[110] Ye, Q., Xu, H., Xu, G., Ye, J., Yan, M., Zhou, Y., Wang, J., Hu, A., \nShi, P., Shi, Y., Li, C., Xu, Y., Chen , H., Tian, J., Qi, Q., Zhang, J., &'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 112, 'page_label': '113'}, page_content='org (accessed 14 April 2023), 2023.  \n[110] Ye, Q., Xu, H., Xu, G., Ye, J., Yan, M., Zhou, Y., Wang, J., Hu, A., \nShi, P., Shi, Y., Li, C., Xu, Y., Chen , H., Tian, J., Qi, Q., Zhang, J., & \nHuang, F. (2023). MPLUG -Owl:  Modularization Empowers Large \nLanguage Models with Multimodality. ArXiv. /abs/2304. 14178.  \n[111] Bai J, Bai S, Yang S, et al. Qwen -VL: A Frontier Large \nVision -Language Model with Versatile Abilities[J]. arXiv preprint \narXiv:2308.12966, 2023.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 112, 'page_label': '113'}, page_content='[111] Bai J, Bai S, Yang S, et al. Qwen -VL: A Frontier Large \nVision -Language Model with Versatile Abilities[J]. arXiv preprint \narXiv:2308.12966, 2023.  \n[112] Tensorflow: Large -scale machine learning on heterogeneous \ndistributed systems. arXiv preprint arXiv:1603.04467.  \n[113] Ma, Y., Yu, D., Wu, T., & Wang, H. (2019). PaddlePaddle: An \nopen -source deep learning platform from  industrial practice. Frontiers of \nData and Domputing, 1(1), 105 -115.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 112, 'page_label': '113'}, page_content='[113] Ma, Y., Yu, D., Wu, T., & Wang, H. (2019). PaddlePaddle: An \nopen -source deep learning platform from  industrial practice. Frontiers of \nData and Domputing, 1(1), 105 -115. \n[114] L. Huawei Technologies Co., “Huawei mindspore ai development \nframework,” in Art ificial Intelligence Technology. Springer, 2022, pp. \n137–162.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 113, 'page_label': '114'}, page_content='113 [115] Hu, S.M., Liang, D., Yang, G.Y ., Yang, G.W. and Zhou, W.Y ., 2020. \nJittor: a novel deep learning framework with meta -operators and unified \ngraph execution. Science China Information Sciences, 63, pp.1 -21. \n[116] Yuan, J., Li, X., Cheng, C., Liu, J., Guo, R., Cai, S., ... & Zhao, J. \n(2021). Oneflow: Redesign the distributed deep learning framework from \nscratch. arXiv prepr int arXiv:2110.15032.  \n[117] Li, S., Fang, J., Bian, Z., Liu, H., Liu, Y., Huang, H., ... &  You, Y.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 113, 'page_label': '114'}, page_content='(2021). Oneflow: Redesign the distributed deep learning framework from \nscratch. arXiv prepr int arXiv:2110.15032.  \n[117] Li, S., Fang, J., Bian, Z., Liu, H., Liu, Y., Huang, H., ... &  You, Y. \n(2021). Colossal -AI: A unified deep learning system for large -scale \nparallel training. arXiv preprint arXiv:2110.14883.  \n[118] Shoeybi, M., Patwary, M., Puri, R., LeGresley, P., Casper, J., & \nCatanzaro, B. (2019). Megatron -lm: Training multi -billion parameter'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 113, 'page_label': '114'}, page_content='parallel training. arXiv preprint arXiv:2110.14883.  \n[118] Shoeybi, M., Patwary, M., Puri, R., LeGresley, P., Casper, J., & \nCatanzaro, B. (2019). Megatron -lm: Training multi -billion parameter \nlanguage models using model parallelism. arXiv preprint \narXiv:1909.08053.  \n[119]张奇、桂韬、郑锐、黄萱菁，大规模语言模型：从理论到实践 ，\nhttps://intro -llm.github.io/, 2023.  \n[120] Du N, Huang Y, Dai A M, et a l. Glam: Efficient scaling of language \nmodels with mixture -of-experts [C]//Internati onal Conference on'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 113, 'page_label': '114'}, page_content='https://intro -llm.github.io/, 2023.  \n[120] Du N, Huang Y, Dai A M, et a l. Glam: Efficient scaling of language \nmodels with mixture -of-experts [C]//Internati onal Conference on \nMachine Learning. PMLR, 2022: 5547 -5569.  \n[121] Rae J W, Borgeaud S, Cai T, et al. Scaling language models: \nMethods, analysis & insights from training gopher[J]. arXiv preprint \narXiv:2112.11446, 2021.  \n[122] Ouyang L, Wu J, Jiang X, et al. Training language models to follow'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 113, 'page_label': '114'}, page_content='Methods, analysis & insights from training gopher[J]. arXiv preprint \narXiv:2112.11446, 2021.  \n[122] Ouyang L, Wu J, Jiang X, et al. Training language models to follow \ninstructions with human feedback[J]. Advances in Neural Information \nProcessing Syst ems, 2022, 35: 27730 -27744.  \n[123] Chen S, Li H, Wang Q, et al. VAST: A Vision -Audio -Subtitle -Text \nOmni -Modality Foundation Model and Dataset[J]. arXiv prep rint'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 114, 'page_label': '115'}, page_content='114 arXiv:2305.18500, 2023.  \n[124] Bain M, Nagrani A, Varol G, et al. Frozen in time: A joint video and \nimage encoder for end -to-end retrieval[C]//Proceedings of the IEEE/CVF \nInternational Conference on Computer Vision. 2021: 1728 -1738.  \n[125] Zhu Y, Kiros R, Zemel R, et al. Aligning books and movies: \nTowards story -like visual explanations by watching movies and reading \nbooks[C]//Proceedings of the IEEE international conference on comput er \nvision. 2015: 19 -27.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 114, 'page_label': '115'}, page_content='Towards story -like visual explanations by watching movies and reading \nbooks[C]//Proceedings of the IEEE international conference on comput er \nvision. 2015: 19 -27. \n[126] Gao L, Biderman S, Black S, et al. The pile: An 800gb datase t of \ndiverse text for language modeling [J]. arXiv preprint arXiv:2101.00027, \n2020.  \n[127] Bai Y, Jones A, Ndousse K, et al. Training a helpful and harmless \nassistant with reinforcement learning from human feedback[Z]. 2022.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 114, 'page_label': '115'}, page_content='2020.  \n[127] Bai Y, Jones A, Ndousse K, et al. Training a helpful and harmless \nassistant with reinforcement learning from human feedback[Z]. 2022.  \n[128] Taori R, Gulrajani I, Zhang T, et al. Stanford alpaca: An \ninstruction -following llama model[J/OL]. GitHub repository, 2023. \nhttps://github.com/tatsu -lab/stanford_alpaca . \n[129] static -hh. https://huggingface.co/datasets/Dahoas/static -hh, 2023  \n[130] ShareGPT.https://huggingface.co/datasets/anon8231489123/ShareG'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 114, 'page_label': '115'}, page_content='https://github.com/tatsu -lab/stanford_alpaca . \n[129] static -hh. https://huggingface.co/datasets/Dahoas/static -hh, 2023  \n[130] ShareGPT.https://huggingface.co/datasets/anon8231489123/ShareG\nPT_Vicuna_unfiltered/tree/main, 2023  \n[131] zhihu_rlhf_3k.https://huggingface.co/datasets/liyucheng/zhihu_rlhf_\n3k, 2023  \n[132] Beaver Tails.https://huggingface.co/datasets/PKU -Alignment/PKU -S\nafeRLHF/viewer/PKU -Alignment --PKU -SafeRLHF, 2023'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 114, 'page_label': '115'}, page_content='3k, 2023  \n[132] Beaver Tails.https://huggingface.co/datasets/PKU -Alignment/PKU -S\nafeRLHF/viewer/PKU -Alignment --PKU -SafeRLHF, 2023  \n[133] Ordonez V, K ulkarni G, Berg T. Im2text: Describing images using 1 \nmillion cap tioned photographs[J]. Advances in neural information \nprocessing systems, 2011, 24.  \n[134] Lin T Y, Maire M, Belongie S, et al. Microsoft coco: Common'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 115, 'page_label': '116'}, page_content='115 objects in context[C]//Computer Vision –ECCV 2014: 13th European \nConference, Zurich, Switzerland, September 6 -12, 2014, Proceedings, \nPart V 13. Springer International Publishing, 2014: 740 -755. \n[135] Krishna R, Zhu Y, Groth O, et al. Visual genome: Connecting \nlanguage and vision using crowdsourced dense image  annotations[J]. \nInternational journal of computer vision, 2017, 123: 32 -73. \n[136] Changpinyo S, Sharma P, Ding N, et al. Conceptual 12m: Pushing'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 115, 'page_label': '116'}, page_content='International journal of computer vision, 2017, 123: 32 -73. \n[136] Changpinyo S, Sharma P, Ding N, et al. Conceptual 12m: Pushing \nweb-scale  image -text pre -training to recognize long -tail visual \nconcepts[C]//Proceedings of the IEEE/CVF Conference on Computer \nVision and Pattern Recognition. 2021: 3558 -3568.  \n[137] M. Byeon, B. Park, H. Kim, S. Lee, W. Baek, and S. Kim, \n“Coyo -700m: Image -text pair dataset,” \nhttps://github.com/kakaobrain/coyo -dataset, 2022.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 115, 'page_label': '116'}, page_content='[137] M. Byeon, B. Park, H. Kim, S. Lee, W. Baek, and S. Kim, \n“Coyo -700m: Image -text pair dataset,” \nhttps://github.com/kakaobrain/coyo -dataset, 2022.  \n[138] Miech A, Zhukov D, Alayrac J B, et al. Howto100m: L earning a \ntext-video embedding by watching hundred million narrat ed video \nclips[C]//Proceedings of the IEEE/CVF international conference on \ncomputer vision. 2019: 2630 -2640.  \n[139] Zellers R, Lu X, Hessel J, et al. Merlot: Multimodal neural script'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 115, 'page_label': '116'}, page_content='clips[C]//Proceedings of the IEEE/CVF international conference on \ncomputer vision. 2019: 2630 -2640.  \n[139] Zellers R, Lu X, Hessel J, et al. Merlot: Multimodal neural script \nknowledge models[J]. Advances in Neural Information Processing \nSystems, 2021, 34: 23634 -23651.  \n[140] Xue H, Hang T, Zeng Y, et al. Advancing high -resolution \nvideo -language representation with large -scale video \ntranscriptions[C]//Proceedings of the IEEE/CVF Conference on'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 115, 'page_label': '116'}, page_content='[140] Xue H, Hang T, Zeng Y, et al. Advancing high -resolution \nvideo -language representation with large -scale video \ntranscriptions[C]//Proceedings of the IEEE/CVF Conference on \nComput er Vision and Pattern Recognition. 2022: 5036 -5045.  \n[141] Chen S, He X,  Guo L, et al. Valor: Vision -audio -language \nomni -perception pretraining model and da taset[J]. arXiv preprint \narXiv:2304.08345, 2023.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 116, 'page_label': '117'}, page_content='116 [142] Ren J, Rajbhandari S, Aminabadi R Y, et al. {ZeRO -Offload}: \nDemocratizing {Billion -Scale} model training[C]//2021 USENIX Annual \nTechnical Conference (USENIX ATC 21). 2021: 551 -564. \n[143] Darema F, George D A, Norton V A, et al. A \nsingle -program -multiple -data computational model for \nEPEX/FORTRAN[J]. Parallel Computing, 1988, 7(1): 11 -24. \n[144] Huang Y, Cheng Y, Bapna A, et al. Gpipe: Effic ient training of giant'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 116, 'page_label': '117'}, page_content='single -program -multiple -data computational model for \nEPEX/FORTRAN[J]. Parallel Computing, 1988, 7(1): 11 -24. \n[144] Huang Y, Cheng Y, Bapna A, et al. Gpipe: Effic ient training of giant \nneural networks using pipeline parallelism[J]. Advances in ne ural \ninformation processing systems, 2019, 32.   \n[145] Narayanan D, Shoeybi M, Casper J, et al. Efficient large -scale \nlanguage model training on gpu clusters using \nmegatron -lm[C]//Proceedings of the International Conference for High'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 116, 'page_label': '117'}, page_content='[145] Narayanan D, Shoeybi M, Casper J, et al. Efficient large -scale \nlanguage model training on gpu clusters using \nmegatron -lm[C]//Proceedings of the International Conference for High \nPerformance Computing, Networking, Storage and Analysis. 2021: 1 -15.  \n[146] Rajbhandari S, Rasley J, Ruwase O, et al. Zero: Memory \noptimization s toward training trillion parameter models[C]//SC20: \nInternation al Conference for High Performance Computing, Networking,'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 116, 'page_label': '117'}, page_content='optimization s toward training trillion parameter models[C]//SC20: \nInternation al Conference for High Performance Computing, Networking, \nStorage and Analysis. IEEE , 2020: 1 -16.  \n[147] Smith S, Patwary M, Norick B, et al. Using deepspeed and \nmegatron to train megatron -turing nlg 530b, a large -scale generative \nlanguage model[J]. arXiv preprint arXiv:2201.11990, 2022.  \n[148] Ao Y, Wu Z, Yu D, et al. End -to-end adaptive distributed training on'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 116, 'page_label': '117'}, page_content='language model[J]. arXiv preprint arXiv:2201.11990, 2022.  \n[148] Ao Y, Wu Z, Yu D, et al. End -to-end adaptive distributed training on \npaddlepaddle[J]. arXiv preprint arXiv:2112.02752, 2021.  \n[149] Liang T, Glossner J, Wang L, et al. Pru ning and quantization for \ndeep neural network acceleration: A sur vey[J]. Neurocomputing, 2021, \n461: 370 -403. \n[150] Kurtic E, Frantar E, Alistarh D. Ziplm: Hardware -aware structured \npruning of language models[J]. arXiv preprint arXiv:2302.04089, 2023.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 117, 'page_label': '118'}, page_content='117 [151] Frantar E, Alistarh D. Massive language models can be accurately \npruned in one -shot[J]. arXiv preprint arXiv:2301.00774, 2023.  \n[152] Lan Z, Chen M, Goodman S, et al. Albert: A lite bert for \nself-supervised learning of language representations[J]. arXiv preprint \narXiv:1909. 11942, 2019.  \n[153] Dettmers T, Lewis M, Belkada Y, et al. Llm. int8 ():  8-bit matrix \nmultiplication for transformers at scale[J]. arXiv preprint \narXiv:2208 .07339, 2022.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 117, 'page_label': '118'}, page_content='arXiv:1909. 11942, 2019.  \n[153] Dettmers T, Lewis M, Belkada Y, et al. Llm. int8 ():  8-bit matrix \nmultiplication for transformers at scale[J]. arXiv preprint \narXiv:2208 .07339, 2022.  \n[154] Frantar E, Ashkboos S, Hoefler T, et al. OPTQ: Accurate \nquantization for generative pre -trained transformers[C]//The Eleventh \nInternational Conference on Learning Representations. 2022.  \n[155] Bondarenko Y, Nagel M, Blankevoort T. Understanding and'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 117, 'page_label': '118'}, page_content='quantization for generative pre -trained transformers[C]//The Eleventh \nInternational Conference on Learning Representations. 2022.  \n[155] Bondarenko Y, Nagel M, Blankevoort T. Understanding and \novercoming the challenges of efficient transformer quantization[J]. arXiv \npreprint arXiv:2109.12948, 2021.  \n[156] Xiao G, Lin J, Seznec M, et al. Smoothquant: Accurate and efficie nt \npost-training quantization for large language models[C]//International'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 117, 'page_label': '118'}, page_content='preprint arXiv:2109.12948, 2021.  \n[156] Xiao G, Lin J, Seznec M, et al. Smoothquant: Accurate and efficie nt \npost-training quantization for large language models[C]//International \nConference  on Machine Learning. PMLR, 2023: 38087 -38099.  \n[157] [http://taichu.ia.ac.cn/  \n[158] Lin J, Men R, Yang A, et al. M6: A chinese multimodal pretrainer[J]. \narXiv preprint arXiv:2103.00823, 2021.  \n[159] Avsec Ž, Agarwal V , Visentin D, et al. Effective gene expression'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 117, 'page_label': '118'}, page_content='[158] Lin J, Men R, Yang A, et al. M6: A chinese multimodal pretrainer[J]. \narXiv preprint arXiv:2103.00823, 2021.  \n[159] Avsec Ž, Agarwal V , Visentin D, et al. Effective gene expression \nprediction from sequence by integrating long -range interactions[J]. \nNature methods, 2021, 18(10): 1196 -1203.  \n[160] Frazer J,  Notin P, Dias M, et al. Disease variant prediction with deep \ngenerative models of evolutionary data[J]. Nature, 2021, 599(7883): \n91-95.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 117, 'page_label': '118'}, page_content='Nature methods, 2021, 18(10): 1196 -1203.  \n[160] Frazer J,  Notin P, Dias M, et al. Disease variant prediction with deep \ngenerative models of evolutionary data[J]. Nature, 2021, 599(7883): \n91-95. \n[161] Jumper J, Ev ans R, Pritzel A, et al. Highly accurate protein structure'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 118, 'page_label': '119'}, page_content='118 prediction with AlphaFold[J]. Nature, 2021, 596(7873): 583 -589. \n[162] Brohan A, Brown N, Carbajal J, et al. Rt -1: Robotics transformer for \nreal-world control at scale[J]. arXiv preprint arXiv:2212.06817, 2022.  \n[163] Sun Y, Ma S, Madaan R, et al. SMART: Self -supervised Multi -task \npretrAining with contRol Transformer s[J]. arXiv preprint \narXiv:2301.09816, 2023.  \n[164] Bi K, Xie L, Zhang H , et al. Accurate medium -range global weather'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 118, 'page_label': '119'}, page_content='pretrAining with contRol Transformer s[J]. arXiv preprint \narXiv:2301.09816, 2023.  \n[164] Bi K, Xie L, Zhang H , et al. Accurate medium -range global weather \nforecasting with 3D neural networks[J] . Nature, 2023: 1 -6. \n[165] Sun H, Zhang Z, Deng J, et al. Safety Assessment of Chinese Large \nLanguage Models[J]. arXiv preprint arXiv:2304.10436, 2023.  \n[166] Shi J, Liu Y, Zhou P, et al. BadGPT: Exploring Security \nVulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT[J].'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 118, 'page_label': '119'}, page_content='Language Models[J]. arXiv preprint arXiv:2304.10436, 2023.  \n[166] Shi J, Liu Y, Zhou P, et al. BadGPT: Exploring Security \nVulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT[J]. \narXiv preprint arXiv:2304.12298, 2023.  \n[167] Li J, Yang Y, Wu Z, et al. Chatgpt as an attack tool: Stealthy textual \nbackdoor attack via blackbox generative model tr igger[J]. arXiv preprint \narXiv:2304.14475, 2023.  \n[168] Glaese A, McAleese N, Trębacz M, e t al. Improving alignment of'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 118, 'page_label': '119'}, page_content='backdoor attack via blackbox generative model tr igger[J]. arXiv preprint \narXiv:2304.14475, 2023.  \n[168] Glaese A, McAleese N, Trębacz M, e t al. Improving alignment of \ndialogue agents via targeted human judgements[J]. arXiv preprint \narXiv:2209.14375, 2022.  \n[169] Bai Y, Kadavath S, Kundu S, et al. Constitutional ai: Harmlessness \nfrom ai feedback[J]. arXiv preprint arXiv:2212.08073, 2022.  \n[170] Dai J, Pan X, Ji J, et al. PKU -Beaver: Constrained Value -Aligned'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 118, 'page_label': '119'}, page_content='from ai feedback[J]. arXiv preprint arXiv:2212.08073, 2022.  \n[170] Dai J, Pan X, Ji J, et al. PKU -Beaver: Constrained Value -Aligned \nLLM via Safe RLHF . GitHub repository. \nhttps://github.com/PKU -Alignment/safe -rlhf. 2023.  \n[171] Zheng R, Dou S, Gao S, et al. Secrets of RLHF in Large L anguage \nModels Part I: PPO[J]. arXiv preprint arXiv:2307.04964, 2023.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 119, 'page_label': '120'}, page_content="119 [172] Shevlane T, Farquhar S, Garfinkel B, et al. Model evaluation for \nextreme risks[J]. arXiv preprint arXiv:2305.15324, 2023.  \n[173] Pan A, Chan J S, Zou A, et al. Do the Rewards Justify the Means? \nMeasuring Trade -Offs Between Rewards and Ethical Behavior in the \nMACHIA VELLI Benchmark [C]//International Conference on Machine \nLearning. PMLR, 2023: 26837 -26867.  \n[174] K. Gresh ake, S. Abdelnabi, S. Mishra, et al. Not what you've signed"), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 119, 'page_label': '120'}, page_content="MACHIA VELLI Benchmark [C]//International Conference on Machine \nLearning. PMLR, 2023: 26837 -26867.  \n[174] K. Gresh ake, S. Abdelnabi, S. Mishra, et al. Not what you've signed \nup for: Compromising Rea l-World LLM -Integrated Applications with \nIndirect Prompt Injection. arXiv preprint arXiv:2302.12173, 2023.  \n[175] D. Bibhu, P. Sharma. “Are ChatGPT and deepfake algorithms \nendangering the cybersecurity industry? A review.” International Journal"), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 119, 'page_label': '120'}, page_content='[175] D. Bibhu, P. Sharma. “Are ChatGPT and deepfake algorithms \nendangering the cybersecurity industry? A review.” International Journal \nof Engineering and Applied Sciences, 10(1), 2023.'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 120, 'page_label': '121'}, page_content='120 编写人员贡献  \n白皮书的编写组成员包括： 陶建华（清华大学 ）、吴飞（浙江大\n学）、黄民烈（清华大学 ）、文继荣（中国人民大学 ）、王海峰（百度）、 \n刘知远（清华大学 ）、刘静（中国科学院自动化研究所 ）、杨小康（上\n海交通大学 ）、聂帅（启元实验室 ）。在撰写过程中，除 编写组成员外，\n还得到（以下按拼音序）车飞虎（清华大学 ）、甘磊磊（浙江大学 ）、\n郭龙腾（中国科学院自动化研究所 ）、马艳军（百度）、任瑞阳（中国\n人民大学 ）、汪华东（清华大学 ）、王永威（浙江大学 ）、吴蕾（百度）、\n赵鑫（中国人民大学 ）等人帮助。  \n其中：吴飞、王永威 、甘磊磊 参与了第一章、第二章、第八章的\n部分撰写和修订 ；刘知远、 汪华东参与了第二章的撰写和修订 ；刘静、\n郭龙腾参与了第三章的撰写和修订 ；文继荣、赵鑫、任瑞阳参与了第\n四章和第六章 的撰写和修订；马艳军、吴蕾 参与了第四章和 第五章的\n撰写和修订；黄民烈、邓佳文 参与了第七章的撰写修订 ；聂帅、车飞\n虎参与了第一章和 第六章的撰写修订 ；杨小康参与了第 三章的部分撰'), Document(metadata={'producer': 'Microsoft® Word 2021', 'creator': 'Microsoft® Word 2021', 'creationdate': '2023-09-21T09:52:06+08:00', 'author': 'Crystal', 'moddate': '2024-05-17T19:46:22+08:00', 'title': '宏观经济管理信息系统初步设计', 'source': './chroma/knowledge/中国人工智能系列白皮书.pdf', 'total_pages': 121, 'page': 120, 'page_label': '121'}, page_content='其中：吴飞、王永威 、甘磊磊 参与了第一章、第二章、第八章的\n部分撰写和修订 ；刘知远、 汪华东参与了第二章的撰写和修订 ；刘静、\n郭龙腾参与了第三章的撰写和修订 ；文继荣、赵鑫、任瑞阳参与了第\n四章和第六章 的撰写和修订；马艳军、吴蕾 参与了第四章和 第五章的\n撰写和修订；黄民烈、邓佳文 参与了第七章的撰写修订 ；聂帅、车飞\n虎参与了第一章和 第六章的撰写修订 ；杨小康参与了第 三章的部分撰\n写；陶建华负责 了白皮书的 框架设计、 整体撰写和修订工作。')]
2025-05-30 21:15:52 | INFO     | knowledge:create_indexes:138 - 文档索引结果为: {'num_added': 352, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}
2025-05-30 21:15:52 | INFO     | knowledge:load_knowledge:78 - 检索器详情: {'71eeedee21ca1f1bec56c3087d4cbfa7': EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)], weights=[0.5, 0.5]), '503dc7d31f89743234dc87e712078441': EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E35579D90>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E36E47390>)], weights=[0.5, 0.5])}
2025-05-30 21:15:52 | INFO     | knowledge:load_knowledge:63 - 文件路径: ./chroma/knowledge/人事管理流程.docx
2025-05-30 21:15:52 | INFO     | knowledge:load_knowledge:67 - 知识库名称: 71eeedee21ca1f1bec56c3087d4cbfa7
2025-05-30 21:15:52 | INFO     | knowledge:load_knowledge:68 - self.__retrievers: {'71eeedee21ca1f1bec56c3087d4cbfa7': EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)], weights=[0.5, 0.5]), '503dc7d31f89743234dc87e712078441': EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E35579D90>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E36E47390>)], weights=[0.5, 0.5])}
2025-05-30 21:16:09 | INFO     | __main__:llm_reply:32 - 用户查询问题:请假流程
2025-05-30 21:16:09 | INFO     | combine_client:get_chain:71 - collection: 人事管理流程.docx
2025-05-30 21:16:09 | INFO     | knowledge:get_retrievers:84 - 知识库名字md5: 71eeedee21ca1f1bec56c3087d4cbfa7
2025-05-30 21:16:09 | INFO     | knowledge:get_retrievers:90 - get_retrievers中: retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)] weights=[0.5, 0.5]
2025-05-30 21:16:09 | DEBUG    | knowledge:get_retrievers:109 - 最终检索器为: base_compressor=DashScopeRerank(client=<class 'dashscope.rerank.text_rerank.TextReRank'>, model='gte-rerank', top_n=3, dashscope_api_key='sk-2c8dde02cb904267975ff9f819aa3c3e') base_retriever=ContextualCompressionRetriever(base_compressor=LLMChainFilter(llm_chain=PromptTemplate(input_variables=['context', 'question'], input_types={}, output_parser=BooleanOutputParser(), partial_variables={}, template="Given the following question and context, return YES if the context is relevant to the question and NO if it isn't.\n\n> Question: {question}\n> Context:\n>>>\n{context}\n>>>\n> Relevant (YES / NO):")
| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
| BooleanOutputParser(), get_input=<function default_get_input at 0x0000025E0CF9E340>), base_retriever=RePhraseQueryRetriever(retriever=EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)], weights=[0.5, 0.5]), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an assistant tasked with taking a natural language query from a user and converting it into a query for a vectorstore. In this process, you strip out information that is not relevant for the retrieval task. Here is the user query: {question}')
| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
| StrOutputParser()))
2025-05-30 21:16:09 | DEBUG    | combine_client:get_chain:74 - [人事管理流程.docx]检索器为: base_compressor=DashScopeRerank(client=<class 'dashscope.rerank.text_rerank.TextReRank'>, model='gte-rerank', top_n=3, dashscope_api_key='sk-2c8dde02cb904267975ff9f819aa3c3e') base_retriever=ContextualCompressionRetriever(base_compressor=LLMChainFilter(llm_chain=PromptTemplate(input_variables=['context', 'question'], input_types={}, output_parser=BooleanOutputParser(), partial_variables={}, template="Given the following question and context, return YES if the context is relevant to the question and NO if it isn't.\n\n> Question: {question}\n> Context:\n>>>\n{context}\n>>>\n> Relevant (YES / NO):")
| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
| BooleanOutputParser(), get_input=<function default_get_input at 0x0000025E0CF9E340>), base_retriever=RePhraseQueryRetriever(retriever=EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)], weights=[0.5, 0.5]), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an assistant tasked with taking a natural language query from a user and converting it into a query for a vectorstore. In this process, you strip out information that is not relevant for the retrieval task. Here is the user query: {question}')
| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
| StrOutputParser()))
2025-05-30 21:16:09 | INFO     | combine_client:get_chain:77 - len: []####:0
2025-05-30 21:16:09 | INFO     | combine_client:get_chain:89 - 产生一个RAG链......
2025-05-30 21:16:09 | DEBUG    | combine_client:get_chain:90 - rag_chain: bound=RunnableAssign(mapper={
  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])
           | ContextualCompressionRetriever(base_compressor=DashScopeRerank(client=<class 'dashscope.rerank.text_rerank.TextReRank'>, model='gte-rerank', top_n=3, dashscope_api_key='sk-2c8dde02cb904267975ff9f819aa3c3e'), base_retriever=ContextualCompressionRetriever(base_compressor=LLMChainFilter(llm_chain=PromptTemplate(input_variables=['context', 'question'], input_types={}, output_parser=BooleanOutputParser(), partial_variables={}, template="Given the following question and context, return YES if the context is relevant to the question and NO if it isn't.\n\n> Question: {question}\n> Context:\n>>>\n{context}\n>>>\n> Relevant (YES / NO):")
             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
             | BooleanOutputParser(), get_input=<function default_get_input at 0x0000025E0CF9E340>), base_retriever=RePhraseQueryRetriever(retriever=EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)], weights=[0.5, 0.5]), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an assistant tasked with taking a natural language query from a user and converting it into a query for a vectorstore. In this process, you strip out information that is not relevant for the retrieval task. Here is the user query: {question}')
             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
             | StrOutputParser()))), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])
})
| RunnableAssign(mapper={
    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={
              context: RunnableLambda(format_docs)
            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])
            | ChatPromptTemplate(input_variables=['context', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000025E0A0D4540>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='你是一名知识问答助手，\n              你将使用检索到的上下文来回答问题。如果你不知道答案，就说你没有找到答案。 "\n              "\n\n"\n              "{context}" \n        '), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])
            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E355E2350>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0F2A1E10>, root_client=<openai.OpenAI object at 0x0000025E354E8DD0>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E32851E90>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=4000)
            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])
  }) kwargs={} config={'run_name': 'retrieval_chain'} config_factories=[]
2025-05-30 21:16:09 | DEBUG    | combine_client:get_chain:107 - 当前的处理链: bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={
  chat_history: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])
}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])
| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function CombineClient.get_chain.<locals>.<lambda> at 0x0000025E0F26BF60> input_messages_key='input' output_messages_key='answer' history_messages_key='chat_history' history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]
2025-05-30 21:16:09 | DEBUG    | __main__:llm_reply:36 - chat_history:[['请假流程', '']]
2025-05-30 21:16:09 | DEBUG    | __main__:llm_reply:40 - chunk:{'input': '请假流程', 'chat_history': []}
2025-05-30 21:16:15 | DEBUG    | __main__:llm_reply:40 - chunk:{'context': [Document(metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5987425805382741}, page_content='3.3 旷工处罚：旷工当日工资不计薪另处以当日工资双倍的罚款。\n\n3.4 自动离职：员工未按公司离职流程办理离职手续且未做工作交接者，视为自动离职。自动离职员工，公司有权扣发一个月工资，并记入员工个人档案。\n\n第七条 加班\n\n公司不支持加班，因特殊原因公司安排需要加班的，请在系统提交申请审批。\n\n请假规定与类别\n\n1、请假审批流程：\n\n1.1普通员工申请请假/加班/调休：由直属领导、事业部总监、人事行政主管审批。抄送考勤组、请假部门、人事行政经理；\n\n1.2 主管及以上人员申请请假/调休/请假≥3天：由直属领导、事业部总监、人事行政经理、总经理审批。抄送考勤组、请假部门、人事行政主管、股东会成员；\n\n1.3原则上所有请假/加班/调休必须在钉钉系统进行申请并批准后方可执行；因紧急特殊原因请假/调休，可以电话获得部门经理同意后24小时内申请，逾期未申请相关审批人员可不予准假，否则视为旷工。\n\n1.4常规请假需提前1个工作日在钉钉系统进行申请，请假3天及以上人员需提前3天申请，并注明请假时间、类型、事由，未按要求提前申请可不予准假，请假审批通过后方可休假，否则按旷工处理；\n\n2、请假规定'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5218398908498185}, page_content='2.4无特殊情况，法定节假日前后不得连续请假，特殊情况需请假的，请假前请做好工作交接，请假期间请保持手机畅通，以便公司及时了解请假员工状况和对接相关工作事宜。\n\n3、请假类别\n\n3.1法定假节日：元旦1天、春节3天、清明节1天、劳动节1天、端午节1天、中秋节1天、国庆节3天\n\n注：如遇国家对法定节假日的休假有最新的调整，按照最新国家规定执行。\n\n3.2事假：无薪\n\n3.2.1 员工遇有个人事务可在不妨碍正常工作的前提下申请事假；\n\n3.2.2 事假全年累计一般不得超过 15天，一次不得超过3天，特殊情况请假一般不得大于5天；\n\n3.2.3 试用期员工请事假，原则上不允许超过3个工作日，用人部门可酌情考虑是否继续留用；\n\n3.3病假：\n\n3.3.1病假单次2天以内提供医院门诊证明，单次2天以上提供三级甲等医院门诊及相关检查证明材料，住院的需提供住院及出院相关证明材料，同时通过钉钉系统办理请假手续；若无相关证明或证明不符合要求的按照事假计算；\n\n3.3.2 工资支付标准：病假期间按长沙市最低工资标准的80%计发；'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5074504869649954}, page_content='1.3原则上所有请假/加班/调休必须在钉钉系统进行申请并批准后方可执行；因紧急特殊原因请假/调休，可以电话获得部门经理同意后24小时内申请，逾期未申请相关审批人员可不予准假，否则视为旷工。\n\n1.4常规请假需提前1个工作日在钉钉系统进行申请，请假3天及以上人员需提前3天申请，并注明请假时间、类型、事由，未按要求提前申请可不予准假，请假审批通过后方可休假，否则按旷工处理；\n\n2、请假规定\n\n2.1最小请假单位为1小时，不足1小时按1小时计算。\n\n2.2如请假提前结束的，需到行政人事行政部办理销假手续，否则假期时间按请假审批所填期限计算；\n\n2.3请假期间如需续假，须在假期到期日前1个工作日在钉钉系统申请，经批准后方可续假；\n\n2.4无特殊情况，法定节假日前后不得连续请假，特殊情况需请假的，请假前请做好工作交接，请假期间请保持手机畅通，以便公司及时了解请假员工状况和对接相关工作事宜。\n\n3、请假类别\n\n3.1法定假节日：元旦1天、春节3天、清明节1天、劳动节1天、端午节1天、中秋节1天、国庆节3天\n\n注：如遇国家对法定节假日的休假有最新的调整，按照最新国家规定执行。\n\n3.2事假：无薪')]}
2025-05-30 21:16:15 | DEBUG    | __main__:llm_reply:44 - doc:page_content='3.3 旷工处罚：旷工当日工资不计薪另处以当日工资双倍的罚款。

3.4 自动离职：员工未按公司离职流程办理离职手续且未做工作交接者，视为自动离职。自动离职员工，公司有权扣发一个月工资，并记入员工个人档案。

第七条 加班

公司不支持加班，因特殊原因公司安排需要加班的，请在系统提交申请审批。

请假规定与类别

1、请假审批流程：

1.1普通员工申请请假/加班/调休：由直属领导、事业部总监、人事行政主管审批。抄送考勤组、请假部门、人事行政经理；

1.2 主管及以上人员申请请假/调休/请假≥3天：由直属领导、事业部总监、人事行政经理、总经理审批。抄送考勤组、请假部门、人事行政主管、股东会成员；

1.3原则上所有请假/加班/调休必须在钉钉系统进行申请并批准后方可执行；因紧急特殊原因请假/调休，可以电话获得部门经理同意后24小时内申请，逾期未申请相关审批人员可不予准假，否则视为旷工。

1.4常规请假需提前1个工作日在钉钉系统进行申请，请假3天及以上人员需提前3天申请，并注明请假时间、类型、事由，未按要求提前申请可不予准假，请假审批通过后方可休假，否则按旷工处理；

2、请假规定' metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5987425805382741}
2025-05-30 21:16:15 | DEBUG    | __main__:llm_reply:44 - doc:page_content='2.4无特殊情况，法定节假日前后不得连续请假，特殊情况需请假的，请假前请做好工作交接，请假期间请保持手机畅通，以便公司及时了解请假员工状况和对接相关工作事宜。

3、请假类别

3.1法定假节日：元旦1天、春节3天、清明节1天、劳动节1天、端午节1天、中秋节1天、国庆节3天

注：如遇国家对法定节假日的休假有最新的调整，按照最新国家规定执行。

3.2事假：无薪

3.2.1 员工遇有个人事务可在不妨碍正常工作的前提下申请事假；

3.2.2 事假全年累计一般不得超过 15天，一次不得超过3天，特殊情况请假一般不得大于5天；

3.2.3 试用期员工请事假，原则上不允许超过3个工作日，用人部门可酌情考虑是否继续留用；

3.3病假：

3.3.1病假单次2天以内提供医院门诊证明，单次2天以上提供三级甲等医院门诊及相关检查证明材料，住院的需提供住院及出院相关证明材料，同时通过钉钉系统办理请假手续；若无相关证明或证明不符合要求的按照事假计算；

3.3.2 工资支付标准：病假期间按长沙市最低工资标准的80%计发；' metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5218398908498185}
2025-05-30 21:16:15 | DEBUG    | __main__:llm_reply:44 - doc:page_content='1.3原则上所有请假/加班/调休必须在钉钉系统进行申请并批准后方可执行；因紧急特殊原因请假/调休，可以电话获得部门经理同意后24小时内申请，逾期未申请相关审批人员可不予准假，否则视为旷工。

1.4常规请假需提前1个工作日在钉钉系统进行申请，请假3天及以上人员需提前3天申请，并注明请假时间、类型、事由，未按要求提前申请可不予准假，请假审批通过后方可休假，否则按旷工处理；

2、请假规定

2.1最小请假单位为1小时，不足1小时按1小时计算。

2.2如请假提前结束的，需到行政人事行政部办理销假手续，否则假期时间按请假审批所填期限计算；

2.3请假期间如需续假，须在假期到期日前1个工作日在钉钉系统申请，经批准后方可续假；

2.4无特殊情况，法定节假日前后不得连续请假，特殊情况需请假的，请假前请做好工作交接，请假期间请保持手机畅通，以便公司及时了解请假员工状况和对接相关工作事宜。

3、请假类别

3.1法定假节日：元旦1天、春节3天、清明节1天、劳动节1天、端午节1天、中秋节1天、国庆节3天

注：如遇国家对法定节假日的休假有最新的调整，按照最新国家规定执行。

3.2事假：无薪' metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5074504869649954}
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': ''}
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:48 - chunk_content:
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '根据'}
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:48 - chunk_content:根据
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '提供的'}
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:48 - chunk_content:提供的
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '信息'}
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:48 - chunk_content:信息
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '，公司的请假流程如下'}
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:48 - chunk_content:，公司的请假流程如下
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '：\n\n1. '}
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:48 - chunk_content:：

1. 
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '请假审批流程：\n'}
2025-05-30 21:16:16 | DEBUG    | __main__:llm_reply:48 - chunk_content:请假审批流程：

2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '   - 普通'}
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:48 - chunk_content:   - 普通
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '员工申请请假/加班/'}
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:48 - chunk_content:员工申请请假/加班/
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '调休：需要'}
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:48 - chunk_content:调休：需要
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '由直属领导、'}
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:48 - chunk_content:由直属领导、
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '事业部总监、人事行政主管'}
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:48 - chunk_content:事业部总监、人事行政主管
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '审批，并抄送考'}
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:48 - chunk_content:审批，并抄送考
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '勤组、请假部门、'}
2025-05-30 21:16:17 | DEBUG    | __main__:llm_reply:48 - chunk_content:勤组、请假部门、
2025-05-30 21:16:18 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '人事行政经理。\n   -'}
2025-05-30 21:16:18 | DEBUG    | __main__:llm_reply:48 - chunk_content:人事行政经理。
   -
2025-05-30 21:16:18 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': ' 主管及以上人员申请请假'}
2025-05-30 21:16:18 | DEBUG    | __main__:llm_reply:48 - chunk_content: 主管及以上人员申请请假
2025-05-30 21:16:18 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '/调休或'}
2025-05-30 21:16:18 | DEBUG    | __main__:llm_reply:48 - chunk_content:/调休或
2025-05-30 21:16:18 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '请假≥3天：需要'}
2025-05-30 21:16:18 | DEBUG    | __main__:llm_reply:48 - chunk_content:请假≥3天：需要
2025-05-30 21:16:18 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '由直属领导、事业部总监'}
2025-05-30 21:16:18 | DEBUG    | __main__:llm_reply:48 - chunk_content:由直属领导、事业部总监
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '、人事行政经理、总经理'}
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:48 - chunk_content:、人事行政经理、总经理
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '审批，并抄送考勤'}
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:48 - chunk_content:审批，并抄送考勤
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '组、请假部门、人事'}
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:48 - chunk_content:组、请假部门、人事
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '行政主管、股东会成员'}
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:48 - chunk_content:行政主管、股东会成员
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '。\n\n2. 所有'}
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:48 - chunk_content:。

2. 所有
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '请假/加班/调休'}
2025-05-30 21:16:19 | DEBUG    | __main__:llm_reply:48 - chunk_content:请假/加班/调休
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '原则上必须在钉'}
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:48 - chunk_content:原则上必须在钉
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '钉系统进行申请并获得'}
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:48 - chunk_content:钉系统进行申请并获得
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '批准后方可执行。因'}
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:48 - chunk_content:批准后方可执行。因
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '紧急特殊原因请假/调'}
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:48 - chunk_content:紧急特殊原因请假/调
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '休，可以先'}
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:48 - chunk_content:休，可以先
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '电话获得部门经理同意，'}
2025-05-30 21:16:20 | DEBUG    | __main__:llm_reply:48 - chunk_content:电话获得部门经理同意，
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '但必须在2'}
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:48 - chunk_content:但必须在2
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '4小时内补交'}
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:48 - chunk_content:4小时内补交
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '申请，否则相关'}
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:48 - chunk_content:申请，否则相关
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '审批人员可不予准假'}
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:48 - chunk_content:审批人员可不予准假
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '，且视为旷工'}
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:48 - chunk_content:，且视为旷工
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '。\n\n3. 常'}
2025-05-30 21:16:21 | DEBUG    | __main__:llm_reply:48 - chunk_content:。

3. 常
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '规请假需提前1个工作'}
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:48 - chunk_content:规请假需提前1个工作
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '日在钉钉系统进行申请'}
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:48 - chunk_content:日在钉钉系统进行申请
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '。请假3天'}
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:48 - chunk_content:。请假3天
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '及以上的人员需'}
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:48 - chunk_content:及以上的人员需
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '提前3天申请，并注明'}
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:48 - chunk_content:提前3天申请，并注明
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '请假时间、类型、事'}
2025-05-30 21:16:22 | DEBUG    | __main__:llm_reply:48 - chunk_content:请假时间、类型、事
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '由。未按要求提前'}
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:48 - chunk_content:由。未按要求提前
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '申请的，审批'}
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:48 - chunk_content:申请的，审批
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '人员可不予准'}
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:48 - chunk_content:人员可不予准
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '假，请假审批通过'}
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:48 - chunk_content:假，请假审批通过
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '后方可休假，'}
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:48 - chunk_content:后方可休假，
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '否则按旷工处理。\n\n'}
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:48 - chunk_content:否则按旷工处理。


2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '4. 最小请假单位'}
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:48 - chunk_content:4. 最小请假单位
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '为1小时，不足1'}
2025-05-30 21:16:23 | DEBUG    | __main__:llm_reply:48 - chunk_content:为1小时，不足1
2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '小时按1小时计算。\n\n'}
2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:48 - chunk_content:小时按1小时计算。


2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '5. 如请假提前结束'}
2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:48 - chunk_content:5. 如请假提前结束
2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '，需到行政'}
2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:48 - chunk_content:，需到行政
2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '人事行政部办理销假'}
2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:48 - chunk_content:人事行政部办理销假
2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '手续，否则假期时间按'}
2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:48 - chunk_content:手续，否则假期时间按
2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '请假审批所填期限计算'}
2025-05-30 21:16:24 | DEBUG    | __main__:llm_reply:48 - chunk_content:请假审批所填期限计算
2025-05-30 21:16:25 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '。\n\n6. 请假期间'}
2025-05-30 21:16:25 | DEBUG    | __main__:llm_reply:48 - chunk_content:。

6. 请假期间
2025-05-30 21:16:25 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '如需续假，须'}
2025-05-30 21:16:25 | DEBUG    | __main__:llm_reply:48 - chunk_content:如需续假，须
2025-05-30 21:16:25 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '在假期到期日前1个工作'}
2025-05-30 21:16:25 | DEBUG    | __main__:llm_reply:48 - chunk_content:在假期到期日前1个工作
2025-05-30 21:16:25 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '日在钉钉系统申请，'}
2025-05-30 21:16:25 | DEBUG    | __main__:llm_reply:48 - chunk_content:日在钉钉系统申请，
2025-05-30 21:16:25 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '经批准后方可续假'}
2025-05-30 21:16:25 | DEBUG    | __main__:llm_reply:48 - chunk_content:经批准后方可续假
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '。\n\n7. '}
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:48 - chunk_content:。

7. 
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '法定节假日前后不得连续'}
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:48 - chunk_content:法定节假日前后不得连续
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '请假，除非有'}
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:48 - chunk_content:请假，除非有
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '特殊情况，并且请假前需要'}
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:48 - chunk_content:特殊情况，并且请假前需要
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '做好工作交接，请'}
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:48 - chunk_content:做好工作交接，请
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '假期间保持手机畅通以便'}
2025-05-30 21:16:26 | DEBUG    | __main__:llm_reply:48 - chunk_content:假期间保持手机畅通以便
2025-05-30 21:16:27 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '公司及时了解状况'}
2025-05-30 21:16:27 | DEBUG    | __main__:llm_reply:48 - chunk_content:公司及时了解状况
2025-05-30 21:16:27 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '和对接工作事宜。'}
2025-05-30 21:16:27 | DEBUG    | __main__:llm_reply:48 - chunk_content:和对接工作事宜。
2025-05-30 21:16:27 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': ''}
2025-05-30 21:16:27 | DEBUG    | __main__:llm_reply:48 - chunk_content:
2025-05-30 21:16:27 | DEBUG    | __main__:llm_reply:53 - chat_history:[['请假流程', '根据提供的信息，公司的请假流程如下：\n\n1. 请假审批流程：\n   - 普通员工申请请假/加班/调休：需要由直属领导、事业部总监、人事行政主管审批，并抄送考勤组、请假部门、人事行政经理。\n   - 主管及以上人员申请请假/调休或请假≥3天：需要由直属领导、事业部总监、人事行政经理、总经理审批，并抄送考勤组、请假部门、人事行政主管、股东会成员。\n\n2. 所有请假/加班/调休原则上必须在钉钉系统进行申请并获得批准后方可执行。因紧急特殊原因请假/调休，可以先电话获得部门经理同意，但必须在24小时内补交申请，否则相关审批人员可不予准假，且视为旷工。\n\n3. 常规请假需提前1个工作日在钉钉系统进行申请。请假3天及以上的人员需提前3天申请，并注明请假时间、类型、事由。未按要求提前申请的，审批人员可不予准假，请假审批通过后方可休假，否则按旷工处理。\n\n4. 最小请假单位为1小时，不足1小时按1小时计算。\n\n5. 如请假提前结束，需到行政人事行政部办理销假手续，否则假期时间按请假审批所填期限计算。\n\n6. 请假期间如需续假，须在假期到期日前1个工作日在钉钉系统申请，经批准后方可续假。\n\n7. 法定节假日前后不得连续请假，除非有特殊情况，并且请假前需要做好工作交接，请假期间保持手机畅通以便公司及时了解状况和对接工作事宜。']]
2025-05-30 21:23:40 | INFO     | __main__:llm_reply:32 - 用户查询问题:请假流程
2025-05-30 21:23:40 | INFO     | combine_client:get_chain:71 - collection: 人事管理流程.docx
2025-05-30 21:23:40 | INFO     | knowledge:get_retrievers:84 - 知识库名字md5: 71eeedee21ca1f1bec56c3087d4cbfa7
2025-05-30 21:23:40 | INFO     | knowledge:get_retrievers:90 - get_retrievers中: retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)] weights=[0.5, 0.5]
2025-05-30 21:23:40 | DEBUG    | knowledge:get_retrievers:109 - 最终检索器为: base_compressor=DashScopeRerank(client=<class 'dashscope.rerank.text_rerank.TextReRank'>, model='gte-rerank', top_n=3, dashscope_api_key='sk-2c8dde02cb904267975ff9f819aa3c3e') base_retriever=ContextualCompressionRetriever(base_compressor=LLMChainFilter(llm_chain=PromptTemplate(input_variables=['context', 'question'], input_types={}, output_parser=BooleanOutputParser(), partial_variables={}, template="Given the following question and context, return YES if the context is relevant to the question and NO if it isn't.\n\n> Question: {question}\n> Context:\n>>>\n{context}\n>>>\n> Relevant (YES / NO):")
| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
| BooleanOutputParser(), get_input=<function default_get_input at 0x0000025E0CF9E340>), base_retriever=RePhraseQueryRetriever(retriever=EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)], weights=[0.5, 0.5]), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an assistant tasked with taking a natural language query from a user and converting it into a query for a vectorstore. In this process, you strip out information that is not relevant for the retrieval task. Here is the user query: {question}')
| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
| StrOutputParser()))
2025-05-30 21:23:40 | DEBUG    | combine_client:get_chain:74 - [人事管理流程.docx]检索器为: base_compressor=DashScopeRerank(client=<class 'dashscope.rerank.text_rerank.TextReRank'>, model='gte-rerank', top_n=3, dashscope_api_key='sk-2c8dde02cb904267975ff9f819aa3c3e') base_retriever=ContextualCompressionRetriever(base_compressor=LLMChainFilter(llm_chain=PromptTemplate(input_variables=['context', 'question'], input_types={}, output_parser=BooleanOutputParser(), partial_variables={}, template="Given the following question and context, return YES if the context is relevant to the question and NO if it isn't.\n\n> Question: {question}\n> Context:\n>>>\n{context}\n>>>\n> Relevant (YES / NO):")
| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
| BooleanOutputParser(), get_input=<function default_get_input at 0x0000025E0CF9E340>), base_retriever=RePhraseQueryRetriever(retriever=EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)], weights=[0.5, 0.5]), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an assistant tasked with taking a natural language query from a user and converting it into a query for a vectorstore. In this process, you strip out information that is not relevant for the retrieval task. Here is the user query: {question}')
| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
| StrOutputParser()))
2025-05-30 21:23:40 | INFO     | combine_client:get_chain:77 - len: [HumanMessage(content='请假流程', additional_kwargs={}, response_metadata={}), AIMessage(content='根据提供的信息，公司的请假流程如下：\n\n1. 请假审批流程：\n   - 普通员工申请请假/加班/调休：需要由直属领导、事业部总监、人事行政主管审批，并抄送考勤组、请假部门、人事行政经理。\n   - 主管及以上人员申请请假/调休或请假≥3天：需要由直属领导、事业部总监、人事行政经理、总经理审批，并抄送考勤组、请假部门、人事行政主管、股东会成员。\n\n2. 所有请假/加班/调休原则上必须在钉钉系统进行申请并获得批准后方可执行。因紧急特殊原因请假/调休，可以先电话获得部门经理同意，但必须在24小时内补交申请，否则相关审批人员可不予准假，且视为旷工。\n\n3. 常规请假需提前1个工作日在钉钉系统进行申请。请假3天及以上的人员需提前3天申请，并注明请假时间、类型、事由。未按要求提前申请的，审批人员可不予准假，请假审批通过后方可休假，否则按旷工处理。\n\n4. 最小请假单位为1小时，不足1小时按1小时计算。\n\n5. 如请假提前结束，需到行政人事行政部办理销假手续，否则假期时间按请假审批所填期限计算。\n\n6. 请假期间如需续假，须在假期到期日前1个工作日在钉钉系统申请，经批准后方可续假。\n\n7. 法定节假日前后不得连续请假，除非有特殊情况，并且请假前需要做好工作交接，请假期间保持手机畅通以便公司及时了解状况和对接工作事宜。', additional_kwargs={}, response_metadata={})]####:2
2025-05-30 21:23:41 | INFO     | combine_client:get_chain:89 - 产生一个RAG链......
2025-05-30 21:23:41 | DEBUG    | combine_client:get_chain:90 - rag_chain: bound=RunnableAssign(mapper={
  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])
           | ContextualCompressionRetriever(base_compressor=DashScopeRerank(client=<class 'dashscope.rerank.text_rerank.TextReRank'>, model='gte-rerank', top_n=3, dashscope_api_key='sk-2c8dde02cb904267975ff9f819aa3c3e'), base_retriever=ContextualCompressionRetriever(base_compressor=LLMChainFilter(llm_chain=PromptTemplate(input_variables=['context', 'question'], input_types={}, output_parser=BooleanOutputParser(), partial_variables={}, template="Given the following question and context, return YES if the context is relevant to the question and NO if it isn't.\n\n> Question: {question}\n> Context:\n>>>\n{context}\n>>>\n> Relevant (YES / NO):")
             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
             | BooleanOutputParser(), get_input=<function default_get_input at 0x0000025E0CF9E340>), base_retriever=RePhraseQueryRetriever(retriever=EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'DashScopeEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x0000025E0D233490>, search_kwargs={'k': 3}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x0000025E3407FE10>)], weights=[0.5, 0.5]), llm_chain=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='You are an assistant tasked with taking a natural language query from a user and converting it into a query for a vectorstore. In this process, you strip out information that is not relevant for the retrieval task. Here is the user query: {question}')
             | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E0F24DF50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E0D01C5D0>, root_client=<openai.OpenAI object at 0x0000025E0A506890>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E0F24E0D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=8000)
             | StrOutputParser()))), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])
})
| RunnableAssign(mapper={
    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={
              context: RunnableLambda(format_docs)
            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])
            | ChatPromptTemplate(input_variables=['context', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000025E0A0D4540>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='你是一名知识问答助手，\n              你将使用检索到的上下文来回答问题。如果你不知道答案，就说你没有找到答案。 "\n              "\n\n"\n              "{context}" \n        '), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])
            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000025E35576410>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000025E38351E10>, root_client=<openai.OpenAI object at 0x0000025E38358B90>, root_async_client=<openai.AsyncOpenAI object at 0x0000025E383590D0>, model_name='qwen-max-latest', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://dashscope.aliyuncs.com/compatible-mode/v1', max_tokens=4000)
            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])
  }) kwargs={} config={'run_name': 'retrieval_chain'} config_factories=[]
2025-05-30 21:23:41 | DEBUG    | combine_client:get_chain:107 - 当前的处理链: bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={
  chat_history: RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])
}), kwargs={}, config={'run_name': 'insert_history'}, config_factories=[])
| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function CombineClient.get_chain.<locals>.<lambda> at 0x0000025E383A0860> input_messages_key='input' output_messages_key='answer' history_messages_key='chat_history' history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]
2025-05-30 21:23:41 | DEBUG    | __main__:llm_reply:36 - chat_history:[['请假流程', '根据提供的信息，公司的请假流程如下：\n\n1. 请假审批流程：\n   - 普通员工申请请假/加班/调休：需要由直属领导、事业部总监、人事行政主管审批，并抄送考勤组、请假部门、人事行政经理。\n   - 主管及以上人员申请请假/调休或请假≥3天：需要由直属领导、事业部总监、人事行政经理、总经理审批，并抄送考勤组、请假部门、人事行政主管、股东会成员。\n\n2. 所有请假/加班/调休原则上必须在钉钉系统进行申请并获得批准后方可执行。因紧急特殊原因请假/调休，可以先电话获得部门经理同意，但必须在24小时内补交申请，否则相关审批人员可不予准假，且视为旷工。\n\n3. 常规请假需提前1个工作日在钉钉系统进行申请。请假3天及以上的人员需提前3天申请，并注明请假时间、类型、事由。未按要求提前申请的，审批人员可不予准假，请假审批通过后方可休假，否则按旷工处理。\n\n4. 最小请假单位为1小时，不足1小时按1小时计算。\n\n5. 如请假提前结束，需到行政人事行政部办理销假手续，否则假期时间按请假审批所填期限计算。\n\n6. 请假期间如需续假，须在假期到期日前1个工作日在钉钉系统申请，经批准后方可续假。\n\n7. 法定节假日前后不得连续请假，除非有特殊情况，并且请假前需要做好工作交接，请假期间保持手机畅通以便公司及时了解状况和对接工作事宜。'], ['请假流程', '']]
2025-05-30 21:23:41 | DEBUG    | __main__:llm_reply:40 - chunk:{'input': '请假流程', 'chat_history': [HumanMessage(content='请假流程', additional_kwargs={}, response_metadata={}), AIMessage(content='根据提供的信息，公司的请假流程如下：\n\n1. 请假审批流程：\n   - 普通员工申请请假/加班/调休：需要由直属领导、事业部总监、人事行政主管审批，并抄送考勤组、请假部门、人事行政经理。\n   - 主管及以上人员申请请假/调休或请假≥3天：需要由直属领导、事业部总监、人事行政经理、总经理审批，并抄送考勤组、请假部门、人事行政主管、股东会成员。\n\n2. 所有请假/加班/调休原则上必须在钉钉系统进行申请并获得批准后方可执行。因紧急特殊原因请假/调休，可以先电话获得部门经理同意，但必须在24小时内补交申请，否则相关审批人员可不予准假，且视为旷工。\n\n3. 常规请假需提前1个工作日在钉钉系统进行申请。请假3天及以上的人员需提前3天申请，并注明请假时间、类型、事由。未按要求提前申请的，审批人员可不予准假，请假审批通过后方可休假，否则按旷工处理。\n\n4. 最小请假单位为1小时，不足1小时按1小时计算。\n\n5. 如请假提前结束，需到行政人事行政部办理销假手续，否则假期时间按请假审批所填期限计算。\n\n6. 请假期间如需续假，须在假期到期日前1个工作日在钉钉系统申请，经批准后方可续假。\n\n7. 法定节假日前后不得连续请假，除非有特殊情况，并且请假前需要做好工作交接，请假期间保持手机畅通以便公司及时了解状况和对接工作事宜。', additional_kwargs={}, response_metadata={})]}
2025-05-30 21:23:56 | DEBUG    | __main__:llm_reply:40 - chunk:{'context': [Document(metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5987425805382741}, page_content='3.3 旷工处罚：旷工当日工资不计薪另处以当日工资双倍的罚款。\n\n3.4 自动离职：员工未按公司离职流程办理离职手续且未做工作交接者，视为自动离职。自动离职员工，公司有权扣发一个月工资，并记入员工个人档案。\n\n第七条 加班\n\n公司不支持加班，因特殊原因公司安排需要加班的，请在系统提交申请审批。\n\n请假规定与类别\n\n1、请假审批流程：\n\n1.1普通员工申请请假/加班/调休：由直属领导、事业部总监、人事行政主管审批。抄送考勤组、请假部门、人事行政经理；\n\n1.2 主管及以上人员申请请假/调休/请假≥3天：由直属领导、事业部总监、人事行政经理、总经理审批。抄送考勤组、请假部门、人事行政主管、股东会成员；\n\n1.3原则上所有请假/加班/调休必须在钉钉系统进行申请并批准后方可执行；因紧急特殊原因请假/调休，可以电话获得部门经理同意后24小时内申请，逾期未申请相关审批人员可不予准假，否则视为旷工。\n\n1.4常规请假需提前1个工作日在钉钉系统进行申请，请假3天及以上人员需提前3天申请，并注明请假时间、类型、事由，未按要求提前申请可不予准假，请假审批通过后方可休假，否则按旷工处理；\n\n2、请假规定'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5218398908498185}, page_content='2.4无特殊情况，法定节假日前后不得连续请假，特殊情况需请假的，请假前请做好工作交接，请假期间请保持手机畅通，以便公司及时了解请假员工状况和对接相关工作事宜。\n\n3、请假类别\n\n3.1法定假节日：元旦1天、春节3天、清明节1天、劳动节1天、端午节1天、中秋节1天、国庆节3天\n\n注：如遇国家对法定节假日的休假有最新的调整，按照最新国家规定执行。\n\n3.2事假：无薪\n\n3.2.1 员工遇有个人事务可在不妨碍正常工作的前提下申请事假；\n\n3.2.2 事假全年累计一般不得超过 15天，一次不得超过3天，特殊情况请假一般不得大于5天；\n\n3.2.3 试用期员工请事假，原则上不允许超过3个工作日，用人部门可酌情考虑是否继续留用；\n\n3.3病假：\n\n3.3.1病假单次2天以内提供医院门诊证明，单次2天以上提供三级甲等医院门诊及相关检查证明材料，住院的需提供住院及出院相关证明材料，同时通过钉钉系统办理请假手续；若无相关证明或证明不符合要求的按照事假计算；\n\n3.3.2 工资支付标准：病假期间按长沙市最低工资标准的80%计发；'), Document(metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5074504869649954}, page_content='1.3原则上所有请假/加班/调休必须在钉钉系统进行申请并批准后方可执行；因紧急特殊原因请假/调休，可以电话获得部门经理同意后24小时内申请，逾期未申请相关审批人员可不予准假，否则视为旷工。\n\n1.4常规请假需提前1个工作日在钉钉系统进行申请，请假3天及以上人员需提前3天申请，并注明请假时间、类型、事由，未按要求提前申请可不予准假，请假审批通过后方可休假，否则按旷工处理；\n\n2、请假规定\n\n2.1最小请假单位为1小时，不足1小时按1小时计算。\n\n2.2如请假提前结束的，需到行政人事行政部办理销假手续，否则假期时间按请假审批所填期限计算；\n\n2.3请假期间如需续假，须在假期到期日前1个工作日在钉钉系统申请，经批准后方可续假；\n\n2.4无特殊情况，法定节假日前后不得连续请假，特殊情况需请假的，请假前请做好工作交接，请假期间请保持手机畅通，以便公司及时了解请假员工状况和对接相关工作事宜。\n\n3、请假类别\n\n3.1法定假节日：元旦1天、春节3天、清明节1天、劳动节1天、端午节1天、中秋节1天、国庆节3天\n\n注：如遇国家对法定节假日的休假有最新的调整，按照最新国家规定执行。\n\n3.2事假：无薪')]}
2025-05-30 21:23:56 | DEBUG    | __main__:llm_reply:44 - doc:page_content='3.3 旷工处罚：旷工当日工资不计薪另处以当日工资双倍的罚款。

3.4 自动离职：员工未按公司离职流程办理离职手续且未做工作交接者，视为自动离职。自动离职员工，公司有权扣发一个月工资，并记入员工个人档案。

第七条 加班

公司不支持加班，因特殊原因公司安排需要加班的，请在系统提交申请审批。

请假规定与类别

1、请假审批流程：

1.1普通员工申请请假/加班/调休：由直属领导、事业部总监、人事行政主管审批。抄送考勤组、请假部门、人事行政经理；

1.2 主管及以上人员申请请假/调休/请假≥3天：由直属领导、事业部总监、人事行政经理、总经理审批。抄送考勤组、请假部门、人事行政主管、股东会成员；

1.3原则上所有请假/加班/调休必须在钉钉系统进行申请并批准后方可执行；因紧急特殊原因请假/调休，可以电话获得部门经理同意后24小时内申请，逾期未申请相关审批人员可不予准假，否则视为旷工。

1.4常规请假需提前1个工作日在钉钉系统进行申请，请假3天及以上人员需提前3天申请，并注明请假时间、类型、事由，未按要求提前申请可不予准假，请假审批通过后方可休假，否则按旷工处理；

2、请假规定' metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5987425805382741}
2025-05-30 21:23:56 | DEBUG    | __main__:llm_reply:44 - doc:page_content='2.4无特殊情况，法定节假日前后不得连续请假，特殊情况需请假的，请假前请做好工作交接，请假期间请保持手机畅通，以便公司及时了解请假员工状况和对接相关工作事宜。

3、请假类别

3.1法定假节日：元旦1天、春节3天、清明节1天、劳动节1天、端午节1天、中秋节1天、国庆节3天

注：如遇国家对法定节假日的休假有最新的调整，按照最新国家规定执行。

3.2事假：无薪

3.2.1 员工遇有个人事务可在不妨碍正常工作的前提下申请事假；

3.2.2 事假全年累计一般不得超过 15天，一次不得超过3天，特殊情况请假一般不得大于5天；

3.2.3 试用期员工请事假，原则上不允许超过3个工作日，用人部门可酌情考虑是否继续留用；

3.3病假：

3.3.1病假单次2天以内提供医院门诊证明，单次2天以上提供三级甲等医院门诊及相关检查证明材料，住院的需提供住院及出院相关证明材料，同时通过钉钉系统办理请假手续；若无相关证明或证明不符合要求的按照事假计算；

3.3.2 工资支付标准：病假期间按长沙市最低工资标准的80%计发；' metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5218398908498185}
2025-05-30 21:23:56 | DEBUG    | __main__:llm_reply:44 - doc:page_content='1.3原则上所有请假/加班/调休必须在钉钉系统进行申请并批准后方可执行；因紧急特殊原因请假/调休，可以电话获得部门经理同意后24小时内申请，逾期未申请相关审批人员可不予准假，否则视为旷工。

1.4常规请假需提前1个工作日在钉钉系统进行申请，请假3天及以上人员需提前3天申请，并注明请假时间、类型、事由，未按要求提前申请可不予准假，请假审批通过后方可休假，否则按旷工处理；

2、请假规定

2.1最小请假单位为1小时，不足1小时按1小时计算。

2.2如请假提前结束的，需到行政人事行政部办理销假手续，否则假期时间按请假审批所填期限计算；

2.3请假期间如需续假，须在假期到期日前1个工作日在钉钉系统申请，经批准后方可续假；

2.4无特殊情况，法定节假日前后不得连续请假，特殊情况需请假的，请假前请做好工作交接，请假期间请保持手机畅通，以便公司及时了解请假员工状况和对接相关工作事宜。

3、请假类别

3.1法定假节日：元旦1天、春节3天、清明节1天、劳动节1天、端午节1天、中秋节1天、国庆节3天

注：如遇国家对法定节假日的休假有最新的调整，按照最新国家规定执行。

3.2事假：无薪' metadata={'source': './chroma/knowledge/人事管理流程.docx', 'relevance_score': 0.5074504869649954}
2025-05-30 21:23:56 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': ''}
2025-05-30 21:23:56 | DEBUG    | __main__:llm_reply:48 - chunk_content:
2025-05-30 21:23:56 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '根据提供的信息'}
2025-05-30 21:23:56 | DEBUG    | __main__:llm_reply:48 - chunk_content:根据提供的信息
2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '，公司的请假流程如下：\n\n'}
2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:48 - chunk_content:，公司的请假流程如下：


2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '1. **审批'}
2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:48 - chunk_content:1. **审批
2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '流程**：\n   - **'}
2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:48 - chunk_content:流程**：
   - **
2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '普通员工**申请'}
2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:48 - chunk_content:普通员工**申请
2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '请假/加班/调休'}
2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:48 - chunk_content:请假/加班/调休
2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '：需由**'}
2025-05-30 21:23:57 | DEBUG    | __main__:llm_reply:48 - chunk_content:：需由**
2025-05-30 21:23:58 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '直属领导**、**事业部'}
2025-05-30 21:23:58 | DEBUG    | __main__:llm_reply:48 - chunk_content:直属领导**、**事业部
2025-05-30 21:23:58 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '总监**、**人事行政'}
2025-05-30 21:23:58 | DEBUG    | __main__:llm_reply:48 - chunk_content:总监**、**人事行政
2025-05-30 21:23:58 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '主管**审批，并抄送'}
2025-05-30 21:23:58 | DEBUG    | __main__:llm_reply:48 - chunk_content:主管**审批，并抄送
2025-05-30 21:23:58 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '**考勤组**、'}
2025-05-30 21:23:58 | DEBUG    | __main__:llm_reply:48 - chunk_content:**考勤组**、
2025-05-30 21:23:58 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '**请假部门**、**'}
2025-05-30 21:23:58 | DEBUG    | __main__:llm_reply:48 - chunk_content:**请假部门**、**
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '人事行政经理**。\n  '}
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:48 - chunk_content:人事行政经理**。
  
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': ' - **主管及以上人员**'}
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:48 - chunk_content: - **主管及以上人员**
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '申请请假/调休或'}
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:48 - chunk_content:申请请假/调休或
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '请假≥3天：需'}
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:48 - chunk_content:请假≥3天：需
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '由**直属领导**、'}
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:48 - chunk_content:由**直属领导**、
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '**事业部总监**、**'}
2025-05-30 21:23:59 | DEBUG    | __main__:llm_reply:48 - chunk_content:**事业部总监**、**
2025-05-30 21:24:00 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '人事行政经理**、**'}
2025-05-30 21:24:00 | DEBUG    | __main__:llm_reply:48 - chunk_content:人事行政经理**、**
2025-05-30 21:24:00 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '总经理**审批，并抄送'}
2025-05-30 21:24:00 | DEBUG    | __main__:llm_reply:48 - chunk_content:总经理**审批，并抄送
2025-05-30 21:24:01 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '**考勤组**、'}
2025-05-30 21:24:01 | DEBUG    | __main__:llm_reply:48 - chunk_content:**考勤组**、
2025-05-30 21:24:01 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '**请假部门**、**'}
2025-05-30 21:24:01 | DEBUG    | __main__:llm_reply:48 - chunk_content:**请假部门**、**
2025-05-30 21:24:01 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '人事行政主管**、**'}
2025-05-30 21:24:01 | DEBUG    | __main__:llm_reply:48 - chunk_content:人事行政主管**、**
2025-05-30 21:24:01 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '股东会成员**。\n\n2'}
2025-05-30 21:24:01 | DEBUG    | __main__:llm_reply:48 - chunk_content:股东会成员**。

2
2025-05-30 21:24:01 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '. **系统申请'}
2025-05-30 21:24:01 | DEBUG    | __main__:llm_reply:48 - chunk_content:. **系统申请
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '**：\n   - 所'}
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:48 - chunk_content:**：
   - 所
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '有请假、加班、调'}
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:48 - chunk_content:有请假、加班、调
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '休原则上必须在**'}
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:48 - chunk_content:休原则上必须在**
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '钉钉系统**进行申请'}
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:48 - chunk_content:钉钉系统**进行申请
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '并获得批准后方可执行'}
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:48 - chunk_content:并获得批准后方可执行
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '。\n   - 因紧急'}
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:48 - chunk_content:。
   - 因紧急
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '特殊原因请假或'}
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:48 - chunk_content:特殊原因请假或
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '调休，可以先'}
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:48 - chunk_content:调休，可以先
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '通过电话获得**'}
2025-05-30 21:24:02 | DEBUG    | __main__:llm_reply:48 - chunk_content:通过电话获得**
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '部门经理**同意，但'}
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:48 - chunk_content:部门经理**同意，但
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '必须在**24小时内'}
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:48 - chunk_content:必须在**24小时内
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '**补交申请'}
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:48 - chunk_content:**补交申请
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '，逾期未申请的'}
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:48 - chunk_content:，逾期未申请的
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '，相关审批人员'}
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:48 - chunk_content:，相关审批人员
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '可不予准假，并'}
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:48 - chunk_content:可不予准假，并
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '视为**旷工**'}
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:48 - chunk_content:视为**旷工**
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '。\n\n3. **提前'}
2025-05-30 21:24:03 | DEBUG    | __main__:llm_reply:48 - chunk_content:。

3. **提前
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '申请**：\n   - '}
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:48 - chunk_content:申请**：
   - 
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '常规请假需**'}
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:48 - chunk_content:常规请假需**
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '提前1个工作日**在钉'}
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:48 - chunk_content:提前1个工作日**在钉
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '钉系统进行申请。\n  '}
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:48 - chunk_content:钉系统进行申请。
  
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': ' - 请假**'}
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:48 - chunk_content: - 请假**
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '3天及以上**的人员'}
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:48 - chunk_content:3天及以上**的人员
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '需**提前3天'}
2025-05-30 21:24:04 | DEBUG    | __main__:llm_reply:48 - chunk_content:需**提前3天
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '**申请，并注明请假时间'}
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:48 - chunk_content:**申请，并注明请假时间
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '、类型、事由。'}
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:48 - chunk_content:、类型、事由。
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '未按要求提前申请的'}
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:48 - chunk_content:未按要求提前申请的
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '，审批人员可不予准'}
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:48 - chunk_content:，审批人员可不予准
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '假，请假审批通过后'}
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:48 - chunk_content:假，请假审批通过后
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '方可休假，否则按**'}
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:48 - chunk_content:方可休假，否则按**
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '旷工**处理。\n\n4'}
2025-05-30 21:24:05 | DEBUG    | __main__:llm_reply:48 - chunk_content:旷工**处理。

4
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '. **最小请假单位**'}
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:48 - chunk_content:. **最小请假单位**
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '：\n   - 最小请假'}
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:48 - chunk_content:：
   - 最小请假
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '单位为**1小时**'}
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:48 - chunk_content:单位为**1小时**
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '，不足1小时按1'}
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:48 - chunk_content:，不足1小时按1
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '小时计算。\n\n5. **'}
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:48 - chunk_content:小时计算。

5. **
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '销假手续**：\n  '}
2025-05-30 21:24:06 | DEBUG    | __main__:llm_reply:48 - chunk_content:销假手续**：
  
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': ' - 如请假提前结束，'}
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:48 - chunk_content: - 如请假提前结束，
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '需到**行政人事行政'}
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:48 - chunk_content:需到**行政人事行政
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '部**办理销假手续'}
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:48 - chunk_content:部**办理销假手续
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '，否则假期时间按请假'}
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:48 - chunk_content:，否则假期时间按请假
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '审批所填期限计算。\n\n'}
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:48 - chunk_content:审批所填期限计算。


2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '6. **续假申请'}
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:48 - chunk_content:6. **续假申请
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '**：\n   - 请假'}
2025-05-30 21:24:07 | DEBUG    | __main__:llm_reply:48 - chunk_content:**：
   - 请假
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '期间如需续假，'}
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:48 - chunk_content:期间如需续假，
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '须在假期到期日前**'}
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:48 - chunk_content:须在假期到期日前**
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '1个工作日**在钉钉'}
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:48 - chunk_content:1个工作日**在钉钉
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '系统申请，经批准后'}
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:48 - chunk_content:系统申请，经批准后
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '方可续假。\n\n7.'}
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:48 - chunk_content:方可续假。

7.
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': ' **法定节假日前后'}
2025-05-30 21:24:08 | DEBUG    | __main__:llm_reply:48 - chunk_content: **法定节假日前后
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '请假规定**：\n  '}
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:48 - chunk_content:请假规定**：
  
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': ' - 无特殊情况，法定'}
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:48 - chunk_content: - 无特殊情况，法定
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '节假日前后不得连续请假。'}
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:48 - chunk_content:节假日前后不得连续请假。
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '特殊情况需请假的，请假'}
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:48 - chunk_content:特殊情况需请假的，请假
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '前请做好工作交接，请'}
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:48 - chunk_content:前请做好工作交接，请
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '假期间请保持手机畅通'}
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:48 - chunk_content:假期间请保持手机畅通
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '，以便公司及时了解请假'}
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:48 - chunk_content:，以便公司及时了解请假
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '员工状况和对接相关工作'}
2025-05-30 21:24:09 | DEBUG    | __main__:llm_reply:48 - chunk_content:员工状况和对接相关工作
2025-05-30 21:24:10 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '事宜。\n\n以上是完整的'}
2025-05-30 21:24:10 | DEBUG    | __main__:llm_reply:48 - chunk_content:事宜。

以上是完整的
2025-05-30 21:24:10 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': '请假流程及相关规定。'}
2025-05-30 21:24:10 | DEBUG    | __main__:llm_reply:48 - chunk_content:请假流程及相关规定。
2025-05-30 21:24:10 | DEBUG    | __main__:llm_reply:40 - chunk:{'answer': ''}
2025-05-30 21:24:10 | DEBUG    | __main__:llm_reply:48 - chunk_content:
2025-05-30 21:24:10 | DEBUG    | __main__:llm_reply:53 - chat_history:[['请假流程', '根据提供的信息，公司的请假流程如下：\n\n1. 请假审批流程：\n   - 普通员工申请请假/加班/调休：需要由直属领导、事业部总监、人事行政主管审批，并抄送考勤组、请假部门、人事行政经理。\n   - 主管及以上人员申请请假/调休或请假≥3天：需要由直属领导、事业部总监、人事行政经理、总经理审批，并抄送考勤组、请假部门、人事行政主管、股东会成员。\n\n2. 所有请假/加班/调休原则上必须在钉钉系统进行申请并获得批准后方可执行。因紧急特殊原因请假/调休，可以先电话获得部门经理同意，但必须在24小时内补交申请，否则相关审批人员可不予准假，且视为旷工。\n\n3. 常规请假需提前1个工作日在钉钉系统进行申请。请假3天及以上的人员需提前3天申请，并注明请假时间、类型、事由。未按要求提前申请的，审批人员可不予准假，请假审批通过后方可休假，否则按旷工处理。\n\n4. 最小请假单位为1小时，不足1小时按1小时计算。\n\n5. 如请假提前结束，需到行政人事行政部办理销假手续，否则假期时间按请假审批所填期限计算。\n\n6. 请假期间如需续假，须在假期到期日前1个工作日在钉钉系统申请，经批准后方可续假。\n\n7. 法定节假日前后不得连续请假，除非有特殊情况，并且请假前需要做好工作交接，请假期间保持手机畅通以便公司及时了解状况和对接工作事宜。'], ['请假流程', '根据提供的信息，公司的请假流程如下：\n\n1. **审批流程**：\n   - **普通员工**申请请假/加班/调休：需由**直属领导**、**事业部总监**、**人事行政主管**审批，并抄送**考勤组**、**请假部门**、**人事行政经理**。\n   - **主管及以上人员**申请请假/调休或请假≥3天：需由**直属领导**、**事业部总监**、**人事行政经理**、**总经理**审批，并抄送**考勤组**、**请假部门**、**人事行政主管**、**股东会成员**。\n\n2. **系统申请**：\n   - 所有请假、加班、调休原则上必须在**钉钉系统**进行申请并获得批准后方可执行。\n   - 因紧急特殊原因请假或调休，可以先通过电话获得**部门经理**同意，但必须在**24小时内**补交申请，逾期未申请的，相关审批人员可不予准假，并视为**旷工**。\n\n3. **提前申请**：\n   - 常规请假需**提前1个工作日**在钉钉系统进行申请。\n   - 请假**3天及以上**的人员需**提前3天**申请，并注明请假时间、类型、事由。未按要求提前申请的，审批人员可不予准假，请假审批通过后方可休假，否则按**旷工**处理。\n\n4. **最小请假单位**：\n   - 最小请假单位为**1小时**，不足1小时按1小时计算。\n\n5. **销假手续**：\n   - 如请假提前结束，需到**行政人事行政部**办理销假手续，否则假期时间按请假审批所填期限计算。\n\n6. **续假申请**：\n   - 请假期间如需续假，须在假期到期日前**1个工作日**在钉钉系统申请，经批准后方可续假。\n\n7. **法定节假日前后请假规定**：\n   - 无特殊情况，法定节假日前后不得连续请假。特殊情况需请假的，请假前请做好工作交接，请假期间请保持手机畅通，以便公司及时了解请假员工状况和对接相关工作事宜。\n\n以上是完整的请假流程及相关规定。']]
